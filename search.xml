<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>lightroomcahce</title>
    <url>/2022/07/13/%E5%B7%A5%E5%85%B7/lightroomcahce/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="目录缓存-catalog">目录缓存 (Catalog)</h2>
<pre><code>引导 LR 到照片在硬盘中的位置信息，对其进行远程操控，不用再复制一遍文件,不占用过多内存，也就是操作面板左侧的部分。只保存操作信息。在`编辑-目录设置 `中找到其缓存位置。</code></pre>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202207141203760.png" alt="目录缓存位置" /><figcaption aria-hidden="true">目录缓存位置</figcaption>
</figure>
<p>有三个文件夹</p>
<ol type="1">
<li><strong>Backup</strong> : 备份目录缓存，不会备份照片。</li>
<li><strong>Helper</strong>: 搜索目录缓存</li>
<li><strong>Preview</strong>: 图片预览缓存，可删除，下次进入会重新加载</li>
</ol>
<h2 id="相机原始缓存-camera-raw">相机原始缓存 (Camera RAW)</h2>
<pre><code>将图片完整加载进入 **camera RAW ** 缓存，获得更大的调整范围。`编辑-首选项-性能` 中可进行清理和配置，</code></pre>
]]></content>
      <categories>
        <category>工具</category>
      </categories>
  </entry>
  <entry>
    <title>Git 使用 代理</title>
    <url>/2023/07/31/%E6%8A%80%E6%9C%AF/20230731-Git%20%E4%BD%BF%E7%94%A8%20%E4%BB%A3%E7%90%86/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>首先Git 与远程仓库（如 Github) 的连接有两种，分别是 <strong>Http</strong> 和 <strong>SSH</strong></p>
<h1 id="http-启用代理">HTTP 启用代理</h1>
<p>首先介绍命令 <code>git config --global</code>。<code>git config --global</code> 是用于设置全局Git配置的命令。通过 <code>--global</code> 选项，你可以将配置应用到当前用户下所有的Git仓库，而不仅仅是当前仓库。</p>
<p>以下是几个常见的用法示例：</p>
<ul>
<li>设置用户名： <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git config --global user.name <span class="string">&quot;Your Name&quot;</span></span><br></pre></td></tr></table></figure></li>
<li>设置邮箱： <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git config --global user.email <span class="string">&quot;yourname@example.com&quot;</span></span><br></pre></td></tr></table></figure></li>
<li>配置默认的文本编辑器： <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git config --global core.editor <span class="string">&quot;vim&quot;</span></span><br></pre></td></tr></table></figure></li>
<li>显示已设置的全局配置： <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git config --global --list</span><br></pre></td></tr></table></figure></li>
<li>同理设置全局的 Http 代理 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Sock5 代理</span></span><br><span class="line">git config --global http.proxy socks5://127.0.0.1:7890</span><br><span class="line">git config --global https.proxy socks5://127.0.0.1:7890</span><br><span class="line"></span><br><span class="line"><span class="comment">#需要用户名和密码进行验证并限定代理的域名（如 github.com)：</span></span><br><span class="line">git config --global http.proxy.https://&lt;域名&gt;.proxy &lt;用户名&gt;:&lt;密码&gt;@&lt;代理地址&gt;</span><br><span class="line">git config --global https./&lt;域名&gt;.proxy &lt;用户名&gt;:&lt;密码&gt;@&lt;代理地址&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">#如果你想禁用全局代理，可以使用以下命令：</span></span><br><span class="line">git config --global --<span class="built_in">unset</span> http.proxy</span><br><span class="line">git config --global --<span class="built_in">unset</span> https.proxy</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="ssh-启用代理">SSH 启用代理</h1>
<p>回顾一下当使用 <code>git clone</code> 命令通过SSH克隆代码仓库时，背后涉及到以下原理：</p>
<ol type="1">
<li><p>SSH 密钥对生成：首先，你需要在本地计算机上生成一对 SSH 密钥（公钥和私钥）。在生成密钥对时，公钥将被添加到你的 GitHub 账户中，而私钥则保留在你的本地计算机上。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ssh-keygen -t rsa -C &quot;your_email@example.com&quot; -f ~/.ssh/name_of_your_private_key</span><br></pre></td></tr></table></figure></li>
<li><p>SSH 连接建立：通过 SSH 协议，你的本地计算机与远程服务器之间建立一个加密的连接。这个连接用于在本地计算机和远程代码仓库之间传输数据。在建立连接时，SSH 将使用你的私钥与远程服务器进行身份验证。</p></li>
<li><p>远程仓库验证：当连接建立后，Git 将使用你提供的 SSH URL 来访问远程代码仓库。在这个过程中，Git 使用你的公钥在远程服务器上进行身份验证，以确认你具有访问该代码仓库的权限。</p></li>
<li><p>代码仓库克隆：一旦成功验证身份并获得了访问权限，Git 将从远程仓库拉取所有代码和历史记录，并在本地创建一个与远程仓库相同的副本。这样，你就可以在本地计算机上对代码进行修改、提交和推送。</p></li>
</ol>
<p>通常通过命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh -vvvT  git@github.com -i ~/.ssh/name_of_your_private_key</span><br></pre></td></tr></table></figure>
<p>来check 2、3步。参数中 v 的数量越多，返回的 debug 信息越多。</p>
<p>值得注意的是 ssh 在默认情况下只会使用 <code>~/.ssh/id_&lt;Algorithm&gt;</code> 的 private key。<code>&lt;Algorithm&gt;</code> 表示加密算法比如 RSA,ECDSA 等。所以如果你生成密钥时指定了特定的名字，需要在连接时需要用参数 <code>-i</code> 指定私钥的路径。</p>
<h2 id="config">Config</h2>
<p>为了避免每次都需要制定冗长的参数，<code>~/.ssh/config</code> 文件应运而生，使我们的 ssh 命令十分简洁。</p>
<p><code>~/.ssh/config</code> 文件结构如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Host myserver <span class="comment"># 指定主机的别名，用于标识该连接配置适用于哪个主机。可以使用通配符 `*` 匹配多个主机别名。</span></span><br><span class="line">    HostName 192.168.1.100  <span class="comment"># 指定主机的 IP 地址或域名。</span></span><br><span class="line">    User myusername           <span class="comment"># 指定连接远程主机时使用的用户名。</span></span><br><span class="line">    IdentityFile ~/.ssh/id_rsa_server     <span class="comment"># 指定用于身份验证的私钥文件的路径。</span></span><br><span class="line">    Port 22                        <span class="comment"># 指定连接的端口号</span></span><br></pre></td></tr></table></figure>
<p>原本的 ssh 命令</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ssh myusername@192.168.1.100 -p 22 -i  ~/.ssh/id_rsa_server</span><br></pre></td></tr></table></figure>
<p>而当我们配置好上面的 config 文件后，ssh 命令简化为</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ssh myserver</span><br></pre></td></tr></table></figure>
<p>为了启用代理我原本是这么写的</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Host github.com</span><br><span class="line">    HostName github.com</span><br><span class="line">    User git</span><br><span class="line">    Port 22</span><br><span class="line">    ProxyCommand connect -S 127.0.0.1:7890 %h %p </span><br><span class="line">    IdentityFile C:\Users\lenovo\.ssh\id_rsa_github</span><br></pre></td></tr></table></figure>
<p><code>ProxyCommand</code> 表示使用代理连接。<code>connect</code> 是一个用于建立连接的工具，<code>-S 127.0.0.1:7890</code> 指定代理服务器的地址和端口号 。<code>%h</code> 和 <code>%p</code> 是SSH配置中的占位符，分别代表目标主机和目标端口。</p>
<p>然而报错</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kex_exchange_identification: Connection closed by remote host</span><br><span class="line">Connection closed by UNKNOWN port 65535</span><br></pre></td></tr></table></figure>
<p>端口换成 443，主机名改为 <code>ssh.github.com</code> 成功。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Host github.com</span><br><span class="line">    HostName ssh.github.com</span><br><span class="line">    User git</span><br><span class="line">    Port 443</span><br><span class="line">    ProxyCommand connect -S 127.0.0.1:7890 %h %p</span><br><span class="line">    IdentityFile C:\Users\lenovo\.ssh\id_rsa_github</span><br></pre></td></tr></table></figure>
<p>推断原因可能是代理服务器的DNS解析的问题。</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
  </entry>
  <entry>
    <title>Hexo-Next主题外接评论系统</title>
    <url>/2022/06/29/%E5%B7%A5%E5%85%B7/Hexo-Next%E4%B8%BB%E9%A2%98%E5%A4%96%E6%8E%A5%E8%AF%84%E8%AE%BA%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h3 id="前言">前言</h3>
<pre><code>**Waline** 是一款基于 **Valine** 衍生的评论系统，首先在笔者目前使用的 NexT 8.12.1 下已经不再内置 Valine 系统，需要自己手动配置。 看了一圈其他的评论系统，貌似只有 Waline 支持数学公式，所以最终选择 Waline 评论系统</code></pre>
<span id="more"></span>
<h3 id="配置数据库和服务端部署">配置数据库和服务端部署</h3>
<pre><code>选择[Leanclound]([LeanCloud](https://www.leancloud.cn/)) 作为评论数据库，在 Vercel 上部署服务端。接着就按照 [Waline的官方文档](https://waline.js.org/guide/get-started.html#leancloud-%E8%AE%BE%E7%BD%AE-%E6%95%B0%E6%8D%AE%E5%BA%93) 进行操作即可。这里介绍几个注意的点：</code></pre>
<ol type="1">
<li><p>注册时推荐使用国际版，否则需要绑定备案的域名，比较麻烦。</p></li>
<li><p>在 Vercel 上部署服务端时，注意环境变量名称 <code>LEAN_ID</code>, <code>LEAN_KEY</code> 和 <code>LEAN_MASTER_KEY</code>一定要一字不差。遇到访客评论系统在不登录账号时报错如下:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Invalid value type for field &#x27;link&#x27;,value &#x27;&quot;&quot;&#x27;,expect type is &#123;:type &quot;Object&quot;&#125;,but it is &#x27;&#123;:type &quot;String&quot;&#125;&#x27;. [400 POST https://ioksy7et.api.lncldglobal.com/1.1/classes/Comment]</span><br></pre></td></tr></table></figure>
<p>解决方法：重新在 Leanclound 上创建<code>Comment</code> 类。</p></li>
</ol>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202206301329339.png" alt="在 数据储存中创建新的Comment类" /><figcaption aria-hidden="true">在 数据储存</code>中创建新的Comment类</figcaption>
</figure>
<h3 id="在-hexo-上使用-waline">在 Hexo 上使用 Waline</h3>
<p>在 Hexo 根目录下执行命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install @waline/hexo-next</span><br></pre></td></tr></table></figure>
<p>接着你可以在 Hexo 根目录下 <code>\node_modules\@waline</code> 中找到 <code>default.yaml</code> 文件，里面就是所有 Waline 的设置选项了。 为了方便将其中需要改变的选项手动写入到 <code>next</code> 主题下 的 <code>_config.yaml</code>中， 以下是部分参考，更多的选项设置在上述 <code>default.yaml</code> 中：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">waline:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span> <span class="comment">#是否开启</span></span><br><span class="line">  <span class="attr">serverURL:</span> <span class="string">waline-server-ecru.vercel.app</span> <span class="comment"># Waline #服务端地址，我们这里就是上面部署的 Vercel 地址</span></span><br><span class="line">  <span class="attr">locale:</span></span><br><span class="line">    <span class="attr">placeholder:</span> <span class="string">疑义相与析，畅所欲言，不登录也没关系哒</span> <span class="comment"># #评论框的默认文字</span></span><br><span class="line">  <span class="attr">avatar:</span> <span class="string">mm</span> <span class="comment"># 头像风格</span></span><br><span class="line">  <span class="attr">meta:</span> [<span class="string">nick</span>,<span class="string">mail</span>] <span class="comment"># 自定义评论框上面的三个输入框的内容</span></span><br><span class="line">  <span class="attr">pageSize:</span> <span class="number">10</span> <span class="comment"># 评论数量多少时显示分页</span></span><br><span class="line">  <span class="attr">lang:</span> <span class="string">zh-cn</span> <span class="comment"># 语言, 可选值: en, zh-cn</span></span><br><span class="line">  <span class="attr">visitor:</span> <span class="literal">true</span> <span class="comment"># 文章阅读统计</span></span><br><span class="line">  <span class="attr">comment_count:</span> <span class="literal">true</span> <span class="comment"># 如果为 false , 评论数量只会在当前评论页面显示, 主页则不显示</span></span><br><span class="line">  <span class="attr">requiredFields:</span> [<span class="string">nick</span>] <span class="comment"># 设置用户评论时必填的信息，[nick,mail]: [nick] | [nick, mail]</span></span><br><span class="line">  <span class="attr">libUrl:</span> <span class="string">https://unpkg.com/@waline/client@v2/dist/waline.js</span> <span class="comment"># Set custom library cdn url</span></span><br><span class="line">  <span class="attr">login:</span> <span class="string">enable</span></span><br></pre></td></tr></table></figure>
<h3 id="登录服务端">登录服务端</h3>
<p>接着部署后就能够看到登录按钮，进行登录，貌似第一个登录的账号就会有个 <strong>博主</strong> 的标识。</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202206292335984.png" alt="进入登录界面" /><figcaption aria-hidden="true">进入登录界面</figcaption>
</figure>
<p>但是访客不登陆也能评论。访客填写不同的邮箱会显示其对应账号的头像。</p>
<p>最后效果可以参见<span class="exturl" data-url="aHR0cHM6Ly93YWxpbmUuanMub3JnLw==">官方文档<i class="fa fa-external-link-alt"></i></span> 。</p>
<h3 id="参考">参考</h3>
<p><span class="exturl" data-url="aHR0cHM6Ly93YWxpbmUuanMub3JnL2d1aWRlL2dldC1zdGFydGVkLmh0bWw=">官方文档<i class="fa fa-external-link-alt"></i></span></p>
<p><span class="exturl" data-url="aHR0cHM6Ly9xaWFuZmFuZ3VvamluLnRvcC8yMDIyLzAxLzIwL0hleG8lRTUlOEQlOUElRTUlQUUlQTIlRTglQkYlOUIlRTklOTglQjYlRUYlQkMlOUElRTQlQjglQkEtTmV4dC0lRTQlQjglQkIlRTklQTIlOTglRTYlQjclQkIlRTUlOEElQTAtV2FsaW5lLSVFOCVBRiU4NCVFOCVBRSVCQSVFNyVCMyVCQiVFNyVCQiU5Ri8=">谢同学博客<i class="fa fa-external-link-alt"></i></span></p>
]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>HTML</tag>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>Break_tie_randomly</title>
    <url>/2022/12/19/%E6%8A%80%E6%9C%AF/Break_tie_randomly/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p><code>np.argmax()</code>返回 arr 中第一个最大元素的下标，但是有时候需要在最大元素中随机选择一个.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.random.choice(np.flatnonzero(b == b.<span class="built_in">max</span>()))</span><br></pre></td></tr></table></figure>
<ul>
<li><code>b==b.max()</code> will return an array of booleans, with values of <code>true</code> where items are max and values of <code>false</code> for other items.</li>
<li><code>flatnonzero()</code> will do two things: ignore the <code>false</code> values (nonzero part) then return indices of <code>true</code> values. In other words, you get an array with indices of items matching the max value.</li>
<li>Finally, you pick a random index from the array.</li>
</ul>
<p>发现还是很慢，不如手写版本</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">random_argmax</span>(<span class="params">value_list</span>):</span><br><span class="line">  <span class="string">&quot;&quot;&quot; a random tie-breaking argmax &quot;&quot;&quot;</span></span><br><span class="line">  values = np.asarray(value_list)</span><br><span class="line">  <span class="keyword">return</span> np.argmax(np.random.random(values.shape) * (values==values.<span class="built_in">max</span>()))</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
  </entry>
  <entry>
    <title>Item03_const</title>
    <url>/2022/06/30/%E6%8A%80%E6%9C%AF/Item03_const/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>只要明确值不被改变就应该声明为 <code>const</code> ，以此获得编译器的襄助，保证规则不被违反。</p>
<h2 id="顶层-const-与-底层-const">顶层 <code>const</code> 与 底层 <code>const</code></h2>
<p>const pointer 成为顶层 const, pointer 指向的数据为 const 称为底层 const.</p>
<span id="more"></span>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">char</span> greeting[] = <span class="string">&quot;hello world&quot;</span>; 	<span class="comment">// greeting 类型为 char [12]</span></span><br><span class="line"><span class="type">const</span> <span class="type">char</span> *p = greeting;			<span class="comment">// 添加底层const const data , non-const pointer</span></span><br><span class="line"><span class="type">char</span> * <span class="type">const</span> p = greeting;			<span class="comment">// 顶层const non-const data , const pointer </span></span><br><span class="line"><span class="type">const</span> <span class="type">char</span> * <span class="type">const</span> p =greeting 		<span class="comment">// const data , const pointer</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>底层 const 的以下两种写法等价</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">const</span> <span class="type">char</span> *p;		</span><br><span class="line"><span class="type">char</span> <span class="type">const</span> *p;</span><br></pre></td></tr></table></figure>
<p><strong>STL</strong> 中的 iterator 类似于 (T*) 指针。声明迭代器为 const 类似于 <code>T * const</code> ，顶层const。而如果需要迭代器所指向的数据不被修改，需要 <code>const_iterator</code> 。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">std::vector&lt;<span class="type">int</span>&gt; v&#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>&#125;;</span><br><span class="line"><span class="type">const</span> std::vector&lt;<span class="type">int</span>&gt;::iterator it = v.<span class="built_in">begin</span>();      <span class="comment">//顶层const </span></span><br><span class="line">*it = <span class="number">1</span>;  <span class="comment">//正确，可被修改</span></span><br><span class="line">++it;   <span class="comment">//错误，不能修改迭代器本身</span></span><br><span class="line">std::vector&lt;<span class="type">int</span>&gt;::const_iterator itt = v.<span class="built_in">begin</span>();      <span class="comment">//底层const </span></span><br><span class="line">*itt = <span class="number">1</span>;  <span class="comment">//错误，被指向的数据不可被修改</span></span><br><span class="line">++itt;   <span class="comment">//正确，可以递增迭代器本身</span></span><br></pre></td></tr></table></figure>
<h2 id="函数返回值">函数返回值</h2>
<p>将函数范围值声明为 const 可以减少不必要的麻烦,比如</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Rational</span> &#123;</span><br><span class="line">&#125;;</span><br><span class="line">...</span><br><span class="line"><span class="function"><span class="type">const</span> Rational *<span class="title">operator</span><span class="params">(<span class="type">const</span> Rational &amp;lhs, <span class="type">const</span> Rational &amp;rhs)</span> </span>&#123;...&#125;</span><br></pre></td></tr></table></figure>
<p>如果去掉返回值的 const ，你的用户可能做出如下行为</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">(<span class="number">3</span>*<span class="number">5</span>) = <span class="number">3</span></span><br></pre></td></tr></table></figure>
<p>你可能觉得根本不会有人做出怎么奇怪的操作，但是下面这个错误就比较隐蔽， 用户在条件语句中将 <code>==</code> 写成了 <code>=</code>，发生隐式 <strong>bool</strong> 类型的转化：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span>( (<span class="number">3</span>*<span class="number">5</span>) = <span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<p>尽量将使用 <em>reference-to-const</em> 作为参数不仅避免拷贝，还能绑定到右值，比如:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">foo</span> <span class="params">(std::string &amp; s)</span></span></span><br><span class="line"><span class="function">...</span></span><br><span class="line"><span class="function">std::string str</span>;</span><br><span class="line"><span class="built_in">foo</span>(str)		<span class="comment">//正确，绑定到左值</span></span><br><span class="line"><span class="built_in">foo</span>(<span class="string">&quot;hello&quot;</span>)	<span class="comment">//错误，不能绑定右值 &quot;hello&quot; </span></span><br></pre></td></tr></table></figure>
<p>尽管 const 只有六个字符，但是却能避免很多不必要的麻烦。</p>
<h2 id="const-成员函数">const 成员函数</h2>
<h4 id="目的">目的</h4>
<ol type="1">
<li>使得 class 接口容易被理解，明白哪些函数改动内容，而哪些不行</li>
<li>使得 ‘操作 const 对象’ 成为可能。因为很多情况需要使用 <em>pass by reference-to-const</em> ，这项技术的前提就是需要 const 成员函数。</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TextBlock</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="type">const</span> <span class="type">char</span> &amp;<span class="keyword">operator</span>[](std::<span class="type">size_t</span> pos) <span class="type">const</span> &#123; </span><br><span class="line">      <span class="keyword">return</span> text[pos];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">char</span> &amp;<span class="keyword">operator</span>[](std::<span class="type">size_t</span> pos)  &#123;</span><br><span class="line">      <span class="keyword">return</span> text[pos];</span><br><span class="line">    &#125;</span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    std::string text;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>下面是调用 operator [] 的例子</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">print</span><span class="params">(<span class="type">const</span> TextBlock &amp; str)</span> </span>&#123; <span class="comment">//str 是 const 对象</span></span><br><span class="line">  std::cout &lt;&lt; str[<span class="number">0</span>];       <span class="comment">//调用 const 成员函数</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果 operator [] 的返回值类型是 <strong>char reference</strong> ，如果是 char 的话，下面句子无法编译:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">str[<span class="number">0</span>] = <span class="string">&#x27;x&#x27;</span></span><br></pre></td></tr></table></figure>
<h3 id="bitwise-const-and-logical-const">bitwise const and logical const</h3>
<ul>
<li><strong>bitwise const</strong>: class 内部的成员变量不能修改 ，编译器检测的方式</li>
<li><strong>logical const</strong>: 设计者期望的常量</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CTextBlock</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">CTextBlock</span>(<span class="type">char</span> *str):<span class="built_in">p</span>(str)&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">char</span> &amp; <span class="keyword">operator</span>[](std::<span class="type">size_t</span> pos) <span class="type">const</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> p[pos];</span><br><span class="line">    &#125;</span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    <span class="type">char</span> *p;</span><br><span class="line">&#125;;</span><br><span class="line">...</span><br><span class="line"><span class="type">char</span> str[] = <span class="string">&quot;hello&quot;</span>;</span><br><span class="line"><span class="function"><span class="type">const</span> CTextBlock <span class="title">ccb</span><span class="params">(str)</span></span>;</span><br><span class="line"><span class="type">char</span> *p = &amp;ccb[<span class="number">0</span>];</span><br><span class="line">*p = <span class="string">&#x27;J&#x27;</span>;			<span class="comment">//还是被修改了</span></span><br></pre></td></tr></table></figure>
<p>这里我们想要的 const 是 p 的内部值不被改变，但是 operator[] 返回值没加 const 时也能编译成功，即逃过了编译器 <strong>bitwise const</strong> 检查。所以尽可能使用 <strong>STL</strong> 中的 string 而非手动管理内存。</p>
<p>下面在介绍一个 <strong>logical const</strong> 被 编译器 <strong>bitwise const </strong>所过度限制的例子。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CTextBlock</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="function">std::<span class="type">size_t</span> <span class="title">length</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    <span class="type">char</span> *pText;</span><br><span class="line">    std::<span class="type">size_t</span> textlength;</span><br><span class="line">    <span class="type">bool</span> lengthIsvalid;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function">std::<span class="type">size_t</span> <span class="title">CTextBlock::length</span><span class="params">()</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span>(!lengthIsvalid) &#123;</span><br><span class="line">    textlength = std::<span class="built_in">strlen</span>(pText);</span><br><span class="line">    lengthIsvalid = <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> textlength;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>显然 <code>length()</code> 不是 <code>bitwise const</code> ， 因为 <code>textlength</code> 发生了改变。但是对于我们而言，<code>textlength</code> 与 <code>lengthIsvalid</code> 是可以接受的。 我们可以使用 <code>mutable</code> 关键字释放掉 non-static 成员变量 <strong>bitwise const</strong> 的约束。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CTextBlock</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="function">std::<span class="type">size_t</span> <span class="title">length</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    <span class="type">char</span> *pText;</span><br><span class="line">    <span class="keyword">mutable</span> std::<span class="type">size_t</span> textlength; <span class="comment">//现在可在 const 成员函数中被修改</span></span><br><span class="line">    <span class="keyword">mutable</span> <span class="type">bool</span> lengthIsvalid;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function">std::<span class="type">size_t</span> <span class="title">CTextBlock::length</span><span class="params">()</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span>(!lengthIsvalid) &#123;</span><br><span class="line">    textlength = std::<span class="built_in">strlen</span>(pText);</span><br><span class="line">    lengthIsvalid = <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> textlength;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="在-const-成员函数和-non-const-成员函数中避免重复">在 const 成员函数和 non-const 成员函数中避免重复</h2>
<p>在对某个函数实现 const 与 non-const 重载时，会产生大量的代码重复，比如在上面的例子中放入更多复杂的操作</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TextBlock</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="type">const</span> <span class="type">char</span> &amp;<span class="keyword">operator</span>[](std::<span class="type">size_t</span> pos) <span class="type">const</span> &#123; </span><br><span class="line">      <span class="comment">//do  somethings</span></span><br><span class="line">      <span class="keyword">return</span> text[pos];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">char</span> &amp;<span class="keyword">operator</span>[](std::<span class="type">size_t</span> pos)  &#123;</span><br><span class="line">      <span class="comment">// do somethings</span></span><br><span class="line">      <span class="keyword">return</span> text[pos];</span><br><span class="line">    &#125;</span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    std::string text;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>我们应该考虑令其中的一个调用另一个，这是一种很重要的思想，在重载 <code>+=</code> 和 <code>+</code> 是也利用之。利用 const 成员函数实现 non-const</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TextBlock</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="type">const</span> <span class="type">char</span> &amp;<span class="keyword">operator</span>[](std::<span class="type">size_t</span> pos) <span class="type">const</span> &#123; </span><br><span class="line">      <span class="comment">//do  somethings</span></span><br><span class="line">      <span class="keyword">return</span> text[pos];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">char</span> &amp;<span class="keyword">operator</span>[](std::<span class="type">size_t</span> pos)  &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="built_in">const_cast</span>&lt;<span class="type">char</span> &amp;&gt;(      <span class="comment">//移除 op[] 的 const </span></span><br><span class="line">          <span class="built_in">static_cast</span>&lt;<span class="type">const</span> TextBlock&amp;&gt;(*<span class="keyword">this</span>)[pos]);  <span class="comment">//为当前对象添加 const </span></span><br><span class="line">    &#125;</span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    std::string text;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>这里用到两次转型 分别是为 <code>*this</code> 添加 const ， 为 op[ ] 的返回值移除 const. 注意 <code>const_cast</code> 与 <code>static_const</code> 的区别。只有 <code>const_cast</code> 能移除 const。</p>
<p>但是反向做法：利用 non-const 成员函数实现 const 是不正确的。这是一个危险的行为，首先 <strong>non-const</strong> 函数并未声明不对对象进行修改，而 <strong>const</strong> 成员函数依赖与一个改变对象的函数显然是不合理的。而且你不得不使用 <code>const_cast</code> 去除 const，最终实现的 <strong>const</strong> 成员函数不能保证真正的 const. const 成员函数声明也就失效了。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TextBlock</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="type">const</span> <span class="type">char</span> &amp;<span class="keyword">operator</span>[](std::<span class="type">size_t</span> pos) <span class="type">const</span> &#123; </span><br><span class="line">      <span class="comment">//do  somethings</span></span><br><span class="line">      <span class="keyword">return</span> <span class="built_in">static_cast</span>&lt;<span class="type">const</span> <span class="type">char</span> &amp;&gt;(      <span class="comment">//添加 op[] 的 const </span></span><br><span class="line">          <span class="built_in">const_cast</span>&lt;TextBlock&amp;&gt;(*<span class="keyword">this</span>)[pos]);  <span class="comment">//为当前对象移除 const </span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">char</span> &amp;<span class="keyword">operator</span>[](std::<span class="type">size_t</span> pos)  &#123;</span><br><span class="line">      <span class="comment">// do somethings</span></span><br><span class="line">      text[pos] = <span class="string">&#x27;a&#x27;</span>;</span><br><span class="line">      <span class="keyword">return</span> text[pos];</span><br><span class="line">    &#125;</span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    std::string text;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h2 id="总结">总结</h2>
<ul>
<li>将某些东西声明为 const 可帮助编译器侦测错误用法。const 可作用于对象，函数参数，函数返回值类型，成员函数本体。</li>
<li>编译器实施 <strong>bitwise constness</strong> ，但编写程序时应使用 <strong>conceptual constness</strong>.</li>
<li>non-const 版本调用 const 版本避免代码重复</li>
</ul>
<h2 id="参考">参考</h2>
<p>Effective C++ 中文版（第三版）</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
  </entry>
  <entry>
    <title>Ananconda问题</title>
    <url>/2022/07/22/%E6%8A%80%E6%9C%AF/Ananconda%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>打开 <strong>Anaconda</strong> 时出现</p>
<h3 id="解决方法">解决方法</h3>
<p>取消代理</p>
<p><img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202207221821701.png" /></p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
  </entry>
  <entry>
    <title>vscode_git</title>
    <url>/2022/12/18/%E6%8A%80%E6%9C%AF/vscode_git/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="git">Git</h1>
<ol type="1">
<li><p><code>clone</code> : 所有版本有一个远程仓库，把它复制到本地工作区称为 <code>clone</code>。</p></li>
<li><p><code>add</code>: 增加的内容载入暂存区。</p></li>
<li><p><code>commit</code>: 为添加的到副本的内容起一个名字，最终将添加的内容加入本地仓库。</p></li>
<li><p><code>push</code>: 把本地仓库里新增的添加到正本里面</p></li>
<li><p><code>pull</code>:其他成员把远程仓库同步更新到自己的工作区，注意会覆盖本地文件。</p></li>
<li><p><code>fetch</code>: 将远程仓库更新的本地版本仓库。</p></li>
<li><p><code>diff</code>: 对比区别，没问题在合并过来。</p></li>
<li><p>文件的几个状态：</p>
<ul>
<li><strong>untracked</strong>: 新建的文件</li>
<li><strong>upstage</strong>: 被 track 且被修改的文件</li>
<li><strong>stage</strong>: 已经被 track</li>
</ul></li>
</ol>
<h1 id="实操">实操</h1>
<ol type="1">
<li><code>git init</code> 初始化。</li>
<li><code>git status</code> 查看当前文件的状态。</li>
<li><code>git add</code> 将修改暂存到缓存区。</li>
<li><code>git commit -m</code> 输入提交信息。</li>
<li><code>git status</code> nothing to commit，也就是把所有文件都提交到本地版本库了</li>
<li><code>git log</code> 查看记录，谁提交的</li>
<li><code>touch .gitignore</code> 在 <code>.gitignore</code> 增加忽略的文件名即可。</li>
<li><code>git commit -am 信息</code> 将 add 和 commit 合并在一起写。</li>
</ol>
<h2 id="分支">分支</h2>
<p>不确定当前修改是否需要，可以创建新的分支，在新分支里修改，准备好后可合并到主分支中。</p>
<ol type="1">
<li><code>git branch</code> 查看分支，+ 分支名 创建分支。</li>
<li><code>git checkout + 分支名</code> 切换分支</li>
<li><strong>注意</strong>： 如果在分支里删除.ignore 文件， 在主分支里也会被删除</li>
<li><code>git branch -d</code> ： 删除分支</li>
<li><code>git checkout -b</code> 创建并切换到新分支。</li>
<li><code>git merge + 分支名</code> 把其他分支合并到所在分支。注意冲突</li>
</ol>
<h1 id="上手-github">上手 Github</h1>
<ol type="1">
<li><code>git-clone + http 连接</code> github上一开始创建时的主支名字是 main 而本地用git 则是 master.</li>
<li><code>git remote -v</code> 查看本地仓库和哪些远程仓库有联系。默认用 origin 代表远程仓库的名字。</li>
<li><code>git remote add</code> 自己选名字 <code>&lt;url&gt;</code>/<code>git remote remove</code> 添加远程仓库连接。</li>
<li>生成 token</li>
<li><code>git fetch</code> 可以指定远程仓库和分支名的。</li>
<li><code>git diff 远程仓库名/分支名</code> 看到区别。</li>
</ol>
<h1 id="问题汇总">问题汇总</h1>
<h3 id="在git中走代理">在git中走代理</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 设置</span></span><br><span class="line">git config --global http.proxy <span class="string">&#x27;socks5://127.0.0.1:7890&#x27;</span> </span><br><span class="line">git config --global https.proxy <span class="string">&#x27;socks5://127.0.0.1:7890&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 恢复</span></span><br><span class="line">git config --global --<span class="built_in">unset</span> http.proxy</span><br><span class="line">git config --global --<span class="built_in">unset</span> https.proxy</span><br></pre></td></tr></table></figure>
<p>用 <code>curl -v https://www.google.com</code> 查看是否成功</p>
<p>很多网络的原理都不清楚，打算以后来补。</p>
<h3 id="git-upstream-branch"><strong>Git Upstream Branch</strong></h3>
<p>"Upstream Branch" is the remote branch hosted on Github. It’s the branch you fetch/pull from whenever you issue a plain git fetch/git pull basically without arguments.</p>
<p><code>git push --set-upstream origin &lt;branch name&gt;</code> 来设置.</p>
<p><span class="exturl" data-url="aHR0cHM6Ly93d3cuZ2Vla3Nmb3JnZWVrcy5vcmcvaG93LXRvLXNldC11cHN0cmVhbS1icmFuY2gtb24tZ2l0Lw==">How to set up Upstream Branch on Git<i class="fa fa-external-link-alt"></i></span></p>
<h3 id="refusing-to-merge-unrelated-histories">refusing to merge unrelated histories</h3>
<p>一般出现在创建新仓库的时候新建 <code>readme.md</code>文件，然后在pull 的时候，所以最后的流程最好是先在远程仓库建好，然后 clone. 解决方法强制合并</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git pull origin branchname --allow-unrelated-histories</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
  </entry>
  <entry>
    <title>np</title>
    <url>/2022/07/23/%E6%8A%80%E6%9C%AF/np.random.rand%20vs%20np.random.random/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><table>
<tbody>
<tr class="odd">
<td>span</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.random.rand(<span class="number">2</span>,<span class="number">7</span>)</span><br><span class="line">a = np.random.random((<span class="number">2.7</span>))</span><br></pre></td></tr></table></figure>
<h3 id="推荐写法">推荐写法</h3>
<p>自 Numpy 1.17 后， 提供新的 方法</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rng = np.random.default_rng()  <span class="comment"># Create a default Generator.</span></span><br><span class="line">rng.random(size=<span class="number">10</span>)  <span class="comment"># Generate 10 samples.</span></span><br><span class="line">array([<span class="number">0.00416913</span>, <span class="number">0.31533329</span>, <span class="number">0.19057857</span>, <span class="number">0.48732511</span>, <span class="number">0.40638395</span>,</span><br><span class="line">       <span class="number">0.32165646</span>, <span class="number">0.02597142</span>, <span class="number">0.19788567</span>, <span class="number">0.08142055</span>, <span class="number">0.15755424</span>])</span><br><span class="line">rng = np.random.uniform(<span class="number">0</span>,<span class="number">1</span>,size=(<span class="number">2</span>,<span class="number">3</span>)) <span class="comment">#specify bound </span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
  </entry>
  <entry>
    <title>Tensorflow-gpu2</title>
    <url>/2022/08/14/%E6%8A%80%E6%9C%AF/Tensorflow-gpu2.4.0%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="前言">前言</h1>
<p>装好 <code>Tensorflow 2.3.0</code> 之后，训练一个 MNIST 集花了7分钟左右，于是想安装 GPU 版本的. 于是就开始踩坑了</p>
<h1 id="选定版本">选定版本</h1>
<p>安装 <code>Tensorflow-gpu</code> 需要安装<a href="https://www.tensorflow.org/install/source"><strong>相应的</strong> CUDA 和 cuDNN 版本</a>。这里应该先看自己的显卡所支持的 CUDA 版本，再确定 Tensorflow 版本。通过 <code>NIVIDIA-系统信息-组件</code> 查看</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202208141916549.png" alt="驱动支持的CUDA版本" /><figcaption aria-hidden="true">驱动支持的CUDA版本</figcaption>
</figure>
<p>我的显卡是 RTX 3060 版本比较高，之前安装的 2.3.0 版本不知道为什么就在编译模型，和构建模型的时候卡死。所以选择 <code>Tensorflow-gpu=2.4.0</code> 。</p>
<h1 id="安装">安装</h1>
<p>打开cmd, 激活虚拟环境</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda active ts</span><br></pre></td></tr></table></figure>
<p>选择阿里云镜像源，默认源无该版本且速度慢</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install Tensorflow-gpu=2.4.0 -i https://mirrors.aliyun.com/pypi/simple/</span><br></pre></td></tr></table></figure>
<p>听说这里应该会自动安装对应的 CUDA 和 cuDNN，然而我并没用，手动安装</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install cudnn==8.0 -i https://mirrors.aliyun.com/pypi/simple/</span><br></pre></td></tr></table></figure>
<p>这里会自动安装 cudatookit ，接着安装 keras</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install keras==2.4.3</span><br></pre></td></tr></table></figure>
<p>是否检测到GPU</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">tf.config.list_physical_devices(<span class="string">&#x27;GPU&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>输出 <code>[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]</code> 则成功。</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
  </entry>
  <entry>
    <title>手写数字识别</title>
    <url>/2022/08/14/%E6%8A%80%E6%9C%AF/%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="使用-mlp-实现">使用 MLP 实现</h1>
<h2 id="设置">设置</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">tf.config.list_physical_devices(<span class="string">&#x27;GPU&#x27;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>[PhysicalDevice(name=&#39;/physical_device:GPU:0&#39;, device_type=&#39;GPU&#39;)]</code></pre>
<h2 id="载入数据">载入数据</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">(x_train,y_train),(x_test,y_test) = mnist.load_data()</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.imshow(x_test[<span class="number">0</span>])</span><br><span class="line">plt.colorbar()</span><br><span class="line">plt.grid(<span class="literal">False</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202208141915773.png" alt="载入数据" /><figcaption aria-hidden="true">载入数据</figcaption>
</figure>
<h4 id="load_data">load_data()</h4>
<p><strong>返回</strong>：</p>
<p>两个元组：</p>
<pre><code>x_train, x_test: uint8 数组表示的灰度图像，尺寸为 (num_samples, 28, 28)

y_train, y_test: uint8 数组表示的数字标签（范围在 0-9 之间的整数），尺寸为 (num_samples,)</code></pre>
<p><strong>参数</strong>： path: 如果在本地没有索引文件 (at '~/.keras/datasets/' + path), 它将被下载到该目录</p>
<h4 id="mnist-数据集">Mnist 数据集</h4>
<p>训练集为 60,000 张 28x28 像素灰度图像，测试集为 10,000 同规格图像，总共 10 类数字标签。</p>
<h2 id="处理原始数据">处理原始数据</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">x_train = x_train / <span class="number">255.0</span>       <span class="comment">#隐式转换为float64</span></span><br><span class="line">x_test = x_test / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(x_train.shape,<span class="string">&quot;train data&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(x_test.shape,<span class="string">&quot;test data&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>(60000, 28, 28) train data
(10000, 28, 28) test data</code></pre>
<p>将原始数据归一化。<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RiYXQyMDE1L2FydGljbGUvZGV0YWlscy81MDAwODMxNQ==" title="最好的markdown教程">归一化的作用<i class="fa fa-external-link-alt"></i></span></p>
<h2 id="转换标签">转换标签</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> to_categorical</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">y_train = to_categorical(y_train, num_classes=<span class="number">10</span>)</span><br><span class="line">y_test = to_categorical(y_test, num_classes=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(y_test)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>[[0. 0. 0. ... 1. 0. 0.]
 [0. 0. 1. ... 0. 0. 0.]
 [0. 1. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]</code></pre>
<p>使用 <span class="exturl" data-url="aHR0cHM6Ly93d3cuZ2Vla3Nmb3JnZWVrcy5vcmcvcHl0aG9uLWtlcmFzLWtlcmFzLXV0aWxzLXRvX2NhdGVnb3JpY2FsLw==">to_categorical()<i class="fa fa-external-link-alt"></i></span> 将标签向量转化为 binary matrix</p>
<h2 id="构建模型">构建模型</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense,Dropout,Flatten</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Flatten(input_shape=(<span class="number">28</span>,<span class="number">28</span>)))</span><br><span class="line">model.add(Dense(<span class="number">512</span>,activation=<span class="string">&#x27;relu&#x27;</span>,name=<span class="string">&quot;Dense1&quot;</span>)) <span class="comment">#添加全连接层</span></span><br><span class="line">model.add(Dropout(<span class="number">0.3</span>,name=<span class="string">&#x27;dropout1&#x27;</span>))</span><br><span class="line">model.add(Dense(<span class="number">128</span>,activation=<span class="string">&#x27;relu&#x27;</span>,name=<span class="string">&#x27;Dense2&#x27;</span>))</span><br><span class="line">model.add(Dropout(<span class="number">0.3</span>,name=<span class="string">&#x27;dropout2&#x27;</span>))</span><br><span class="line">model.add(Dense(<span class="number">10</span>,activation=<span class="string">&#x27;softmax&#x27;</span>,name=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line">model.summary()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;sequential&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
flatten (Flatten)            (None, 784)               0
_________________________________________________________________
Dense1 (Dense)               (None, 512)               401920
_________________________________________________________________
dropout1 (Dropout)           (None, 512)               0
_________________________________________________________________
Dense2 (Dense)               (None, 128)               65664
_________________________________________________________________
dropout2 (Dropout)           (None, 128)               0
_________________________________________________________________
softmax (Dense)              (None, 10)                1290
=================================================================
Total params: 468,874
Trainable params: 468,874
Non-trainable params: 0
_________________________________________________________________</code></pre>
<p>网络第一层 <code>Flatten</code> 将图像转换成以为数组，该层没有要学习的参数。</p>
<p>每个 <code>Dense</code> 层有 512 神经元， 最后一个使用 <code>softmax</code> 激活函数，它可以将一个数值向量归一化为一个概率分布向量:</p>
<p><span class="math display">\[
Softmax(zi) = \frac{e^{z_i}}{\sum_j {e^{z_j}}}
\]</span></p>
<h2 id="编译模型">编译模型</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.losses <span class="keyword">import</span> categorical_crossentropy</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> Adamax</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=Adamax(),</span><br><span class="line">              loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br></pre></td></tr></table></figure>
<p>使用 <code>Admax</code> <span class="exturl" data-url="aHR0cHM6Ly9rZXJhcy5pby96aC9vcHRpbWl6ZXJzLw==">优化器<i class="fa fa-external-link-alt"></i></span>，<code>categotical_crossentropy</code>（交叉熵损失） 作为<span class="exturl" data-url="aHR0cHM6Ly9rZXJhcy5pby96aC9sb3NzZXMv">损失函数<i class="fa fa-external-link-alt"></i></span>，通常与 softmax 配合使用：</p>
<p><span class="math display">\[
Loss = -log(1-p_i)
\]</span></p>
<p><span class="math inline">\(p_i\)</span>是预测样本真实标签得到的概率</p>
<h2 id="训练模型">训练模型</h2>
<p>调用 <code>model.fit</code> 方法，这样命名因为会将模型与训练数据进行拟合</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.fit(x_train,y_train,batch_size=<span class="number">128</span>,epochs=<span class="number">10</span>,verbose=<span class="number">1</span>,validation_data=(x_test,y_test))</span><br></pre></td></tr></table></figure>
<pre><code>Epoch 1/10
469/469 [==============================] - 4s 5ms/step - loss: 0.7144 - accuracy: 0.7838 - val_loss: 0.1901 - val_accuracy: 0.9447
Epoch 2/10
469/469 [==============================] - 2s 4ms/step - loss: 0.2355 - accuracy: 0.9317 - val_loss: 0.1319 - val_accuracy: 0.9605
Epoch 3/10
469/469 [==============================] - 2s 4ms/step - loss: 0.1644 - accuracy: 0.9515 - val_loss: 0.1056 - val_accuracy: 0.9678
Epoch 4/10
469/469 [==============================] - 2s 4ms/step - loss: 0.1290 - accuracy: 0.9617 - val_loss: 0.0917 - val_accuracy: 0.9717
Epoch 5/10
469/469 [==============================] - 2s 4ms/step - loss: 0.1077 - accuracy: 0.9687 - val_loss: 0.0837 - val_accuracy: 0.9743
Epoch 6/10
469/469 [==============================] - 2s 4ms/step - loss: 0.0963 - accuracy: 0.9710 - val_loss: 0.0751 - val_accuracy: 0.9759
Epoch 7/10
469/469 [==============================] - 2s 4ms/step - loss: 0.0802 - accuracy: 0.9763 - val_loss: 0.0738 - val_accuracy: 0.9772
Epoch 8/10
469/469 [==============================] - 2s 4ms/step - loss: 0.0714 - accuracy: 0.9790 - val_loss: 0.0663 - val_accuracy: 0.9791
Epoch 9/10
469/469 [==============================] - 2s 4ms/step - loss: 0.0664 - accuracy: 0.9798 - val_loss: 0.0647 - val_accuracy: 0.9798
Epoch 10/10
469/469 [==============================] - 2s 4ms/step - loss: 0.0570 - accuracy: 0.9830 - val_loss: 0.0633 - val_accuracy: 0.9800</code></pre>
<p><code>epochs</code> 是训练次数，<code>validation_date</code> 是划分出测试集，训练集正确率达到98%以上</p>
<h2 id="评估准确率">评估准确率</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">test_loss,test_acc = model.evaluate(x_test,y_test,verbose=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nTest accurancy&#x27;</span>, test_acc)</span><br></pre></td></tr></table></figure>
<pre><code>313/313 [==============================] - 1s 2ms/step - loss: 0.0284 - accuracy: 0.9916

Test accurancy 0.991599977016449</code></pre>
<h2 id="进行预测">进行预测</h2>
<p>来看第一个预测结果</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">predictions= model.predict(x_test)</span><br><span class="line">predictions[<span class="number">0</span>]</span><br><span class="line">np.argmax(predictions[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<pre><code>7</code></pre>
<p>可以绘制图表，查看对全部类的预测</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">plot_image</span>(<span class="params">i,predictions_array, true_label, img</span>):</span><br><span class="line">  predictions_array, true_label, img = predictions_array, true_label, img</span><br><span class="line">  plt.grid(<span class="literal">False</span>)</span><br><span class="line">  plt.xticks([])</span><br><span class="line">  plt.yticks([])</span><br><span class="line"></span><br><span class="line">  plt.imshow(img, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line">  predicted_label = np.argmax(predictions_array)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> predicted_label == true_label:</span><br><span class="line">    color = <span class="string">&#x27;blue&#x27;</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    color = <span class="string">&#x27;red&#x27;</span></span><br><span class="line"></span><br><span class="line">  plt.xlabel(<span class="string">&quot;&#123;&#125; &#123;:3.0f&#125;% (&#123;&#125;)&quot;</span>.<span class="built_in">format</span>(predicted_label,</span><br><span class="line">                                      <span class="number">100</span>*np.<span class="built_in">max</span>(predictions_array),true_label),color=color)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_value_array</span>(<span class="params">i,predictions_array, true_label</span>):</span><br><span class="line">   predictions_array, true_label = predictions_array, true_label</span><br><span class="line">   plt.grid(<span class="literal">False</span>)</span><br><span class="line">   plt.xticks(<span class="built_in">range</span>(<span class="number">10</span>))</span><br><span class="line">   plt.yticks([])</span><br><span class="line">   thisplot = plt.bar(<span class="built_in">range</span>(<span class="number">10</span>), predictions_array, color=<span class="string">&quot;#777777&quot;</span>)</span><br><span class="line">   plt.ylim([<span class="number">0</span>,<span class="number">1</span>])</span><br><span class="line">   predicted_label = np.argmax(predictions_array)</span><br><span class="line"></span><br><span class="line">   thisplot[predicted_label].set_color(<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">   thisplot[true_label].set_color(<span class="string">&#x27;blue&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>正确标签为蓝色，错误为红色</p>
<h2 id="验证预测结果">验证预测结果</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">num_rows = <span class="number">10</span></span><br><span class="line">num_cols = <span class="number">5</span></span><br><span class="line">num_images = num_rows*num_cols</span><br><span class="line">plt.figure(figsize=(<span class="number">2</span>*<span class="number">2</span>*num_cols, <span class="number">2</span>*num_rows))</span><br><span class="line">x_test.reshape(<span class="number">10000</span>,<span class="number">28</span>,<span class="number">28</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_images):</span><br><span class="line">  t = np.argmax(y_test[i])</span><br><span class="line">  plt.subplot(num_rows, <span class="number">2</span>*num_cols, <span class="number">2</span>*i+<span class="number">1</span>)</span><br><span class="line">  plot_image(i, predictions[i], t, x_test[i])</span><br><span class="line">  plt.subplot(num_rows, <span class="number">2</span>*num_cols, <span class="number">2</span>*i+<span class="number">2</span>)</span><br><span class="line">  plot_value_array(i, predictions[i], t)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202208141915886.png" alt="验证预测结果" /><figcaption aria-hidden="true">验证预测结果</figcaption>
</figure>
<h1 id="使用-cnn">使用 CNN</h1>
<h2 id="重新载入数据">重新载入数据</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">(x_train,y_train),(x_test,y_test) = mnist.load_data()</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.imshow(x_test[<span class="number">0</span>])</span><br><span class="line">plt.colorbar()</span><br><span class="line">plt.grid(<span class="literal">False</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">x_train = np.expand_dims(x_train,-<span class="number">1</span>)</span><br><span class="line">x_test = np.expand_dims(x_test,-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">x_train = x_train / <span class="number">255.0</span></span><br><span class="line">x_test = x_test / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line">y_train = to_categorical(y_train)</span><br><span class="line">y_test = to_categorical(y_test)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202208141914539.png" alt="载入数据" /><figcaption aria-hidden="true">载入数据</figcaption>
</figure>
<p>x.shape = (samples_nums, height, width, channels)</p>
<h2 id="构建模型-1">构建模型</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Conv2D,MaxPooling2D</span><br><span class="line">model = Sequential()</span><br><span class="line">input_size = (<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>)</span><br><span class="line">model.add(Conv2D(<span class="number">32</span>,</span><br><span class="line">          kernel_size = (<span class="number">3</span>,<span class="number">3</span>), </span><br><span class="line">          activation = <span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">          input_shape = input_size))</span><br><span class="line"></span><br><span class="line">model.add(Dropout(<span class="number">0.3</span>))</span><br><span class="line"></span><br><span class="line">model.add(Conv2D(<span class="number">16</span>,</span><br><span class="line">          kernel_size = (<span class="number">3</span>,<span class="number">3</span>), </span><br><span class="line">          activation = <span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(MaxPooling2D(pool_size=(<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line">model.add(Dropout(<span class="number">0.3</span>))</span><br><span class="line">model.add(Flatten())</span><br><span class="line">model.add(Dense(<span class="number">128</span>,activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(Dropout(<span class="number">0.4</span>))</span><br><span class="line">model.add(Dense(<span class="number">10</span>,activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;sequential_5&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d_8 (Conv2D)            (None, 26, 26, 32)        320
_________________________________________________________________
dropout_12 (Dropout)         (None, 26, 26, 32)        0
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 24, 24, 16)        4624
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 12, 12, 16)        0
_________________________________________________________________
dropout_13 (Dropout)         (None, 12, 12, 16)        0
_________________________________________________________________
flatten_5 (Flatten)          (None, 2304)              0
_________________________________________________________________
dense_8 (Dense)              (None, 128)               295040
_________________________________________________________________
dropout_14 (Dropout)         (None, 128)               0
_________________________________________________________________
dense_9 (Dense)              (None, 10)                1290
=================================================================
Total params: 301,274
Trainable params: 301,274
Non-trainable params: 0
_________________________________________________________________</code></pre>
<h2 id="编译和训练模型">编译和训练模型</h2>
<p>选择 <code>Adamdelta</code> 作为优化器</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> Adam</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=Adam(), loss = <span class="string">&#x27;categorical_crossentropy&#x27;</span>, metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">model.fit(x_train,y_train,</span><br><span class="line">          batch_size=<span class="number">128</span>,</span><br><span class="line">          epochs=<span class="number">10</span>,</span><br><span class="line">          verbose=<span class="number">1</span>,</span><br><span class="line">          validation_data=(x_test,y_test))</span><br></pre></td></tr></table></figure>
<pre><code>Epoch 1/10
469/469 [==============================] - 6s 9ms/step - loss: 0.6243 - accuracy: 0.8000 - val_loss: 0.0790 - val_accuracy: 0.9767
Epoch 2/10
469/469 [==============================] - 3s 7ms/step - loss: 0.1273 - accuracy: 0.9605 - val_loss: 0.0503 - val_accuracy: 0.9837
Epoch 3/10
469/469 [==============================] - 3s 6ms/step - loss: 0.0927 - accuracy: 0.9715 - val_loss: 0.0396 - val_accuracy: 0.9874
Epoch 4/10
469/469 [==============================] - 3s 7ms/step - loss: 0.0748 - accuracy: 0.9758 - val_loss: 0.0387 - val_accuracy: 0.9891
Epoch 5/10
469/469 [==============================] - 3s 6ms/step - loss: 0.0634 - accuracy: 0.9814 - val_loss: 0.0355 - val_accuracy: 0.9880
Epoch 6/10
469/469 [==============================] - 3s 7ms/step - loss: 0.0558 - accuracy: 0.9828 - val_loss: 0.0331 - val_accuracy: 0.9900
Epoch 7/10
469/469 [==============================] - 3s 6ms/step - loss: 0.0502 - accuracy: 0.9835 - val_loss: 0.0295 - val_accuracy: 0.9911
Epoch 8/10
469/469 [==============================] - 3s 6ms/step - loss: 0.0488 - accuracy: 0.9848 - val_loss: 0.0296 - val_accuracy: 0.9906
Epoch 9/10
469/469 [==============================] - 3s 6ms/step - loss: 0.0439 - accuracy: 0.9856 - val_loss: 0.0313 - val_accuracy: 0.9910
Epoch 10/10
469/469 [==============================] - 3s 6ms/step - loss: 0.0420 - accuracy: 0.9865 - val_loss: 0.0303 - val_accuracy: 0.9912

&lt;tensorflow.python.keras.callbacks.History at 0x16d0c5fa340&gt;</code></pre>
<h2 id="评估准确率-1">评估准确率</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">test_loss, test_acc = model.evaluate(x_test, y_test, verbose= <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nTest accuracy:&#x27;</span>, test_acc)</span><br><span class="line"></span><br><span class="line">num_rows = <span class="number">10</span></span><br><span class="line">num_cols = <span class="number">5</span></span><br><span class="line">num_images = num_rows*num_cols</span><br><span class="line">plt.figure(figsize=(<span class="number">2</span>*<span class="number">2</span>*num_cols, <span class="number">2</span>*num_rows))</span><br><span class="line">x_test.reshape(<span class="number">10000</span>,<span class="number">28</span>,<span class="number">28</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_images):</span><br><span class="line">  t = np.argmax(y_test[i])</span><br><span class="line">  plt.subplot(num_rows, <span class="number">2</span>*num_cols, <span class="number">2</span>*i+<span class="number">1</span>)</span><br><span class="line">  plot_image(i, predictions[i], t, x_test[i])</span><br><span class="line">  plt.subplot(num_rows, <span class="number">2</span>*num_cols, <span class="number">2</span>*i+<span class="number">2</span>)</span><br><span class="line">  plot_value_array(i, predictions[i], t)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>313/313 - 1s - loss: 0.0303 - accuracy: 0.9912

Test accuracy: 0.9911999702453613</code></pre>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202208141915772.png" alt="验证预测结果" /><figcaption aria-hidden="true">验证预测结果</figcaption>
</figure>
<h2 id="cnn-与-mlp-对比">CNN 与 MLP 对比</h2>
<ol type="1">
<li>CNN 能提取像素间的空间关系，而 MLP 将图像变为一维向量丢失空间信息</li>
<li>MLP 是每一层是全连接的，参数数量多， CNN 每一层共享 kernel ，节点之间不是全连接，因此参数大小取决于 kernel 大小，参数数量少</li>
<li>CNN　具有 <em>局部平移不变性</em>, 即无论图像出现在那个位置，都能提取到该特征。（因为共享 filter）. 而 MLP 不具有平移不变性，如果一张图片的特征出现在左上，而另一张特征出现在右下，那么 MLP 将尝试往右下修正参数。</li>
</ol>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
  </entry>
  <entry>
    <title>CS101 PA3</title>
    <url>/2022/12/17/%E6%95%B0%E5%AD%A6/CS101%20PA3/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="t2">T2</h1>
<p>考虑贪心，对每一个容器，就是在能够容纳的信息里面选择一个能最大化利用容器的。将信息和容器都按照 a 为关键字排序。然后外层循环容器，对于第 i个容器，如果第 j 个信息的 <span class="math inline">\(a_j\leq A_i\)</span> ，把第 j 个信息放入待选的信息，然后 j++，直到不能放为止。然后从待选的信息的挑选一个最优的信息 ，即满足 <span class="math inline">\(d \leq D_i\)</span> 的信息中 <span class="math inline">\(d_k\)</span> 最大的一个信息，然后 ans++，从待选信息中删除该信息。由于满足了 a 从小到大排序，对于待选的信息, <span class="math inline">\(a_j \leq A_i \leq A_{i+1}\)</span> ，所以后面的每一个容器都是可以从待选信息中选择的。维护待选信息可使用 <span class="math inline">\(BST\)</span> ，也可以用 <code>multiset</code>, 在 <span class="math inline">\(\log n\)</span> 时间内查询。总的时间复杂度是 <span class="math inline">\(O(n\log n)\)</span>.</p>
<h1 id="t3">T3</h1>
<ol type="1">
<li><span class="math inline">\(A\geq D\)</span>: 也就是说我们需要尽量快的到达 n 点，直接BFS，每个点的遍历顺序一定是保证最快到达的，如果到达该点发现打不过，那么这个点相当于“死了”，不用考虑路过该点了。</li>
<li><span class="math inline">\(A&lt;D\)</span>: 首先是如何判断能否到达 n 点。 这个时候我们只需要尽可能多地从占领的区域的相邻的点中，挑选一个 <code>s[y]</code> 最小的一个点，如果能打过，那么 <code>attack</code> 增加，有利于我打更强的，如果连最小的都打不过，那么说明已经无法从占领区域中扩展了，就这样不断扩大占领区域，用优先队列维护相邻的点，直到能扩展到 n 点就说明可以到达（注：不用扩展到全部点）。 <strong>假设</strong>我们能够到达 n 点，那么和之前类似，如果到达该点发现打不过，那么我们可以加上一个等待时间 <code>wait</code> 直到能击败该节点为止 <code>dis[pre]+1+wait &lt; dis[y]</code> 那么更新 y 点，但是这个时候需要用 <code>dijkstra</code> 来确保始终从距离最小的点更新。之前判断能不能的时候，我们其实已经达到过n，也就是对所有点，wait最多可以是最终的最优解dis[n]，因为最多可以打dis[n]个小怪来补充攻击力，打败当前点 <code>wait&gt;=dis[n]</code>的话，也没关系，因为最后松弛操作会把这种情况滤掉</li>
</ol>
]]></content>
      <categories>
        <category>数学</category>
      </categories>
  </entry>
  <entry>
    <title>三角形中的几个恒等式</title>
    <url>/2022/07/01/%E6%95%B0%E5%AD%A6/%E4%B8%89%E8%A7%92%E5%BD%A2%E4%B8%AD%E7%9A%84%E5%87%A0%E4%B8%AA%E6%81%92%E7%AD%89%E5%BC%8F/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在 <span class="math inline">\(\Delta ABC\)</span> 中，以下等式成立</p>
<h3 id="正余弦平方和">正余弦平方和</h3>
<p><span class="math display">\[
\sin A+\sin B+\sin C=4\cos  \frac{A}{2}\cos  \frac{B}{2}\cos  \frac{C}{2}\ \tag{1}
\]</span></p>
<p>证：</p>
<p><span class="math display">\[
\begin{aligned} LHS &amp;= 2\,\sin \frac{A+B}{2}\,\cos \frac{A-B}{2} +\sin C  \\ &amp;= 2 \,\cos  \frac{C}{2}\,\cos \frac{A-B}{2}+2\,\sin \frac{C}{2}\,\cos \frac{C}{2}\\ &amp;=2\,\cos  \frac{C}{2}\,(\cos \frac{A-B}{2}+\cos \frac{A+B}{2})\\ &amp;=4\,\cos \frac{A}{2}\,\cos \frac{B}{2}\,\cos \frac{C}{2} \\ \end{aligned}
\]</span></p>
<p><span class="math display">\[
\cos A+\cos B+\cos C=1+4\sin  \frac{A}{2}\sin  \frac{B}{2}\sin  \frac{C}{2}\\ \tag{2}
\]</span></p>
<p>证：</p>
<p><span class="math display">\[
\begin{aligned} LHS &amp;= 2\,\cos \frac{A+B}{2}\,\cos \frac{A-B}{2} + 1-2\,\sin ^2\frac{C}{2}  \\  &amp;= 1-2\,\sin \frac{C}{2}\,(\sin \frac{C}{2}-\cos \frac{A-B}{2})  \\ &amp;=1-2\,\sin \frac{C}{2}\,(\cos \frac{A+B}{2}-\cos \frac{A-B}{2})   \\ &amp;=1-2\,\sin \frac{C}{2}\,(-2\,\sin \frac{A}{2}\,\sin \frac{B}{2})\\ &amp;=1+4\sin  \frac{A}{2}\sin  \frac{B}{2}\sin  \frac{C}{2} \end{aligned}
\]</span></p>
<h3 id="正余半角平方和">正余半角平方和</h3>
<p><span class="math display">\[
\sin ^2\frac{A}{2}+\sin ^2\frac{B}{2}+\sin ^2\frac{C}{2}= 1-2\,\sin \frac{A}{2}\sin \frac{B}{2}\sin \frac{C}{2}\tag{3}
\]</span></p>
<p>证：</p>
<p><span class="math display">\[
\begin{aligned} RHS &amp;= 1+\sin \frac{C}{2}\,(\cos \frac{A+B}{2}-\cos \frac{A-B}{2}) \\ &amp;=  1+\sin ^2\frac{C}{2}- \cos \frac{A+B}{2}\cos \frac{A-B}{2}\\ &amp;=  1+\sin ^2\frac{C}{2}-\frac{\cos A+\cos B}{2} \\ &amp;= 1+\sin ^2\frac{C}{2}-\frac{2-2\sin ^2\frac{A}{2}-2\sin ^2\frac{B}{2}}{2}   \\ &amp;=  \sin ^2\frac{A}{2}+\sin ^2\frac{B}{2}+\sin ^2\frac{C}{2} \end{aligned}
\]</span></p>
<p>同理易得：</p>
<p><span class="math display">\[
\cos ^2\frac{A}{2}+\cos ^2\frac{B}{2}+\cos ^2\frac{C}{2}= 2+2\,\sin \frac{A}{2}\sin \frac{B}{2}\sin \frac{C}{2}\tag{4}
\]</span></p>
<h3 id="正割余割和">正割余割和</h3>
<p><span class="math display">\[
\tan A+\tan B+\tan C=\tan A\;\tan B\;\tan C \tag{5}
\]</span></p>
<p>证：</p>
<p><span class="math display">\[
\begin{gather*} \text{和角公式：}\tan C = -\frac{\tan A+\tan B}{1-\tan A\;\tan B}\\ \tan C-\tan A\;\tan B\;\tan C = -(\tan A+\tan B)\\ \text{移项后得到结论} \end{gather*}
\]</span></p>
<p>推论：</p>
<p><span class="math display">\[
\cot A\,\cot B+\cot A\,\cot C+\cot B\,\cot C =1\tag{6}
\]</span></p>
<p>证：</p>
<p><span class="math display">\[
\begin{aligned} \text{由 (5)得到: }\frac{1}{\tan A\,\tan B}&amp;=\frac{\tan C}{\tan A+\tan B+\tan C}\\ \frac{1}{\tan A\,\tan C}&amp;=\frac{\tan B}{\tan A+\tan B+\tan C}\\ \frac{1}{\tan B\,\tan C}&amp;=\frac{\tan A}{\tan A+\tan B+\tan C}\\ \end{aligned}
\]</span></p>
<p>三个式子相加即可</p>
<h3 id="正余割半角">正余割半角</h3>
<p><span class="math display">\[
\cot \frac{A}{2}\cot \frac{B}{2}\cot \frac{C}{2} = \cot \frac{A}{2}\,\cot \frac{B}{2}\,\cot \frac{C}{2} \tag{7}
\]</span></p>
<p>证： 受到 (5) 启发，只需证明</p>
<p><span class="math display">\[
cot \frac{C}{2} = -\frac{\cot \frac{A}{2}+\cot \frac{B}{2}}{1-\cot \frac{A}{2}\,\cot \frac{B}{2}}
\]</span></p>
<p>即证：</p>
<p><span class="math display">\[
\begin{gather*} \tan\frac{C}{2} =\frac{\cot \frac{A}{2}\,\cot \frac{B}{2}-1}{\cot \frac{A}{2}+\cot \frac{B}{2}}\\ \Leftarrow \tan\frac{C}{2} = \frac{1-\tan\frac{A}{2}\tan\frac{B}{2}}{\tan\frac{A}{2}+\tan\frac{B}{2}} \end{gather*}
\]</span></p>
<p>推论：</p>
<p><span class="math display">\[
\tan\frac{A}{2}\tan\frac{B}{2}+\tan\frac{B}{2}\tan\frac{C}{2}+\tan\frac{A}{2}\tan\frac{C}{2} = 1 \tag{8}
\]</span></p>
<p>由 (7) 移项得到</p>
<p><span class="math display">\[
\begin{gather*} \tan\frac{A}{2}\tan\frac{B}{2}=\frac{\tan\frac{A}{2}\,\tan\frac{B}{2}\,\tan\frac{B}{2}\,\cot\frac{C}{2}}{\tan\frac{A}{2}+\tan\frac{B}{2}+\tan\frac{C}{2}}\\ \tan\frac{A}{2}\tan\frac{C}{2}=\frac{\tan\frac{A}{2}\,\tan\frac{B}{2}\,\tan\frac{B}{2}\,\cot\frac{B}{2}}{\tan\frac{A}{2}+\tan\frac{B}{2}+\tan\frac{C}{2}}\\ \tan\frac{B}{2}\tan\frac{C}{2}=\frac{\tan\frac{A}{2}\,\tan\frac{B}{2}\,\tan\frac{B}{2}\,\cot\frac{A}{2}}{\tan\frac{A}{2}+\tan\frac{B}{2}+\tan\frac{C}{2}}\\ \end{gather*} \\
\]</span></p>
<p>三个式子相加即可</p>
]]></content>
      <categories>
        <category>数学</category>
      </categories>
  </entry>
  <entry>
    <title>不等式</title>
    <url>/2022/07/05/%E6%95%B0%E5%AD%A6/%E4%B8%8D%E7%AD%89%E5%BC%8F/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="oscillation">Oscillation</h2>
<p>Example:</p>
<p><span class="math display">\[
\begin{gather}
b_n=c_n \, a_n=(-1)^{n+1}a_n \text, \, a_n \geq 0\\
\sum_{n=1}^{N} b_n \leq \sum_{n=1}^{N}\left| b_n \right| = \sum_{n=1}^N a_n
\end{gather}
\]</span></p>
<p>Use <em>Euler's formula</em> to rewrite</p>
<p><span class="math display">\[
(-1)^n=e^{2\pi in\frac{1}{2}}=\cos(2\pi n\frac{1}{2})+i\sin(2\pi n\frac{1}{2})
\]</span></p>
<p>Periodicity is 2. Moreover , Take periodicity k</p>
<p><span class="math display">\[
(e^{2\pi i\frac{1}{k}})^{n+k}= (e^{2\pi i\frac{1}{k}})^{n}\\
\]</span></p>
<h3 id="fourier-series">Fourier series</h3>
<p>More generally, for $ x$, consider <span class="math inline">\(e^{-i\omega n}\)</span>: Periodicity <span class="math inline">\(\frac{1}{x}\)</span>, and <span class="math inline">\(\omega = \frac{2\pi}{x}\)</span></p>
<p><span class="math display">\[
F(x):= \sum_{n=-\infty}^\infty a_n e^{-i\omega n}\text{     ,              }
F_N(x):= \sum_{n=-\infty}^\infty a_n e^{-i\omega n}
\]</span></p>
<p>Generate a new function on <span class="math inline">\(\left[-1,1\right]\)</span> , known as Fourier analysis.</p>
<p>Since <span class="math inline">\(|e^{i\theta}|\leq 1\)</span>, therefore</p>
<h3 id="introduction-a-norm">introduction a norm</h3>
<p>For a sequence <span class="math inline">\((a_n)_{n\in\mathbb{Z}}\in\mathbb{R}\)</span>, Let</p>
<p><span class="math display">\[
\left\|a_n \right\|_{\boldsymbol l^2}:= (\sum _{n=-\infty}^\infty |a_n|^p )^\frac{1}{p} \text{  for } p\in [1,\infty]
\]</span></p>
<p>and</p>
<p><span class="math display">\[
\|a_n\| = \mathop{sup}\limits_{n\in\mathbb{Z}}|a_n|
\]</span></p>
<p>We can measure the distance between two sequences e.g. for <span class="math inline">\(c_n=(-1)^{n+1}\)</span> and <span class="math inline">\(d_n=(-1)^{n+1}(1+\frac{1}{n})\)</span>.</p>
<p><span class="math display">\[
\|c_n-d_n\|=(\sum_{n=-\infty}^{\infty}\frac{1}{n^2})^\frac{1}{2}=\frac{\pi}{\sqrt6}\leq2
\]</span></p>
<h3 id="l2-estimate-crude"><span class="math inline">\(L^2\)</span>-estimate: Crude</h3>
<p>Recall the crude estimate :<span class="math inline">\(|F_N(x)| \leq \sum_{n=-N}^{n=N} a_n\)</span> ：no oscillation</p>
<p>This yields</p>
<p><span class="math display">\[
\begin{aligned}
\|F_N\|_{L^2}&amp;=(\int_{-1}^1(F_N(x))^2d\,x)^\frac{1}{2}\\
&amp;\leq(\int_{-1}^1a_n^2d\,x)^\frac{1}{2})\\
&amp;=2^{\frac{1}{2}}\sum_{n=-N}^{N} a_n
\end{aligned}
\]</span></p>
<p>In particular, if <span class="math inline">\(a_n=1\)</span> for all <span class="math inline">\(|n|\leq N\)</span> then</p>
<p><span class="math display">\[
\|\sum_{n=-\infty}^\infty e^{-i\omega n}\| \leq 2^\frac{3}{2}N
\]</span></p>
<p><span class="math inline">\(L^2\)</span> -size of <span class="math inline">\(F_N(x)\)</span> is bounded by <span class="math inline">\(O(N)\)</span></p>
<h3 id="theorem-3-parsevals-identity">Theorem 3 (Parseval's identity)</h3>
<p><span class="math display">\[
\|\sum_{n=-\infty}^\infty e^{-i\omega n}\| \leq 2N^\frac{3}{2}\ll2^\frac{3}{2}N
\]</span></p>
<p>Multiplying out the square:</p>
<p><span class="math display">\[
\begin{aligned}
\|\sum_{n=-N}^N e^{-i\omega n}\| &amp;=(\int_{-1}^1(\sum_{n=-N}^N e^{-i\omega n}) ^2d\,x)^\frac{1}{2}\\
&amp;=\int_{-1}^1 \sum_{n=-N}^N e^{-i\omega n}\sum_{m=-N}^N e^{-i\omega n}d\,x\\
&amp;= \sum_{n=-N}^N\sum_{m=-N}^N \int_{-1}^1  e^{-i\omega (n-m)}d\,x
\end{aligned}
\]</span></p>
<p>For the diagonal case (m=n)</p>
<p><span class="math display">\[
\int_{-1}^1  e^{-i\omega (n-m)}d\,x =2
\]</span></p>
<p>For the non-diagonal case (<span class="math inline">\(n\neq m\)</span>)</p>
<p><span class="math display">\[
\int_{-1}^1  e^{-i\omega (n-m)}d\,x =-\frac{1}{2\pi i (n-m)}(e^{-2\pi i (n-m)}-e^{2\pi i (n-m)})=0
\]</span></p>
<p>Same argument shows more generally</p>
<p><span class="math display">\[
\begin{gather}
\text{For any }a_n \;s.t.\|a_n\|_{l^2}=(\sum_{n=-\infty}^\infty |a_n|^2)^{\frac{1}{2}}&lt;\infty.\\
\|\sum_{n=-\infty}^\infty e^{-i\omega n}\| _{l^2}=2^{\frac{1}{2}}\|a_n\|_{l^2}
\end{gather}
\]</span></p>
]]></content>
      <categories>
        <category>数学</category>
      </categories>
  </entry>
  <entry>
    <title>将数量场转为向量场</title>
    <url>/2022/06/28/%E6%95%B0%E5%AD%A6/%E5%B0%86%E6%95%B0%E9%87%8F%E5%9C%BA%E8%BD%AC%E4%B8%BA%E5%90%91%E9%87%8F%E5%9C%BA/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h3 id="题面">题面</h3>
<pre><code>设$\Sigma(t)$ 是平面 $x+y+z=t$ 被球面 $x^2+y^2+z^2=1$ 截下的部分，设</code></pre>
<p><span class="math display">\[
F(x,y,z)=1-(x^2+y^2+z^2),
\]</span></p>
<pre><code>求证，对于$\left| t \right| \leq \sqrt 3$ 时，有</code></pre>
<p><span class="math display">\[
\int _{\Sigma(t)} F(x,y,z)\,d\sigma = \frac{\pi}{18} (3-t^2)^2
\]</span></p>
<span id="more"></span>
<h3 id="方法一">方法一</h3>
<pre><code>将原坐标系$X Y Z$ 进行变换，新坐标系的 $X&#39;OY&#39;$ 平面为原坐标系的平面 $x+y+z=0$ ，坐标 $z&#39;$ 为点在原坐标系下距离 $\Sigma(0)$ 的距离，$z&#39; = \frac &#123;t&#125;&#123;\sqrt3&#125;$ ， 为了渐变就沿用 $xyz$ 命名好了。接下来就是很普通的在 $z=\frac&#123;t&#125;&#123;\sqrt 3&#125;$ 上将 $xy$ 化为极坐标的积分了。</code></pre>
<p><span class="math display">\[
\begin{gather}
\begin{aligned}
\iint _{z=\frac{t}{\sqrt 3}} 1-z^2\,d\sigma &amp;= \int_0^{2\pi}d\theta \int_0^{\sqrt {1-\frac{t^2}{3}}}(1-\frac{t^2}{3}-r^2) r\,dr\\
 &amp;=\frac{\pi}{18} (3-t^2)^2
 \end{aligned}
\end{gather}
\]</span></p>
<h3 id="方法二">方法二</h3>
<pre><code>这个方法比较绕，是利用$Gauss$ 定理 + 补面的方式。但是 F 是个数量场，怎么把它变成向量场呢?</code></pre>
<p><span class="math display">\[
\begin{equation}
\iint_S F dS  =\iint_S \boldsymbol{v}\, \vec{n} \,dS
\end{equation}
\]</span></p>
<p>所以现在就是需要去确定一种 <span class="math inline">\(\vec{v}\)</span> 和 <span class="math inline">\(\vec{n}\)</span> 使其点乘为 <span class="math inline">\(F\)</span> ， 为了简便 <span class="math inline">\(\vec{v} = (1-z^2) \,\vec{k}\)</span> ，<span class="math inline">\(\vec{n}=\vec{k}\)</span>， 在进行补面就能使用高斯公式了，设 <span class="math inline">\(V\)</span> 为 <span class="math inline">\(S_1:z=\frac{t}{\sqrt3}\)</span> 和球面 <span class="math inline">\(S_2:x^2+y^2+z^2=1\)</span> 围成的面积。</p>
<p><span class="math display">\[
\begin{gather}
\begin{aligned}
\iint_{S_1+S_2} \boldsymbol{v}\, \vec{n} \,dS &amp; = \iiint_V \Delta\,\vec{v} \, d\vec{S}\\
&amp;=\iiint_V2z \,  dxdydz
\end{aligned}
\end{gather}
\]</span></p>
<p>注意因为高斯定理要求向量场指向平面的外侧，上面公式的 <span class="math inline">\(\vec{v}\)</span> 的方向与的我们构造的<span class="math inline">\(\vec{v}\)</span> 之间方向相反。</p>
<p>再将<span class="math inline">\(xyz\)</span> 换为极坐标 (注意这里和 <span class="math inline">\(t\)</span> 没什么关系，<span class="math inline">\(t\)</span> 只是个常数)</p>
<p><span class="math display">\[
\begin{cases}
x= (1-z^2)\,r\,cos\theta\\
y= (1-z^2)\,r\,sin\theta\\
z=z\\
\end{cases}
\]</span></p>
<p>然后三重积分</p>
<p><span class="math display">\[
\begin{gather}
\begin{aligned}
\iiint_V2z \,  dxdydz &amp;= 2\pi\int_{\frac{t}{\sqrt3}}^1z\,dz\int_0^{\sqrt{1-z^2}}r\,dr\\
&amp; = -\frac{\pi}{18}(3-t^2)^2
\end{aligned}
\end{gather}
\]</span></p>
<p>而另一方面</p>
<p><span class="math display">\[
\because 1-z^2 = 0 \,\text{in} \,S_2\\
\therefore
\iint_{S_2} \boldsymbol{v}\, \vec{n} \,dS = 0\\
\]</span></p>
<p><span class="math display">\[
\begin{gathered}
\begin{aligned}
\iint_{S_1} \boldsymbol{v}\, \vec{n} \,dS &amp;=\iint_{S_1+S_2} \boldsymbol{v}\, \vec{n} \,dS-\iint_{S_2} \boldsymbol{v}\, \vec{n} \,dS \\
&amp;=\frac{\pi}{18}(3-t^2)^2
\end{aligned}
\end{gathered}
\]</span></p>
]]></content>
      <categories>
        <category>数学</category>
      </categories>
  </entry>
  <entry>
    <title>偷影子的人</title>
    <url>/2023/01/22/%E6%9D%82%E8%B0%88/%E5%81%B7%E5%BD%B1%E5%AD%90%E7%9A%84%E4%BA%BA/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><pre><code>读完这本书，很多地方感到迷惑。

『 我』的母亲是个平凡的母亲形象，包括隐瞒病情，和书末母亲去世前为迎接我做的准备，以及『 吃剩的淋了枫糖浆的苹果卡卡蛋糕』无不让人动容。至于母亲为什么把父亲的信藏起来，推测或许是为了断绝我和父亲的来往，将我据为己有？另一个母亲是我在城里的楼上的老妇人艾丽丝。这个老妇人虽然儿女不怎么孝顺，但是却依旧如此幽默和豁达的生活。摔了一跤还那么开心，最后还想认我和吕克为自己的儿子。也许是长期身处异乡吧，我和吕克对老妇人就像对待自己母亲一般，透露出大城市里相互依靠的温情。

友情线主要是和面包店老板的儿子吕克，感觉也没太多感人的细节。倒是吕克喜欢上主人公的女友这个剧情显得很奇怪。倒是伊凡我觉得是更能理解『 我』的朋友，而且彼此之间相互支持。文中『 解放了禁锢在童年的枷锁』出现了两次。第一次是我将信交给伊凡的影子，伊凡所说，随后辞职。第二次是母亲去世后，伊凡给我留下母亲当年写的信时，我心里所想。看到一位知友说伊凡也有偷影子的能力。这也解释了为什么伊凡能知道父亲离开我这件事，而且似乎知道我偷影子的秘密。

主人公的形象感觉前后突兀。一开始以为主人公在班上被欺负，应该属于比较文弱、自卑的性格。但是为什么最后能胜任班长，而且几乎是全票当选。主人公有些时候显得很笨拙，比如父亲的地址不知道，和克蕾儿分别之后如果还喜欢她的话，为什么那么久不去那个小镇寻找，『 我』那么多年都没有想到过克蕾儿吗？ 最后去音乐学院连个人都不会找还得靠吕克。

全篇偷影子这个能力没有体现出更多的作用，尤其是在后半段，可有可无。</code></pre>
]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
  </entry>
  <entry>
    <title>启功带你学书法-破除迷信</title>
    <url>/2022/07/05/%E6%9D%82%E8%B0%88/%E5%90%AF%E5%8A%9F%E7%BB%99%E4%BD%A0%E8%AE%B2%E4%B9%A6%E6%B3%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><pre><code>启功先生以破除迷信的思想贯穿全书，很实在，不故弄玄虚。扫清各种神秘的古怪学说为初学者造成的困惑和恐吓。</code></pre>
<span id="more"></span>
<h3 id="碑和帖">碑和帖</h3>
<pre><code>碑在《说文解字》中解释为「竖石也」。原本是坟墓面前的石头。后来逐渐扩展为活人也立碑，比如谁在此留下丰功伟绩。常常带有纪念意义，史学价值比较高，所以需要是大家共同认得的字。所以大部分时间里，碑都是以楷书为主要的，但是也有例外。比如武则天为张昌宗立碑，叫《升仙太子碑》，完全用草书写，成为草书写碑的开端。碑通常是书写者直接在碑上书写，是书写者与刻工的共同参与。

帖是字条，是平常生活中用来彼此传达信息的，是一种随意的书写，字体行草书偏多。刻帖要求还书写精神的原貌，需要先用墨迹摹写之后，再以字勾勒。</code></pre>
<h3 id="入门练习">入门练习</h3>
<pre><code>临帖和读帖同样重要，不能偏废。

临帖临碑时注意和现实中的用笔区别，再好的拓本也只能反映字的外形轮廓，里面墨色的浓淡、干湿、轻重的细节是丢失的。另外，有的石刻过于方正，是可能用排笔，板刷写出的，不用强求。</code></pre>
<h3 id="用笔">用笔</h3>
<blockquote>
<p>赵雪松云：“书法以用笔为上，而结字亦须用工”。窃以为不然。</p>
</blockquote>
<p>不可被用笔至上论所迷惑，以结字为先。</p>
<blockquote>
<p>无麻不成笔</p>
</blockquote>
<h3 id="选临碑帖">选临碑帖</h3>
<p>可以有自己的创造性，按照古代已有的方法去做，吸取最有效的部分，为我所用。</p>
<blockquote>
<p>名家之书，皆古人之妙处与自家之病处相结合耳。</p>
</blockquote>
<h3 id="悬腕之说">悬腕之说</h3>
<p>「悬腕」是宋初以后的说法，宋代以前，没有高桌椅，都是席地而坐，因此没有地方能够搁放自己的手腕和手肘，显得用笔灵活，上下左右，提按自如。但是如今在高桌椅上写<strong>小字</strong>的时候，如果强行悬腕，反而右臂僵硬，无法运用臂力。</p>
<h3 id="求人不如求己">求人不如求己</h3>
<blockquote>
<p>文章千古事，得失寸心知</p>
</blockquote>
<p>意思是做文章是千古的事情，有失有得，只有自家知道。</p>
<p>书中有一个方法：把自己认为写的好的贴在墙上，过几天再瞧，就觉得很惭愧了，然后再修改，自己就明白了。</p>
]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
  </entry>
  <entry>
    <title>大理火把节来历</title>
    <url>/2022/08/01/%E6%9D%82%E8%B0%88/%E5%A4%A7%E7%90%86%E7%81%AB%E6%8A%8A%E8%8A%82%E6%9D%A5%E5%8E%86/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>普遍流传火烧松明楼的故事缺乏证据。该说法大概在明清时期广泛为人接受。如清代学者</p>
<p>师范曾在《滇系·杂载》中总结出以下几点：</p>
<ol type="1">
<li>火把节即星回节</li>
<li>起源一：武侯征南，于是日擒孟获，侵夜入城，城中父老设庭燎以迎之</li>
<li>起源二：纪念曼阿奴之妻阿南，焚夫衣后横刀自断。</li>
<li><strong>起源三：火烧松明楼，纪念慈善夫人（也称柏洁夫人），此最为广传的一种。</strong></li>
</ol>
<p>但元明清常常流传着很多关于大理白族火把节的记载与南诏时期不符。比如南诏时期，《太平广记》中引南诏王诗文《星回节游避风台与清平官赋》:</p>
<blockquote>
<p>避风善阐台,极目见藤越,悲哉古与今,依然烟与月。自我居震旦,翊卫类夔契。伊昔颈皇运,艰难仰忠烈。不觉岁云暮,感极星回节。元昶同一心,子孙堪贻厥。</p>
</blockquote>
<p>从「岁云暮」应该看出星回节应该位于年末，而火把节位于六月二十五，二者应该是两个节日。但是在明清的记载中大多将二者混为一谈。</p>
<p>因此，《火烧松明楼》作为白族火把节的起源这一说法，应该只是穿凿附会之说。</p>
<p>尽管如此，纪念柏洁夫人已然作为节日庆祝的主要载体。比如海东镇的赛龙舟与“捞尸会”，染手花（虽然已经不多见）与白洁夫人手刨火烧残余至十指染血有关，大理北门村和西门村等多地更是将“白洁夫人”奉为本主。</p>
<p>目前还有一种的说法是大理白族火把节其真正的象征源于男性的垄断生育。抢升斗的必须是新婚的男性，象征着得子。</p>
]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
  </entry>
  <entry>
    <title>火把节记录</title>
    <url>/2022/08/01/%E6%9D%82%E8%B0%88/%E7%81%AB%E6%8A%8A%E8%8A%82%E6%84%9F%E5%8F%97/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>大理白族的火把节在每年六月二十日，分为竖火把，点火，抢升斗，耍火把等环节，具有独特且浓郁的名族特色，也是白族最盛大的传统节日。</p>
<h2 id="竖火把">竖火把</h2>
<p>火把节的资金往往由村中的新生儿女的几户人家均摊。火把往往在本主庙院子里或者附近竖立，然后在竖立的挖坑以便插入。不同于彝族，白族火把节往往高竖火把，由松木制成。然后再旁边插上竹条和稻草等助燃。最后制作『升斗』，是由细木和彩纸糊成，旁边再插上旗子，共有三层，故曰『连升三级』，象征着婴儿的出世。</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202208012330672.png" alt="连升三级" /><figcaption aria-hidden="true">连升三级</figcaption>
</figure>
<h2 id="点火">点火</h2>
<p>火把节的操办具有地域性，每个村寨都有自己的本主庙，而所有村落按照本主庙划分为不同的「辖区」，每个区域都竖立自己单独的火把，火种必须从本主庙迎出来。</p>
<video src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202208012337426.mp4" title="南潘溪村迎火">
99
</video>
<p>然后将火把顶上的稻草引燃</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202208012350457.png" alt="南潘上登火把节" /><figcaption aria-hidden="true">南潘上登火把节</figcaption>
</figure>
<h2 id="抢升斗">抢升斗</h2>
<p>抢升斗的人选必须是刚婚的男性，抢下『连升三级』，祝愿着得子。</p>
<h2 id="耍火把">耍火把</h2>
<p>这应该是火把节最高潮和有趣的部分了。每家人挤在迎来的火种前引燃自己手中的火把，将火焰传递的温暖送入自家门中。</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202208012356921.png" alt="借火" /><figcaption aria-hidden="true">借火</figcaption>
</figure>
<p>纵然黑夜降临，但亲朋好友之间互相取火，将薪火不断传递，『万炬纵横，灿如星海』。正如同明代诗人杨慎笔下的『松炬荧荧宵作平』。</p>
<p><img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202208020001028.jpg" /></p>
<p><img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202208020107106.jpg" /></p>
<p>撒一把松明子，烈焰迸发，火光四射。</p>
<p><img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202208020009767.jpg" /></p>
<p>尽情挥舞手中的火把，让疾风为火焰注入生命力，让黑暗中染上绚丽炽红的轨迹。</p>
<p><img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202208020012250.jpg" /></p>
<p><img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202208020105980.jpg" /></p>
<p>火把上的大火直冲云霄，点亮一片天空。火星四溅，松木崩裂，感受到火炬内部有股强劲的生命力在迸发。</p>
<p><img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202208020021338.jpg" /></p>
<p>最终火把却被这股生命力反噬，仿佛英雄垂暮，摇摇欲坠，大厦将倾。</p>
<p><img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202208020024687.jpg" /></p>
<p>最终轰然倒塌，仿佛火山爆发，岩浆滚滚流淌而下，又如浴火重生。</p>
<p><img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202208020026118.jpg" /></p>
<p>火把节如同不断上演的光影艺术剧，绚丽多姿，多彩纷呈。白子们通过火焰的传递，传承苍洱间祖祖辈辈生活的土地。又如同一首苍老的山歌，遒劲有力，发自肺腑，全出于本性，没有丝毫扭捏造作。火焰的力量从火把的根部直顶头部，穿云裂石。舞动时，划过黑暗。这就是为何火把节象征着生育的根本吧。</p>
<p>欢迎各位来西南地区体会独特的风土人情。</p>
]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
  </entry>
  <entry>
    <title>甘南游记</title>
    <url>/2022/07/14/%E6%9D%82%E8%B0%88/%E7%94%98%E5%8D%97%E6%B8%B8%E8%AE%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="备冬草">备冬草</h2>
<p>于是乎直接沿着最快的线路，沿着京昆高速和兰海高速直抵舟曲县。随后沿着一条小路经过腊子口到达岷县。在路上遇到了牧民准备冬草。把收割的草晒在路沿上，然后在收起来打捆屯在冬天。准备冬草规模浩大，十分忙碌，大概就是农忙？草原气候，夏季多雨，草肥物盛，冬季雪灾，大雪也会覆盖在草场上，牛羊没有新鲜牧草可以吃，所以趁着牧草枯草前割掉一些，晒干后作为牛羊冬天的食物。</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202207142030421.jpg" alt="储备冬草" /><figcaption aria-hidden="true">储备冬草</figcaption>
</figure>
<h2 id="铁尺梁">铁尺梁</h2>
<pre><code>然后顺着蜿蜒的山路盘旋而上，到达险关腊子口，红军在此激战，突破了国民党军队的防线。可以沿着栈道顺着腊子河谷看到留下的碉堡。</code></pre>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202207142031021.jpg" alt="腊子口纪念碑" /><figcaption aria-hidden="true">腊子口纪念碑</figcaption>
</figure>
<h2 id="铁尺梁-1">铁尺梁</h2>
<pre><code>铁尺梁因如直立的铁尺而得名，众山之巅，诸神之上。无色经幡飘扬。可以俯瞰蜿蜒的盘山公路，散落在低谷的人家。平视可以看到叠锋隐约，错落有致，有个山峰形状酷似。据说毛泽东在此写下七律长征。</code></pre>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202207142034408.jpg" alt="酷似熊的山峰" /><figcaption aria-hidden="true">酷似熊的山峰</figcaption>
</figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202207142036607.jpg" alt="月亮与经幡" /><figcaption aria-hidden="true">月亮与经幡</figcaption>
</figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202207142038251.jpg" alt="成群的牛羊" /><figcaption aria-hidden="true">成群的牛羊</figcaption>
</figure>
<h2 id="达尔宗圣湖">达尔宗圣湖</h2>
]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
  </entry>
  <entry>
    <title>蛤蟆先生去看心理医生</title>
    <url>/2023/01/19/%E6%9D%82%E8%B0%88/%E8%9B%A4%E8%9F%86%E5%85%88%E7%94%9F%E5%8E%BB%E7%9C%8B%E5%BF%83%E7%90%86%E5%8C%BB%E7%94%9F/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><pre><code>讲述了一只抑郁的蛤蟆通过心理咨询，最终成长的故事。

一开始蛤蟆内心深处并非自己意愿。苍鹭告诉他只有当蛤蟆真正担起想要改变的责任的时候才能真正开始。心理咨询更像是一场“**合作**”来访者和咨询者的都需要同主动参与。

随后在谈话之中逐渐引入一些概念。虽然感觉没什么很特别的，但是当把这些概念联系到自身经历，又让人醍醐灌顶。以下是人面对事物的三种状态。

第一个是『 儿童自我状态』。人与生俱来的情感包括：开心、悲伤、愤怒、恐惧。 但是在成长过程中受到影响之后，这些基本的情感就会混合成各式各样的别的情绪和行为。这些影响又主要来源于父母。儿童无法离开父母，于是衍生不得不各种各样的行为是为了适应在家庭环境，顺从和取悦父母，**并不意味真正理解父母输出的价值观**。比如愤怒的方式，我也一度感觉自己不怎么生气。发现只是愤怒发泄的方式不同，我和蛤蟆一样往往就会怄气，会变得异常安静，从而减少攻击性。通常是在父母的权威之下做出的适应。

第二个是『 父母自我状态』。我们会表现地如同自己地父母，包括价值观和道德观，以此来审判某个人。但是每个人地运作方式又有不同。有的人审判别人，而我和蛤蟆会选择审判自己，谴责自己有罪。我常常在想：为什么我明明知道自己做的不对，就是不做出行动去改呢？我推测我的矛盾源自是父母自我状态和儿童自我状态的对抗。比如我明明知道我房间很乱，又不想去整理，然后开始责怪自己，责怪的声音源自于父母，此时我儿童的状态又出现了，作为儿童的天性，又很抵触听从父母的话，如此往复，所谓的**知道** 只是一种来自父母状态的假象，内心深处还是产生对不明所以的强迫的抵触情绪。

第三个是『 成人自我状态』。在这个状态下，我们能理性的合理行事，而不再被脑子里父母过去的声音所驱使，也不会被童年的情绪所围困。说实话，没看懂这个状态的来龙去脉。我把成人自我状态看作是自己真正通过知识和道理来掌控自己的状态，这些知识是自我真正理解和接受的。所以在小时候，父母去强迫施加的那些道理，比如生活上的一些琐事就难以进入状态中。因为从小时候起，这些道理就在自己儿童状态和父母状态中产生着矛盾，很难一下子化解。而像一些我从学校学习的新知识，我更自由地使用和应用它们，父母的声音不会在解数学题时响起。“不愤不启，不悱不发”，合理的引导，积极地思考获得的认知，使用时才会感到更自由和畅快。

最后是『 自证预言』。按照自己童年的观点，构建出一个世界。我们会控制事件的发生，来反复确认自己的信念，让世界和自己预想的一样。仿佛自己在上演一出剧本。具有不同人生坐标的人会有玩着不一样的游戏，如果和自己预想的一样，那么就取得胜利。比如 认为自己和差劲，别人都比他好的人，会玩让自己变成受害者的游戏，来印证自己是生活的受害者的认知。比如，有意的招惹别人，看别人能对自己宽容到什么程度，接着说：”我早说过你会这样对我，证明我是真的很差劲。“ 想起来真的很后怕，尊敬你和爱你的人都会备受伤害，甚至离你远去，最终孤苦伶仃，一个人。没错，达成了游戏的目的，赢了游戏，却输了人生。

读罢此书，蛤蟆怎么好起来的我还是不是不清楚，毕竟咨询的时间线是很长的，我顶多明白自己或者他人行为背后的一部分原因，但是怎么去改变还是一头雾水。</code></pre>
]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
  </entry>
  <entry>
    <title>赣行规划</title>
    <url>/2023/04/17/%E6%9D%82%E8%B0%88/%E8%B5%A3%E8%A1%8C%E8%A7%84%E5%88%92/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>江西地处中国东南部，它三面环山，庐山镇守北大门，北部平原坦荡，中部丘陵，盆地相间。数千条河流纵横交错，其中大部分汇入了鄱阳湖，从而与长江相连。</p>
<p><img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202304171943554.png" alt="image-20230417193555806" style="zoom:50%;" /></p>
<h1 id="五月一日">五月一日</h1>
<ol type="1">
<li><p>自上海出发乘高铁抵达玉山南站</p></li>
<li><p>玉山南站打车到汽车站，去三清山有两种班车，分别是去东部金沙和<strong>南部外双溪</strong>的，票价16元/人</p>
<p><img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202304171943466.png" alt="image-20230417194259736" style="zoom:50%;" /></p></li>
<li><p>票务费用: 学生票 185/人</p></li>
<li><p>从南门外双溪索道上山，到日上山庄放行李</p>
<p><img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202304180102939.png" alt="img" style="zoom:67%;" /></p></li>
</ol>
<h1 id="号">2号</h1>
<ol type="1">
<li>日出观景点在玉清台 里营地1h</li>
<li>中午，东门乘 <strong>金沙索道下山</strong>，乘坐班车到婺源（1.5h)</li>
<li>婺源到皇陵</li>
</ol>
<h1 id="号-返程">3号 返程</h1>
<ol type="1">
<li>在婺源悠闲地休息以下</li>
<li>下午四点返程</li>
</ol>
]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
  </entry>
  <entry>
    <title>镀金时代</title>
    <url>/2022/11/03/%E6%9D%82%E8%B0%88/%E9%95%80%E9%87%91%E6%97%B6%E4%BB%A3/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="第二次工业革命">第二次工业革命</h1>
<h2 id="工业经济">工业经济</h2>
<pre><code>从小农场的手工制造业转型为工业社会。“迅速彻底的革命”。五大湖，匹兹堡钢铁中心，原材料</code></pre>
<h2 id="铁路">铁路</h2>
<ol type="1">
<li>同一轨距</li>
<li>批量化生产，全国连锁店 全国性品牌</li>
</ol>
<h2 id="发明创造">发明创造</h2>
<ol type="1">
<li>爱迪生</li>
</ol>
<h2 id="竞争与合并">竞争与合并</h2>
<ol type="1">
<li>防止恶性竞争咯昂段</li>
</ol>
<h2 id="thomas-a.-scott">Thomas A. Scott</h2>
<ol type="1">
<li>慈善</li>
<li>集权方法，连轴转</li>
<li></li>
</ol>
<h2 id="工人自由">工人自由</h2>
<ol type="1">
<li>利益分配不均</li>
<li>少部分产业技术工人能经济独立：钢铁</li>
<li>半技术工人：操作机器，死亡率高</li>
<li>妇女恶劣的工作环境，“如同内战前一样”</li>
</ol>
<h2 id="阶级分化">阶级分化</h2>
<ol type="1">
<li>贫富差距</li>
</ol>
<h1 id="西部转型">西部转型</h1>
<p>资本主义流入 自然条件 美国文化的特别素质实在西部形成的，西部是安全阀门，将东部对自己不满的人吸引，从而抵消社会动乱。</p>
<h2 id="西进定居">西进定居</h2>
<p>农场主：东部出生本土，重建后南部逃离的黑人</p>
<h2 id="大型农场">大型农场</h2>
<p>主要仍然是家庭弄工厂</p>
<p>加州大型农场</p>
<h2 id="牛仔">牛仔</h2>
<p>牛群驱赶活动</p>
<ol type="1">
<li>西部城市人口比例高</li>
<li>矿山铁路</li>
</ol>
<h2 id="印第安人">印第安人</h2>
<ol type="1">
<li>摧毁伊甸人的经济基础</li>
<li>联邦军队与部落</li>
<li>文化打击</li>
<li><strong>道斯法</strong> ： 将印第安人土地分解，分配个家庭，剩余的出售</li>
<li>1924年赋予所有印第安人</li>
</ol>
<h1 id="政治">政治</h1>
<p>Mark Twain</p>
<h2 id="政治腐败">政治腐败</h2>
<p>大股份公司</p>
<p><strong>腐败政治机器</strong></p>
<p>共和党：控制工业化北部，中西部，西部</p>
<p>政治僵局时代，</p>
<h2 id="政府与经济">政府与经济</h2>
<ol type="1">
<li>联邦权力小</li>
<li>政党被利益集团控制，共和当坚持高关税，保护美国工业</li>
<li>金本控制</li>
</ol>
<h2 id="改革立法">改革立法</h2>
<ol type="1">
<li>文官改革法 竞争性考试</li>
<li>ICC 保障为农场主所收费用合理</li>
</ol>
<h2 id="州政治冲突">州政治冲突</h2>
<h1 id="镀金时代的自由">镀金时代的自由</h1>
<ol type="1">
<li>劳工关系</li>
<li>达尔文 契约自由</li>
</ol>
<h1 id="劳工与共和国">劳工与共和国</h1>
<ol type="1">
<li>铁路大罢工</li>
<li>改革者堆小生产时代的的怀旧，</li>
<li>劳工运动</li>
</ol>
<h2 id="贝拉米乌托邦">贝拉米乌托邦</h2>
<ol type="1">
<li>社会主义《合作社会》</li>
</ol>
<h2 id="劳工与政治">劳工与政治</h2>
]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
  </entry>
  <entry>
    <title>隔离日记</title>
    <url>/2022/12/23/%E6%9D%82%E8%B0%88/%E9%9A%94%E7%A6%BB%E6%97%A5%E8%AE%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="day0-day1">Day0 &amp; Day1</h1>
<p>21日开始发低烧，感觉自己可能要阳了，但是抗原测出来的结果都没有明显的T线。自己可能终究要为自己的自负付出代价了吧。为了让自己可能的阳性对大家来讲没有那么突然，于是开始跟猫和室友不断说我铁定阳了，我想这样提前预告也许能缓和自己内心的害怕和别人的冷眼吧，但内心总是怀着没阳的侥幸。就如同考试后无论好坏总会跟别人大肆宣扬自己考的多么多么差，但内心却依旧不相信，只是通过这种方式能缓解出分时的失望。然后又把刚拿的体温计摔了，就变得十分暴躁，然后zll又让我填那个信息，让我现在去1号楼，我也是神志不清，别人叫我去我就去了。但是当时感觉挺委屈的，大晚上都没什么准备就让我离开寝室，另一方面又害怕自己万一真阳了也对室友不太好。路上突然发现自己也拿捏不准一号楼的位置，只能凭着感觉走。到了一号楼下，望着上面灯光，我环顾了一下其他楼，好像亮的灯都差不多，估计里面应该是人满为患了吧。门口坐着一个穿防护服的人，我便确信的向着门走去，报了一下名字，拿上睡袋和水瓶就上楼了。到了1311门口，敲门许久，终于有人开门了。我走了进去，进去的一瞬间，我有点绝望，好像突然才意识到，我已经出不去了，无论是否感染与否，都会阳。但是进来之后发现寝室十分宽敞和亮堂，况且室友也是非常好，性格也很开朗，也很爱干净。我突然对住在这里感到有一丝兴奋，舒适的环境，新的室友。跟心中所想也有反差，原来，充满病毒的地方并不可怕，人还是可以在这里很好的生活，反倒是外面所谓安全之处，充满着被感染和感染的担忧，不知道自己阳没阳的不确定性，带着薄薄的口罩假装防护。我摘下口罩畅快地大口呼吸，一天焦躁地神经也松弛下来，心情也变得轻快起来。第一天晚上睡得睡袋感觉也非常的新奇，虽然有点小，而且头不怎么好放，最好就在头下面垫裤子，感觉好多了。</p>
<p>第二天发现突然没有烧了，很高兴，觉得自己是新冠免疫者。还就受到猫咪的物资和被子，很感动，很后悔晚上对她发气，呜呜，其实这件事就是我的自负罢了。虽然没有发烧但是起来之后一直流鼻涕，脑子有点糊涂，就这么磨磨蹭蹭的改了一天的论文。下午三点做了核酸之后还在很盼望自己能阴性，心里居然还有这样的侥幸心理。晚上猫咪胃疼，本来应该好好照顾她的，不能陪在身边就应该，多说点话，但是我就是不知道说什么东西。反倒是猫讲了个小兔子的故事，小兔子一开始怎么也卖不出柠檬汁，于是他把自己最喜欢的毛绒玩具拿出来说谁买柠檬汁，谁就能玩毛绒玩具，然后有个小狮子走过来买走了柠檬汁，rua了小兔子一把。然后大家发现小兔子是可以rua的，于是大家就都来买柠檬汁然后rua小兔子。最后小兔子被老奶奶买走了。</p>
<h1 id="day2">Day2</h1>
<p>今天起床和昨天也差不多，也没什么很重的症状。因为室友要早上模拟考，于是早上多躺了一会儿，《天黑以后》看了一半，感觉第二遍读还是没怎么看懂，那个白领程序员那副体面的样子还是挺典型的。下午和晚上又改了一下美国史论文，Brett 一直强调 topic 是美国最重要的时期但是大部分时代之间根本就不是同一个主题，演进的方向也有区别，很难去直接比较谁更重要，彼此之间都是有依赖关系的，那怎么说最重要的难道不得追溯到地球诞生起？ 所以这个 topic 就有问题。然后还老是让我多引用 primary source, 但是教材里那么一大段话放进去字数不就轻松就超过了，我还写什么。 然后晚上有点头晕，但是洗个澡之后瞬间就好了，估计是长期久坐导致血液循环不畅。多起来活动一下。</p>
<pre><code>睡前故事：从前有一只漂亮小鸭子，大家都觉得他是一只天鹅，于是小鸭子也觉得自己是一只天鹅，于是他从小就跟一群小天鹅一起学习和生活，前几年他依然没大家公认是最棒的小鸭子，都对他寄予厚望，小鸭子也很对此很骄傲，甚至有些傲慢，瞧不起身边其他的小天鹅。然后想不出来了</code></pre>
<h1 id="day3">Day3</h1>
<p>今天棋来神清气爽。本以为晚上可能严重但是没有，鼻涕也没有了，也不怎么咳嗽。完全回到两天前的状态，应该是完全好了。看了会儿小马，下午物理一开始有点看不进去，好几天没学了，然后热学那一堆公式也没怎么理清楚，没理解到主线是什么。晚上玩了一下 goose goose duck 游戏，不适合我这种社恐人，但还是可以作为机会锻炼一下。这个隔离日记本来想着是记录一下得了新冠之后的心路历程和症状的，结果出乎意料的好的很快，感觉可以结帖了。</p>
<h1 id="day4">Day4</h1>
<p>今天还是状态挺好，很高兴的是我的23号的核酸居然阴性！那天我晚上我还感觉有点发烧，简直是奇迹。也就是说，我21号晚上住进去，22号核酸阳性，然后23号就阴了。走了一个室友，要是在做一次核酸是阴性就可以出去了，我实在没料到好的这么快，而且没什么痛苦，感觉可以吹一辈子。今天上午还有抗原还是有一点点T线，于是下午漱了口再去做的核酸，然后她桶的有点认真，感觉有点悬。然后猫大老远从图书观出来看我，好久没看猫了，恍如隔世。感觉我自己还是有点危险，然后就匆匆回去了。</p>
<h1 id="day5">Day5</h1>
<p>今天猫和室友都有点发烧，我感觉有点不妙。但是好消息是我的核酸居然有阴了，成功出狱。结果那个比我早来几天的室友的又复阳了，感觉自己还是很幸运的。结帖！！！</p>
]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
  </entry>
  <entry>
    <title>面纱</title>
    <url>/2023/02/09/%E6%9D%82%E8%B0%88/%E9%9D%A2%E7%BA%B1/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><pre><code>正如书名,本书中人们的关系都存在着一层若隐若现的面纱，有时彼此之间都明白，或许只有一方明白。究竟是戳破笼罩彼此的面纱，还是保持现状，寻求新的出路？

对于沃尔特来讲，在一开始，沃尔特想竭力地隐瞒自己所谓的智慧，让凯蒂觉得自己很蠢，这就是他最初地面纱。但个人认为沃尔特是全篇看似智慧，其实才是真正最愚蠢的人。首先沃尔特如果真的早就看透凯蒂，就不应该和她结婚，即使自己多么爱她。在与凯蒂相处中，总是沉默，好像在隐藏自己的情绪，还给凯蒂一种可怕的感觉，不愿沟通。吵个架都是都是不动声色，一点人情味都没有。很不喜欢和那种输了棋之后一点垂头丧气的表现都没有。他的自我意识过于强烈，他的爱显得很自私。就像一句话说得：『 我爱你，与你无关。』这怎么可能，你的爱肯定会把别人卷进你自己自导自演的那出戏之中，摆出一副运筹帷幄、居高临下的模样，接着露出那幅嘲讽而又鄙视的神情说：『 我知道你愚蠢、轻浮、无知，可我爱你。』凯蒂问他为什么不直接揍查理一顿，他说自己『 自视清高，不屑动武』。不屑动武的结果就是最后想带着爱的人去送死？沃尔特其实的情感很强烈，他愤怒，并且伤心欲绝，但是他偏偏就是嘴上说自己不在乎，因为自己『 清高』的自尊，最后压抑的情感把自己逼疯了，生着闷气一同去赴死。一开始他到底想让先谁去死，按照自导自演的心理，说不定原本想让自己死，看下凯蒂的反应，他就可以临死前用自己的高尚反衬她的轻浮，或者让她内疚。最终他在凯蒂怀孕的时候还是反悔毕竟还是有人的情感，坦白了自己一开始是想让置凯蒂于死地，并执意让凯蒂离开。但是他估计千算万算没想到凯蒂在修道院变了，变得不在轻浮，他已经丢失了鄙视凯蒂的资本。反观沃尔特，根据沃尔丁的说法，他并不是冲在前线的医生，而是作为细菌学家的身份做实验，文中也没有直接描写沃尔特是如何工作的，其实他比凯蒂更安全。 他真的没想到，结果完全反过来了，自己是有不纯动机的，而凯蒂变成那首挽歌里的大善人，自己本质还是一条咬人的疯狗，一只鄙视自己爱的人的疯狗。而他的死究竟是意外感染，还是自己故意感染，我更偏向后者。

凯蒂算是全书里面能最好理解的一个『 正常人』。因为是主人公，所以内心独白是最多的，比较好看清她的心理路程。简单的着急，于是匆匆结婚，之后爱上了风流的查理，被查理所骗。故事的转折在凯蒂在修道院见到高尚的修女以及庄严、和蔼可亲的院长时，她逐渐意识到自己的浅薄和愚蠢。在疫情肆虐的地方还想着男女之事。修女们在这片修道院中展现出的欢乐，对待困苦的超然，庄严肃穆的亲切，自我奉献的辛福，让凯蒂觉得自己被这篇神秘的精神乐园拒之门外，而这正是她渴望的幸福，也就是所谓的『 道』。在这种精神的鼓舞下，凯蒂开始到修道院帮忙照顾孩子们，我想这也是沃尔特万万没想到的。修女对自己的丈夫称赞不绝，她也承认自己的沃尔特拥有着非凡的品质，而反观查理汤森，却是一个品质平庸的普通人。尽管她仍然不爱沃尔特，知道自己永远不会爱他，但他希望能与他和解，希望他能原谅她，至少成为朋友的关系。怀孕是一次和解的机会，她本来可以撒谎说，这是他的孩子。但是此时的她觉得撒谎不值得，回答：“我不知道”。凯蒂是个感性的人，只是不爱沃尔特罢了，但她同情，理解沃尔特，并为他的死去感到痛苦和后悔。在知道沃尔特可能拿因为是自杀感染死去时，她辩护道：『 沃尔特是因为心碎才死的。』 当凯蒂回到香港后，她的理智告诉汤森是个卑鄙的小人，但是他对汤森的爱欲还是不可避免的复燃了。在懊丧和怨恨的孤独之下，她终于离开了香港，回到了家中，母亲已经去世。

凯蒂的母亲是个虚荣、挑剔、专横、野心勃勃的人，对父亲也是严加管教，父亲在家里毫无地位，甚至因为无法为家人提供更奢华的生活而瞧不起。看似父亲是个忠诚的好丈夫，但是横亘在父亲和妻女之间的面纱是父亲的苦难和冷漠的隔阂。而这面纱被母亲的离世揭开了。父亲永远解脱了，他得到了自由，崭新的生活在他面前展开。他在也不用拼命工作而养活儿女，可以放手去追逐自己想要的『 道』。但，当凯蒂问他：『 我不能和你一起去吗？』。他屈服于自己的责任感，放弃了自己的全部希望，表示乐意和凯蒂一同生活。这是全书最令人动容的时刻，体现出父亲的伟大之处。随后在理解对方的苦楚之后，他们彼此相拥，双方都感受到骨肉之亲真正的温暖，这才是他们两个真正追求的『 道』。是本书唯一消融与和解的『 面纱』，也是全篇的结束。</code></pre>
]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
  </entry>
  <entry>
    <title>NeRF细节整理</title>
    <url>/2022/10/14/%E7%A7%91%E5%AD%A6/NeRF%E7%B2%BE%E8%AF%BB/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="download-from-google-driver">Download from Google driver</h1>
<p>Use the Wget command:</p>
<p>小文件</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget --no-check-certificate <span class="string">&quot;https://drive.google.com/uc?export=download&amp;id=<span class="variable">$&#123;Fileid&#125;</span>&quot;</span> -O <span class="string">&quot;<span class="variable">$&#123;Filename&#125;</span>&quot;</span></span><br></pre></td></tr></table></figure>
<p>大文件</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget --load-cookies /tmp/cookies.txt <span class="string">&quot;https://drive.google.com/uc?export=download&amp;confirm=<span class="subst">$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate &#x27;https://drive.google.com/uc?export=download&amp;id=$&#123;fileid&#125;&#x27; -O- | sed -rn &#x27;s/.confirm=([0-9A-Za-z_]+)</span>./\1\n/p&#x27;)&amp;id=<span class="variable">$&#123;fileid&#125;</span>&quot;</span> -O <span class="variable">$&#123;filename&#125;</span> &amp;&amp; <span class="built_in">rm</span> -rf /tmp/cookies.txt</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>解压</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">unzip <span class="variable">$&#123;filename&#125;</span></span><br></pre></td></tr></table></figure>
<h1 id="ndc-ray-space-derivation">NDC ray space derivation</h1>
<p>论文中的内参矩阵里的 <span class="math inline">\(n,f\)</span> ：the near and far clipping planes and <span class="math inline">\(r,t\)</span> are the right and top bounds scene at the near clipping plane. 所以 <span class="math inline">\(\frac{r}{t}=\)</span> Aspect ratio (屏幕高宽比)</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202210140206585.png" alt="A perspective camera" /><figcaption aria-hidden="true">A perspective camera</figcaption>
</figure>
<h2 id="ndc">NDC</h2>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202210140217293.png" alt="归一化" /><figcaption aria-hidden="true">归一化</figcaption>
</figure>
]]></content>
      <categories>
        <category>科学</category>
      </categories>
      <tags>
        <tag>NeRF</tag>
      </tags>
  </entry>
  <entry>
    <title>黔行山水间</title>
    <url>/2022/09/22/%E6%9D%82%E8%B0%88/%E9%BB%94%E8%A1%8C%E5%B1%B1%E6%B0%B4%E9%97%B4/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><pre><code>贵州，中国唯一没有平原支撑的省份，群山环绕，数千条河流将其塑造为喀斯特岩溶地貌的王国。大量的山林河谷让这片土地充斥着浓郁的神秘气息。我于是怀着敬畏和些许的恐惧抵达了贵阳。

贵阳的交通是立体的。坐车身在其中，各条道路在眼前不断地交织绕的人晕头转向，难辨东西。黔灵山公园的猕猴让人有些期待，在公园里跋涉许久才终于看到两只猕猴间互相厮杀，其中一只差点失足从屋檐下掉落，令人捏一把汗。又行了几步，终于发现一群猕猴，哦，不，应该是一群强盗吧。幸亏身上没带食物，否则肯定被哄抢的一干二净。在甲秀楼溜达完后，然后再附近找了家餐馆，叫“雷家圆子”，就是用豆腐做的油炸圆子，配上其特有的调料，口感外脆内嫩，味道鲜美，算是特色小吃吧。

饭后到高铁站后与社会实践团队会合，大家神态不一，有的社交达人如鱼得水和旁人侃侃而谈，也有的社恐面露羞涩，一言不发。我显然属于后者，所以高铁路上一直假装睡觉，害怕与旁边的组员交谈。我想，以后会有机会和大家熟悉的，也不必过多担心。

在六盘水经过一晚的修整，来到了本次调研的第一站：水城古镇。这里坐落着一个三线博物馆，纪念的是西南三线建设的历史。沿路的房屋墙壁上都有显赫的那个时代的标语。“人亲堪比阶级爱”，“好人好马上三线”，“为人民服务”等等。参观了博物馆后，知道三线建设是上世纪我国的重大军事战略计划，对西南地区的现代工业化起到了积极的推动作用。让人感到有趣的是一个手动的防空警报器，但是却被工人们用作闹钟，同学们开始疯狂转警报器，空厅传响，整个博物馆瞬间弥漫着一种紧张的备战氛围，霎时间回到那段峥嵘岁月。之后我们便开始在水城古镇进行街头访谈，收获颇丰。突然天空下起大雨，我于是坐在伞下和一个来自广东的游客聊了一下关于三线的问题，谈到当时韶关是广东的三线建设的重点，当时的备战气氛其实非常紧张，很多工业，和技术人员都从东部比如上海等地迁往西部。然后我们小组向一个小卖部的老板考察了水城古镇的历史。在这里未开发以前，这里基本都是住宅区，都用的自己的房子做点小生意，后来政府为了开发古镇景区拆迁了旧的房屋，但是没有给足相应的补贴，如今又向这里的摊位收取较为高昂的租金，这里百姓对此忿忿不平。听到这些话，我感到有些唏嘘。但是我们又采访了一位烙锅店的左氏老板，她对此的看法却又截然不同。她从小生活在水城，她母亲曾经是在路边做烙豆腐的。她对景区的开发持非常积极的态度，街道变得更加整洁了，社会环境和治安也有了很大改善，比如之前女孩子从来不敢走夜路，如今她也不会担心走夜路，游客更多使得生意更加兴隆。我想，之所以产生不同看法的原因是从不同的方面看待水城的变迁。政府在协调拆迁问题时确实存在着过失，百姓原本的生产经营方式突然改变，又缺乏补贴，引起了一部分原本生意蒸蒸日上的商家的忿怨。而后面采访的这位，较为年轻的老板更关注于变迁带来的好的环境改变。尽管如此，政府也应该更多的考虑和协调百姓的不满。然后晚上也品尝了水城的特色小吃—烙锅。用土砂锅烙烤食物，蘸一下辣椒面，香辣爽口，油而不腻。只是有点难以控制火候大小，容易热油飞溅，还是略微有些危险。

第二天从六盘水前往久负盛名的黄果树瀑布，作为最大的瀑布群。做观光车的一路上都能看到一些小型的瀑布。离大瀑布的远近不同，感受也不同。从远处看去，夹在两山之间，激起的云雾在山谷中升腾，是秀美。而逐渐走进后，一下多了一个感官维度--触觉。激荡的水珠在脸上胡乱地拍打，心中升起阵阵凉意，耳边隆隆，水风忽忽，闭上双眼依然能感到震撼。更神奇的事，瀑布的背后，隐藏着一条溶洞，如同西游记里地水帘洞，从背面这个角度观飞瀑实属新奇，飞落地水花出奇的白，仿佛瀑布化身成了雪崩。不得不再一次感叹大自然的鬼斧神工。除了壮阔的黄果树瀑布，还有秀美的银链坠潭瀑布。其落差不大，潭沿面凸起的石面，像一片片莲叶一般，静谧而柔美地流泻如同绸缎。不知这些水滴从高处坠落时是否感到害怕，分明刚刚还在水平如面镜的水流中缓缓流淌，下一刻便倏忽间从平滑的水面坠落倾泻而下，让我不免后怕坐在飞机上的失重感

第三天终于有实操环节了--摘刺梨。之前喝过名叫“刺柠吉”的饮料，印象中爽口。可是当亲眼看到刺梨时，浑身是刺的它似乎并不那么友好，令人不知从哪里下嘴，终于忍住牙床的刺痛艰难咬下一口时，一股酸涩令人倒吸一口气。看来刺梨的确不适合直接食用，难怪必须通过进一步加工才能除去它的酸涩味，以充分其清热爽口的优点。听完讲解后，我们便兴致勃勃地戴上手套下田采摘。这里的农田也是起伏不平，地面湿滑容易摔倒，下坡只能让旁边的玉米受苦了，一群人经过后，玉米全部都垂头丧气的倒了下来。刺梨一簇簇地挂在枝头，生熟让人难以判断，管他呢，权且当搞点小破坏。结果就发现用一层手套摘刺梨稍微一用力就能轻易地被戳穿，只得戴上两层手套，捏住刺梨之后使劲往一个方向转，就能轻易地摘下来了。大家都摘得热火朝天，尽管被刺的惨叫声此起彼伏，最后还是收获了半筐刺梨，半载而归。好心的村民想把刺梨送给我们，但是实在是苦于揣着兜里的麻烦，只得一再推却。

采摘刺梨的之后的一天，我们团队又调查了一家刺梨加工企业，参观了刺梨加工的生产线。了解到刺梨的营养价值很高，尤其是维C含量。又介绍了很多用刺梨作为原材料的产品，除了刺梨原浆，刺梨酒，还有用来解腻用的饮品，大家都仔细品尝了一番。并且与书亦烧仙草合作推出刺梨口味的奶茶。这是确凿的事实，后来从六盘水返回到贵阳的时候，我就在高铁站奶茶店喝到了这熟悉的味道，在喝到的第一口有些莫名感动。刺梨相貌本身不讨好，原本味道又有些苦涩，但是却能被人们坚持发掘价值，经过一系列加工与其他食材配合，最终能华丽蜕变为一种竞品在市场上销售，博得消费者的喜爱，实在是催人奋进。

还令人难以忘怀的就是乌蒙大草原。在海拔两千多米的高山间，竟然滋养出一片西南地区最大的天然草场。与平时所见一马平川的草原不同，乌蒙大草原不断给人遐想和未知期待。山丘起伏挡住了视线，让人一眼看不到全貌，越过眼前的小土坡也许就又能看见奔跑的羊群，抑或是听见阵阵牛羚，而稍微挪动脚步又能看到一只威风凛然的黄牛盘踞在下一个山头。长期在这样有趣的坡道行走，也丝毫不觉得疲惫，反倒妙趣横生。草原上还看到一群穿着布依族服饰的姑娘们围成一圈，随着音乐的节奏欢快的舞蹈，旁边的游客也逐渐加入这场草原盛会，其乐融融。我坐在草地上，和煦的风吹得我醉眼迷离，恍惚地看这片热闹的草地，人们与牛羊甚至骆驼结伴，风筝在白云间游走，山顶上徐徐旋转地大风车。这片深处群山腹地的草原就如同，尽管有些老套，但的确是贵州高原上的明珠。使生活在此的人们，能够在地无三尺平的贵州，在一片广阔的草地尽情撒欢，释放内心的烦闷，遥望连绵的草野。

另外，我在团队中负责视频后期，当然也承担了小部分的拍摄工作。我之前没有任何关于视频创作的经验，完全是从头学起。因为要和配合新闻稿做两个视频，时间非常紧迫。白天不仅坐车和拍摄非常辛苦，晚上还得紧张工作。为了呈现更好的效果，我一帧一帧的处理视频细节，一开始很不熟练，导致效率很低，还出现一堆问题，前几天不得不工作到凌晨2点。后面也感受到自己愈发熟练，效率也逐渐提高，过程虽然很辛苦，但是看到做出来的视频还是非常有成就感，并且学习了一项新的技能。与团队成员的协作共事，同甘共苦，让大家很快成为一个紧密的团体，不善言语的我也认识了很多新的好伙伴。

在这七天里，少不了车马困顿。“天下山峰何其多，唯有此处峰成林”。每个镇乡之间的都要绕行大量的山路。感觉贵州的建设实属不易。交通方面是一个难题，不过越来越多的高桥正在飞架，据统计，贵州桥梁数量达到20000多座，全世界排名100座桥梁当中，有80多座来自中国；这80多座大桥之中，就有一大半来自贵州。但是六盘水铁路线还是处于落后局面，基本靠六安一条线路，我认为如果毕节-六盘水能通铁路能加强黔西和四川的联系。大量山地加上云贵准静止锋带来长期阴雨的天气，制约了贵州的农业发展。除了少量优良的土地能种植猕猴桃等经济作物，而沿途看到的大部分作物还是玉米。尽管如此贵州有着丰富的旅游资源、多彩的民族文化，源远流长的酒文化。在我心中，贵州是一片神圣而又神秘的土地，不同于开阔、壮丽的西藏那样强烈宗教带来的神圣，恰恰相反，崎岖、起伏的峰林赋予贵州一股质朴、平易近人的灵气。在参观农民画时，无意听到苗族山歌，回声嘹亮，空灵婉转，仿佛一场与山灵的对话。我想以后我还会来到贵州，在此体味淡泊自得的生活态度，去追寻信奉神巫的山间传说，涤荡内心，直面自我。</code></pre>
]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
  </entry>
  <entry>
    <title>instant-ngp复现</title>
    <url>/2022/10/19/%E7%A7%91%E5%AD%A6/instant-ngp%E5%A4%8D%E7%8E%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="数据集准备">数据集准备</h1>
<p>数据结构如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-fox</span><br><span class="line">  -images</span><br><span class="line">  -transform.json</span><br></pre></td></tr></table></figure>
<p>通过 <code>scripts/colmap2nerf.py</code> 处理视频或者一序列的图像，图像应避免动态模糊和虚焦。对于大型场景可能训练几分钟来增加锐度</p>
<blockquote>
<p>锐度，即图像边缘对比度，在边缘部分增加白色和黑色边缘增加对比度</p>
</blockquote>
<p>经过 COLMAP 稀疏重建后在 <code>sphare/0</code> 下生成三个 <code>.txt</code> 文件。</p>
<h4 id="camera.txt">camera.txt</h4>
<p>包含相机内参</p>
<p>以下为实例</p>
<figure class="highlight txt"><table><tr><td class="code"><pre><span class="line"># Camera list with one line of data per camera:</span><br><span class="line">#   CAMERA_ID, MODEL, WIDTH, HEIGHT, PARAMS[]</span><br><span class="line"># Number of cameras: 159</span><br><span class="line">1 SIMPLE_RADIAL 1920 1080 1496.1000558533603 960 540 -0.022162590119422163</span><br><span class="line">2 SIMPLE_RADIAL 1920 1080 1487.0032035424961 960 540 0.020998321685288947</span><br></pre></td></tr></table></figure>
<ul>
<li><p>CAMERA_ID ：对应每张图片的序号</p></li>
<li><p>MODEL ： 相机的模型选择具体参考详见<span class="exturl" data-url="aHR0cHM6Ly9jb2xtYXAuZ2l0aHViLmlvL2NhbWVyYXMuaHRtbA==">官方文档<i class="fa fa-external-link-alt"></i></span></p>
<p>主要给出了几种建议, 无畸变时采用 simple model.</p>
<ol type="1">
<li><code>SIMPLE_PINHOLE</code> , <code>PINHOLE</code>: 小孔相机模型，在图像未畸变时使用，在此情况下，也可以通过更复杂的相机模型改进参数</li>
<li><code>SIMPLE_RADIAL</code> ：对于在内参都不知道的情况下，每张图像有不同的相机校准。e.g internet photos??(从网络获取的图片？)</li>
<li><code>OPENCV</code> : 已知校准参数的情况下</li>
</ol>
<p><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2NvbG1hcC9jb2xtYXAvYmxvYi9tYXN0ZXIvc3JjL2Jhc2UvY2FtZXJhX21vZGVscy5o">具体的每个模型的参数<i class="fa fa-external-link-alt"></i></span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">// Simple Pinhole camera model.</span><br><span class="line">//   f, cx, cy</span><br><span class="line">CAMERA_MODEL_DEFINITIONS(<span class="number">0</span>, <span class="string">&quot;SIMPLE_PINHOLE&quot;</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">// Pinhole camera model.</span><br><span class="line">//    fx, fy, cx, cy</span><br><span class="line">CAMERA_MODEL_DEFINITIONS(<span class="number">1</span>, <span class="string">&quot;PINHOLE&quot;</span>, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">// Simple camera model <span class="keyword">with</span> one focal length <span class="keyword">and</span> one radial distortion</span><br><span class="line">// parameter.</span><br><span class="line">//    f, cx, cy, k</span><br><span class="line">CAMERA_MODEL_DEFINITIONS(<span class="number">2</span>, <span class="string">&quot;SIMPLE_RADIAL&quot;</span>, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">// Simple camera model <span class="keyword">with</span> one focal length <span class="keyword">and</span> two radial distortion</span><br><span class="line">// parameters.</span><br><span class="line">//    f, cx, cy, k1, k2</span><br><span class="line">CAMERA_MODEL_DEFINITIONS(<span class="number">3</span>, <span class="string">&quot;RADIAL&quot;</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">// OpenCV camera model.</span><br><span class="line">//    fx, fy, cx, cy, k1, k2, p1, p2</span><br><span class="line">CAMERA_MODEL_DEFINITIONS(<span class="number">4</span>, <span class="string">&quot;OPENCV&quot;</span>, <span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">// OpenCV fish-eye camera model.</span><br><span class="line">//    fx, fy, cx, cy, k1, k2, k3, k4</span><br><span class="line">CAMERA_MODEL_DEFINITIONS(<span class="number">5</span>, <span class="string">&quot;OPENCV_FISHEYE&quot;</span>, <span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">// Full OpenCV camera model.</span><br><span class="line">//    fx, fy, cx, cy, k1, k2, p1, p2, k3, k4, k5, k6</span><br><span class="line">CAMERA_MODEL_DEFINITIONS(<span class="number">6</span>, <span class="string">&quot;FULL_OPENCV&quot;</span>, <span class="number">12</span>)</span><br><span class="line"></span><br><span class="line">// FOV camera model.</span><br><span class="line">//    fx, fy, cx, cy, omega</span><br><span class="line">CAMERA_MODEL_DEFINITIONS(<span class="number">7</span>, <span class="string">&quot;FOV&quot;</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">// Simple camera model <span class="keyword">with</span> one focal length <span class="keyword">and</span> one radial distortion</span><br><span class="line">// parameter, suitable <span class="keyword">for</span> fish-eye cameras.</span><br><span class="line">//    f, cx, cy, k</span><br><span class="line">CAMERA_MODEL_DEFINITIONS(<span class="number">8</span>, <span class="string">&quot;SIMPLE_RADIAL_FISHEYE&quot;</span>, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">// Simple camera model <span class="keyword">with</span> one focal length <span class="keyword">and</span> two radial distortion</span><br><span class="line">// parameters, suitable <span class="keyword">for</span> fish-eye cameras.</span><br><span class="line">//    f, cx, cy, k1, k2</span><br><span class="line">CAMERA_MODEL_DEFINITIONS(<span class="number">9</span>, <span class="string">&quot;RADIAL_FISHEYE&quot;</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">// Camera model <span class="keyword">with</span> radial <span class="keyword">and</span> tangential distortion coefficients <span class="keyword">and</span></span><br><span class="line">// additional coefficients accounting <span class="keyword">for</span> thin-prism distortion.</span><br><span class="line">//    fx, fy, cx, cy, k1, k2, p1, p2, k3, k4, sx1, sy1</span><br><span class="line">CAMERA_MODEL_DEFINITIONS(<span class="number">10</span>, <span class="string">&quot;THIN_PRISM_FISHEYE&quot;</span>, <span class="number">12</span>)</span><br></pre></td></tr></table></figure>
<h4 id="images.txt">images.txt</h4>
<p><code>images.txt</code> 示例：</p></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Image list with two lines of data per image:</span></span><br><span class="line"><span class="comment">#  IMAGE_ID, QW, QX, QY, QZ, TX, TY, TZ, CAMERA_ID, NAME</span></span><br><span class="line"><span class="comment">#  POINTS2D[] as (X, Y, POINT3D_ID)</span></span><br><span class="line"><span class="comment"># Number of images: 2, mean observations per image: 2</span></span><br><span class="line"><span class="number">1</span> <span class="number">0.851773</span> <span class="number">0.0165051</span> <span class="number">0.503764</span> -<span class="number">0.142941</span> -<span class="number">0.737434</span> <span class="number">1.02973</span> <span class="number">3.74354</span> <span class="number">1</span> P1180141.JPG</span><br><span class="line"><span class="number">2362.39</span> <span class="number">248.498</span> <span class="number">58396</span> <span class="number">1784.7</span> <span class="number">268.254</span> <span class="number">59027</span> <span class="number">1784.7</span> <span class="number">268.254</span> -<span class="number">1</span></span><br><span class="line"><span class="number">2</span> <span class="number">0.851773</span> <span class="number">0.0165051</span> <span class="number">0.503764</span> -<span class="number">0.142941</span> -<span class="number">0.737434</span> <span class="number">1.02973</span> <span class="number">3.74354</span> <span class="number">1</span> P1180142.JPG</span><br><span class="line"><span class="number">1190.83</span> <span class="number">663.957</span> <span class="number">23056</span> <span class="number">1258.77</span> <span class="number">640.354</span> <span class="number">59070</span></span><br></pre></td></tr></table></figure>
<pre><code>`Q` 表示的旋转的四个参数？与 `Eigen::Quaterniond `格式相同  `T` 表示平移参数。第二行表示一个特征点在图像中的二维坐标。</code></pre>
<h4 id="points3d.txt">points3D.txt</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 3D point list with one line of data per point:</span></span><br><span class="line"><span class="comment">#  POINT3D_ID, X, Y, Z, R, G, B, ERROR, TRACK[] as (IMAGE_ID, POINT2D_IDX)</span></span><br><span class="line"><span class="comment"># Number of points: 3, mean track length: 3.3334</span></span><br><span class="line"><span class="number">63390</span> <span class="number">1.67241</span> <span class="number">0.292931</span> <span class="number">0.609726</span> <span class="number">115</span> <span class="number">121</span> <span class="number">122</span> <span class="number">1.33927</span> <span class="number">16</span> <span class="number">6542</span> <span class="number">15</span> <span class="number">7345</span> <span class="number">6</span> <span class="number">6714</span> <span class="number">14</span> <span class="number">7227</span></span><br><span class="line"><span class="number">63376</span> <span class="number">2.01848</span> <span class="number">0.108877</span> -<span class="number">0.0260841</span> <span class="number">102</span> <span class="number">209</span> <span class="number">250</span> <span class="number">1.73449</span> <span class="number">16</span> <span class="number">6519</span> <span class="number">15</span> <span class="number">7322</span> <span class="number">14</span> <span class="number">7212</span> <span class="number">8</span> <span class="number">3991</span></span><br><span class="line"><span class="number">63371</span> <span class="number">1.71102</span> <span class="number">0.28566</span> <span class="number">0.53475</span> <span class="number">245</span> <span class="number">251</span> <span class="number">249</span> <span class="number">0.612829</span> <span class="number">118</span> <span class="number">4140</span> <span class="number">117</span> <span class="number">4473</span></span><br></pre></td></tr></table></figure>
<p>如果需要进一步 rectify, 可以把参数输入到 OpenCV 的 <strong>stereoRectify()</strong> 函数中，之后 <strong>initUndistortRectifyMap()</strong> , 最后使用 <strong>remap()</strong> 函数进行重映射 从而得到矫正的结果。</p>
<h2 id="transform.json">transform.json</h2>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="attr">&quot;camera_angle_x&quot;</span><span class="punctuation">:</span> <span class="number">1.2433395001651382</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;camera_angle_y&quot;</span><span class="punctuation">:</span> <span class="number">0.7661685246315253</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;fl_x&quot;</span><span class="punctuation">:</span> <span class="number">1339.9721836141384</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;fl_y&quot;</span><span class="punctuation">:</span> <span class="number">1339.9721836141384</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;k1&quot;</span><span class="punctuation">:</span> <span class="number">-0.021131598158465558</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;k2&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;p1&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;p2&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;cx&quot;</span><span class="punctuation">:</span> <span class="number">960.0</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;cy&quot;</span><span class="punctuation">:</span> <span class="number">540.0</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;w&quot;</span><span class="punctuation">:</span> <span class="number">1920.0</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;h&quot;</span><span class="punctuation">:</span> <span class="number">1080.0</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;aabb_scale&quot;</span><span class="punctuation">:</span> <span class="number">16</span><span class="punctuation">,</span></span><br></pre></td></tr></table></figure>
<p><code>camera_angle_x</code> 是 <code>angle_y = math.atan(h / (fl_y * 2)) * 2</code>，即光心到边缘的最大角度。</p>
<p><code>fl_x</code> 是相机的焦距大小，看了代码之后发现取的是最后一个图像得到的焦距，实际上在·<code>1300-1496</code>之间进行浮动，据通过手机厂商的数据发现是 <code>26.8mm</code> 等效焦距，实际焦距 <code>5.4mm</code> ??</p>
<h2 id="现有数据集">现有数据集</h2>
<p>Nerf: 将near plane 和 far plane 的空间转化成 NDC [-1,1]，渲染时光线只截用该空间中的。</p>
<p>ngp: 没有采用NDC， unit cube ? 似乎没什么影响， <code>aabb_scale</code> 的作用就是为了限制渲染范围。</p>
<h2 id="实验">实验</h2>
<ol type="1">
<li>对云雾的消除。推测原因：上方缺乏光线穿过，因此需要增加相机的视角。上中下 和 上。 如果我们增加相机上方视角更多的图片呢：预测应该不会有很大改善。</li>
<li>增加桌面的特征值</li>
<li>勾选 <code>train extrinces、</code> 等</li>
</ol>
]]></content>
      <categories>
        <category>科学</category>
      </categories>
      <tags>
        <tag>HTML</tag>
        <tag>NeRF</tag>
      </tags>
  </entry>
  <entry>
    <title>ngp代码阅读</title>
    <url>/2022/11/09/%E7%A7%91%E5%AD%A6/ngp%E4%BB%A3%E7%A0%81%E9%98%85%E8%AF%BB/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="implement">Implement</h1>
<p>具体的实现细节</p>
<h2 id="performance-vs-quality">Performance vs quality</h2>
<p>hash table 的大小<span class="math inline">\(T\)</span> 过大导致GPU内存不足。</p>
<p>经过实验取得 <span class="math inline">\(F=2,L=16\)</span></p>
<h2 id="implicit-hash-collision-resolution">Implicit hash collision resolution</h2>
<ol type="1">
<li>一对点不太可能同时在每一层都发生碰撞,而且 <span class="math inline">\(N_{min}\)</span> 保证不发生冲突</li>
<li>一对点对梯度的贡献是不同的,表面的点的影响更大</li>
<li>分辨率的分布是几何的, 分辨率越大的较少的选取</li>
</ol>
<h2 id="online-adaptivity">Online adaptivity</h2>
<p>如果输入 <span class="math inline">\(x\)</span> 的分布集中在一个小的区域,那么精细网格会更少的发生哈希冲突,能学习的更精确.</p>
<p><strong>Neural Radiance Caching</strong></p>
<h2 id="model-architecture">Model Architecture</h2>
<p>由两个 MLP 并联</p>
<ol type="1">
<li><p><strong>density MLP</strong>: maps encoded position <span class="math inline">\(enc(\bold{x},\theta)\)</span> to 16 outputs values ， <span class="math inline">\(\theta\)</span> is the encoding parameters</p></li>
<li><p><strong>color MLP</strong>:</p>
<p><strong>Input</strong></p>
<p>the 16 output values of the density MLP, and the view direction projected onto the first 16 coefficients of the spherical harmonics basis. This is a natural frequency encoding over unit vectors</p>
<p><strong>output:</strong></p>
<p>RGB color triplet.</p>
<p>sRGB: sigmoid activation</p>
<p>HDR: exponential activation</p>
<p>1-hidden-layer density MLP and a 2-hidden-layer color MLP, both 64 neurons wide.</p>
<h2 id="accelerated-ray-marching">Accelerated ray marching</h2>
<p>we concentrate samples near surfaces by maintaining an occupancy grid that coarsely marks empty vs. nonempty space.</p>
<h3 id="ray-marching-step-size-and-stopping">Ray Marching Step Size and Stopping</h3>
<ol type="1">
<li><strong>synthetic NeRF scenes:</strong> step size $t= /1024 $ in the unit cube <span class="math inline">\([0,1]^3\)</span></li>
<li><strong>Others</strong>: <span class="math inline">\(t\)</span> exponential growth, which means that the computation cost grows only logarithmically in scene diameter, with no perceivable loss of quality.</li>
<li>Stop ray marching and set the remaining contribution to zero as soon as the transmittance of the ray drops below a threshold</li>
</ol>
<h2 id="occupancy-grids">Occupancy Grids</h2>
<p>During ray marching, whenever a sample is to be placed according to the step size from the previous section, the sample is skipped if its grid cell’s bit is low. Which one of the 𝐾 grids is queried is determined by both the sample position x and the step size Δ𝑡: among the grids covering x, the finest one with cell side length larger than Δ𝑡 is queried.</p>
<p><em>update the occupancy grids</em>. a second set of grids that store full-precision floating density. update every 16 training steps.</p>
<h2 id="number-of-rays-versus-batch-size">Number of Rays Versus Batch size</h2>
<p>batch size = Samples per ray * Rays per batch</p>
<p><strong>Training from a larger number of rays, i.e. incorporating more viewpoint variation into the batch. </strong>Include as many rays as possible in batches of fixed size rather that building variable-size batches from a fixed ray count</p></li>
</ol>
<h1 id="input">Input</h1>
<ol type="1">
<li><p>load <code>config/base.json</code>: 包括 <code>loss</code>, <code>optimizer</code>, <code>encoding</code> 的超参等 <code>envmap</code>?</p></li>
<li><p><code>train</code></p></li>
<li><p><code>training_prep_nerf</code>: 每过16次迭代，更新occupancy grids.</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (m_training_step &lt; <span class="number">256</span>) &#123;</span><br><span class="line">		<span class="built_in">update_density_grid_nerf</span>(alpha, <span class="built_in">NERF_GRIDSIZE</span>()*<span class="built_in">NERF_GRIDSIZE</span>()*<span class="built_in">NERF_GRIDSIZE</span>()*n_cascades, <span class="number">0</span>, stream);</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">		<span class="built_in">update_density_grid_nerf</span>(alpha, <span class="built_in">NERF_GRIDSIZE</span>()*<span class="built_in">NERF_GRIDSIZE</span>()*<span class="built_in">NERF_GRIDSIZE</span>()/<span class="number">4</span>*n_cascades, <span class="built_in">NERF_GRIDSIZE</span>()*<span class="built_in">NERF_GRIDSIZE</span>()*<span class="built_in">NERF_GRIDSIZE</span>()/<span class="number">4</span>*n_cascades, stream);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p><code>train_nerf_step(uint32_t target_batch_size, Testbed::NerfCounters&amp; counters, cudaStream_t stream)</code>:</p></li>
<li><p><code>generate_training_samples_nerf</code></p></li>
</ol>
]]></content>
      <categories>
        <category>科学</category>
      </categories>
      <tags>
        <tag>NeRF</tag>
      </tags>
  </entry>
  <entry>
    <title>ngp背景重建</title>
    <url>/2022/10/23/%E7%A7%91%E5%AD%A6/ngp%E8%83%8C%E6%99%AF%E9%87%8D%E5%BB%BA/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="目的">目的</h1>
<p>探究影响背景重建的因素。</p>
<h1 id="推测因素">推测因素</h1>
<figure>
<img src="E:\instant-ngp\data\nerf\fs\fs.gif" alt="原始重建结果" /><figcaption aria-hidden="true">原始重建结果</figcaption>
</figure>
<ol type="1">
<li><strong>视角</strong> 在拍摄时由于俯拍绕物体一周，导致场景上方缺乏光线透过，于是在场景顶部产生云雾。</li>
<li><strong>距离</strong> 拍摄时绕物体一周的过程中，对于场景中的一个点，缺乏同一 <span class="math inline">\((\theta,\phi)\)</span> 的数据，导致体密度训练较差。</li>
<li><strong>背景特征</strong> 背景特征多，增加网络的复杂程度，是否导致网络更难学习。</li>
<li>训练 <strong>外参 曝光 畸变</strong></li>
</ol>
<h1 id="实验一">实验一</h1>
<h2 id="实验目的">实验目的</h2>
<p>探究相机拍摄视角对背景重建的影响</p>
<h2 id="实验条件">实验条件</h2>
<ol type="1">
<li><strong>同一场景</strong>，光照相同，背景相同</li>
<li><strong>相机参数</strong> ：同一相机 (Sony A6000), 镜头焦距 50mm，采用 A 挡拍摄 (F = 2.8) , 曝光补偿 +0.7，ISO: auto.</li>
<li><strong>数据量相同</strong>：每组实验的照片数量一致</li>
<li><strong>COLMAP 模型</strong>： <code>SIMPLE_RADIAL</code> 且 每张图像内参一致</li>
<li>未勾选 训练外参，曝光和畸变。</li>
</ol>
<h2 id="实验步骤">实验步骤</h2>
<ol type="1">
<li><p><strong>数据收集</strong>：绕物体分别在 上、中、下拍摄一圈。</p></li>
<li><p><strong>第一组</strong> ：对于从上方拍摄的视角提取 215 张图像。</p>
<p><strong>第二组</strong> ：上、中、下分别使用 60、60 、110张图像 并且筛掉一些模糊和虚焦的照片</p></li>
<li><p><strong>数据处理</strong>：使用COLMAP稀疏重建， <strong>每一组</strong>都总共有215张图像用于稀疏重建</p>
<p>第一组得到的相机内参：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Camera list with one line of data per camera:</span></span><br><span class="line"><span class="comment">#   CAMERA_ID, MODEL, WIDTH, HEIGHT, PARAMS[]</span></span><br><span class="line"><span class="comment"># Number of cameras: 1</span></span><br><span class="line"><span class="number">1</span> SIMPLE_RADIAL <span class="number">1920</span> <span class="number">1080</span> <span class="number">4090.2916176564518</span> <span class="number">960</span> <span class="number">540</span> <span class="number">0.348649511020239</span></span><br></pre></td></tr></table></figure>
<p>第二组得到的相机内参：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Camera list with one line of data per camera:</span></span><br><span class="line"><span class="comment">#   CAMERA_ID, MODEL, WIDTH, HEIGHT, PARAMS[]</span></span><br><span class="line"><span class="comment"># Number of cameras: 1</span></span><br><span class="line"><span class="number">1</span> SIMPLE_RADIAL <span class="number">1920</span> <span class="number">1080</span> <span class="number">4726.2638345804498</span> <span class="number">960</span> <span class="number">540</span> <span class="number">0.48132964624147656</span></span><br></pre></td></tr></table></figure></li>
<li><p><strong>NeRF 重建</strong> : <code>run.py</code> 两组实验相机沿着相同的轨迹 <code>base_cam.json</code>，导出渲染后的视频</p></li>
</ol>
<h2 id="实验结果">实验结果</h2>
<h4 id="第一组"><strong>第一组</strong></h4>
<p>背景渲染结果白色桌面为锥型</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202210241950980.png" alt="整体效果" /><figcaption aria-hidden="true">整体效果</figcaption>
</figure>
<video src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202210242027829.mp4" title="第一组">
99
</video>
<p>物体周围有明显的云雾环绕</p>
<h4 id="实验二">实验二</h4>
<video src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202210242031040.mp4" title="实验二">
99
</video>
<p>云雾分布有明显分层现象，上方云雾仍然为白色，中间云雾的一半视角出现绿色，而另一半云雾基本消除，下方圆桌形态较好重建，但桌面呈现透明。更多周围背景被重建（窗外绿树，栏杆，沙发等）</p>
<h2 id="结论">结论</h2>
<p>增加相机视角多样性明显减少物体周围的云雾</p>
<h2 id="不足">不足</h2>
<ol type="1">
<li>拍摄过程中虚焦导致不同视角的数据量有差别</li>
<li>不同视角拍摄时镜头与物体距离未保持一致</li>
</ol>
<h2 id="讨论">讨论</h2>
<ol type="1">
<li>网络倾向于在相机面前贴云雾，导致通常沿着相机轨迹产生云雾</li>
<li>室内一面造成的云雾少于窗外绿树形成的云雾。推测，室外场景不同变化小.</li>
<li>上方的云雾？</li>
</ol>
<h1 id="实验二-1">实验二</h1>
<h3 id="实验目的-1">实验目的</h3>
<p>背景纹理的复杂程度如何影响背景重建效果</p>
<h3 id="实验条件-1">实验条件</h3>
<ol type="1">
<li><strong>同一场景</strong>，光照相同，背景相同</li>
<li><strong>相机</strong>：同一实际拍摄</li>
<li><strong>数据量相同</strong>：每组实验的照片数量基本一致</li>
<li><strong>COLMAP 模型</strong>： <code>SIMPLE_RADIAL</code> 且选择内参 <code>share_for all images</code></li>
<li>未勾选 训练外参，曝光和畸变。</li>
</ol>
<h3 id="实验步骤-1">实验步骤</h3>
<ol type="1">
<li><p><strong>数据收集</strong>：绕物体在相似的角度分别在有格子纹理和空白桌面进行拍摄</p></li>
<li><p>各提取60张图像</p></li>
<li><p><strong>数据处理</strong>：使用COLMAP稀疏重建</p>
<p>空白桌面得到的相机内参：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Camera list with one line of data per camera:</span></span><br><span class="line"><span class="comment">#   CAMERA_ID, MODEL, WIDTH, HEIGHT, PARAMS[]</span></span><br><span class="line"><span class="comment"># Number of cameras: 1</span></span><br><span class="line"><span class="number">1</span> SIMPLE_RADIAL <span class="number">3840</span> <span class="number">2160</span> <span class="number">2928.591596486669</span> <span class="number">1920</span> <span class="number">1080</span> <span class="number">0.035193673608008569</span></span><br></pre></td></tr></table></figure>
<p>有纹理得到的相机内参：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Camera list with one line of data per camera:</span></span><br><span class="line"><span class="comment">#   CAMERA_ID, MODEL, WIDTH, HEIGHT, PARAMS[]</span></span><br><span class="line"><span class="comment"># Number of cameras: 1</span></span><br><span class="line"><span class="number">1</span> SIMPLE_RADIAL <span class="number">3840</span> <span class="number">2160</span> <span class="number">2929.642972834683</span> <span class="number">1920</span> <span class="number">1080</span> <span class="number">0.027481430175291963</span></span><br></pre></td></tr></table></figure></li>
<li><p><strong>NeRF 重建</strong> : <code>run.py</code> 两组实验相机沿着相同的轨迹 <code>base_cam.json</code>，导出渲染后的视频</p></li>
</ol>
<h3 id="实验结果-1">实验结果</h3>
<h4 id="有纹理组">有纹理组</h4>
<p>桌上的纹理较好重建</p>
<video src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202210261857883.mp4" title="第一组">
99
</video>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202210261912272.png" alt="image-20221026191200695" /><figcaption aria-hidden="true">image-20221026191200695</figcaption>
</figure>
<h4 id="空白桌面组">空白桌面组</h4>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202210261859279.png" alt="空白对照" /><figcaption aria-hidden="true">空白对照</figcaption>
</figure>
<p>空白组的桌面相比有纹理的会更加透明</p>
<h3 id="实验结论">实验结论</h3>
<ol type="1">
<li><p>纹理更多 COLMAP 更好的进行特征提取</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202210261918587.png" alt="image-20221026191811412" /><figcaption aria-hidden="true">image-20221026191811412</figcaption>
</figure></li>
</ol>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202211052223653.png" alt="image-20221026191914388" /><figcaption aria-hidden="true">image-20221026191914388</figcaption>
</figure>
<h2 id="实验三">实验三</h2>
<ol type="1">
<li><strong>Train extrinsic</strong>: propagates gradients back onto the camera parameters in order to minimize the loss (in this case by treating the cameras as rigid bodies with momentum and the loss gradients as impulses acting on them). This can fix slight inaccuracies in the poses from <code>transform.json</code>. If you're using COLMAP, this option only yields a small benefit as COLMAP is already quite accurate -- I'd leave it off for most scenes.</li>
<li><strong>Train distortion</strong>: learns a grid-based camera distortion model on top of the Open CV camera model parameterized in <code>transforms.json</code>. Again, COLMAP usually does a good enough job that you don't need this.</li>
<li><strong>Train exposure</strong>: learns to compensate for varying exposure levels of the training images. If you generate your own data, you should not use this and instead set your camera to fixed exposure</li>
<li><strong>extrinsic</strong>: 14073 steps ; 收敛时间 235s ; Loss: 0.000482(33.17dB)</li>
<li><strong>exposure</strong>: 7032 steps; 收敛时间 110s ; Loss: 0.000577 (32.39dB)</li>
<li><strong>disorder</strong>: 6374 steps ; 收敛时间：100s Loss 0.000606(32.17db)</li>
<li><strong>origin</strong>: 6214 steps ; 收敛时间 100s ; Loss : 000614 (32.12DB)</li>
</ol>
<video src="E:\instant-ngp\data\nerf\ex2\blank\origin.mp4" title="origin">
</video>
<video src="E:\instant-ngp\data\nerf\ex2\blank\extrinsic.mp4">
</video>
<video src="E:\instant-ngp\data\nerf\ex2\blank\exposure.mp4">
</video>
<video src="E:\instant-ngp\data\nerf\ex2\blank\disorder.mp4">
</video>
<h2 id="结论-1">结论</h2>
<ol type="1">
<li>勾选<strong>extrinsic</strong> 结果更加清晰，使头发上的云雾消失，并且训练速度变慢一倍左右。</li>
<li>勾选 <strong>exposure</strong> 使头发上的云雾消失。</li>
<li>勾选 <strong>disorder</strong> 使结果更加清晰。</li>
</ol>
]]></content>
      <categories>
        <category>科学</category>
      </categories>
      <tags>
        <tag>NeRF</tag>
      </tags>
  </entry>
  <entry>
    <title>Variable Bitrate Neural Fields</title>
    <url>/2022/12/14/%E7%A7%91%E5%AD%A6/Variable_Bitrate/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="motivation">Motivation</h1>
<ol type="1">
<li>压缩3D信息用于更高效的数据传输，和直播</li>
<li>传统Nerf 的问题：因为需要很大的网络对场景进行编码，很多光线，每个点都要过这个大网络，因此渲染慢。</li>
<li>feature grids: 每个顶点包含一个 feature vector. 任意一个点用插值的到特征。网络只需要对所有顶点进行编码, 网络减小，速度增加。但是储存的feature grids 占用的空间却比之前一个网络的多。</li>
<li>ngp: 每个顶点的坐标通过 hash 映射到一个 codebook 的 index 上。但是需要多层，每层的codebook也很大，最终的存储还是很大。</li>
</ol>
<h1 id="vq-feature-grids-with-learning">VQ feature grids with learning</h1>
<ol type="1">
<li>直接在顶点上储存 index 并学习</li>
<li>为了解决不可微的问题，使用 softmax 的技巧。 储存一系列浮点数，取max。<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202212141921446.png" alt="Vector quantized feaature grids with learning" /></li>
</ol>
]]></content>
      <categories>
        <category>科学</category>
      </categories>
      <tags>
        <tag>NeRF</tag>
      </tags>
  </entry>
  <entry>
    <title>一文搞懂字符编码</title>
    <url>/2022/06/27/%E7%A7%91%E5%AD%A6/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="字符集和编码">字符集和编码</h1>
<pre><code>字符集从字符到一个数字的映射。编码是一种规则，即如何将这个字符转变为二进制数。</code></pre>
<h2 id="ascll">ASCLL</h2>
<pre><code>计算机处理字符总是需要将其变为一个个 bit 所以最开始的字符集是[**ASCLL**](https://www.ascii-code.com/) 码，将不同的英文字母，数字，以及控制字符映射到 8-bits 中。一开始 ASCLL 码只用到了 0 - 127。后来新增加了扩展 ASCLL 码， 利用了 128 - 255 剩下的一半字符。当称为 ASCLL 集的时候作为一种字符集，ASCLL 码时，是一种编码规则。</code></pre>
<span id="more"></span>
<h2 id="gb">GB</h2>
<h3 id="gb-2312">GB 2312</h3>
<p>GB2312 是一种中文的字符集，分区管理， 共计 94 个区， 每个区含 94 个位，共8836 码位。 码位按照按照区，行，列一次决定，比如「侃」字在 57 区 0 行 9 列， 码位就是 5709，十六进制为 <code>0x39 0x09</code> 分别加上 <code>0xA0</code> 得到 <code>0xD9</code> 和 <code>0xA9</code> ，得到最终的 GB2312 为 <code>0xD90xA9</code> 。 加 <code>0xA0</code> 的目的可能使得高位和低位的值都大于 127， 向下兼容 ASCLL 码。当机器遇到连续两位大于 127 的 byte 时就能以此区分究竟是 ASCLL 码还是 GB2312 码。 GB2312 是双字节编码，为了与 ASCII 码区分开，字节的第8位必须是1，所以GB2312是8位编码。所以至少要从 0x80 128, 1000 0000) 开始吧，但是根据上面的规定，0x80 - 0x9f 要留给控制块，所以只能从 0xA0 开始咯。那为什么 GB2312 编码不是从 0xA0 开始，而是 0xA1 开始呢？ 因为 0xA0 正好是图形块的空格，所以就从 0xA1 编码，这就是 0xA0 的由来</p>
<h3 id="gbk">GBK</h3>
<pre><code>拓展，不规定低位大于 127 ，新增近 20000 个汉字符号。对应的字符编码叫 GBK 码</code></pre>
<h3 id="gb18030">GB18030</h3>
<pre><code>新增少数民族文字</code></pre>
<h2 id="unicode">Unicode</h2>
<pre><code>是一个规则，包含字符集和对应的编码规则。把世界上所有的字符放在一起。</code></pre>
<h3 id="ucs-2-字符集">UCS-2 字符集</h3>
<pre><code>`0x0000 - 0xFFFF` ，可表示 65536 个字符。这里只是一个字符集，并不算真正意义上的编码。</code></pre>
<h3 id="ucs-4-字符集">UCS-4 字符集</h3>
<pre><code>`0x00000000 - 0xFFFFFFFF` ， 可表示 43 亿字符。</code></pre>
<h3 id="缺点">缺点</h3>
<pre><code>储存空间过大</code></pre>
<h3 id="utf-8-编码">UTF-8 编码</h3>
<pre><code>每次传送 8 位 数字，而且可变长，节省流量和内存空间，是目前最广泛使用的编码规则</code></pre>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202206272300871.png" alt="image-20220627230028146" /><figcaption aria-hidden="true">image-20220627230028146</figcaption>
</figure>
<h2 id="编码的应用举例">编码的应用举例</h2>
<ul>
<li>在计算机内存中是使用 Unicode 字符集， 当进行文本编辑时保存之前时用的 Unicode 数据。但是当数据写入磁盘的时候就和操作系统有关了，Linux 下是 UTF-8，在 Windows 下使用 GBK 编码。 比如写入一个文本文件时， 使用 UTF-8 编码 ， 自然当打开文件时也应该默认使用 UTF-8 解码，在转为 Unicode 数据在内存里。 比如当使用 Python的<em>open( )</em> 函数时，是内存中的进程与磁盘的交互，而这个交互过程中的编码格式则是使用操作系统的默认编码（ Linux 为 utf-8，Windows 为 gbk）</li>
<li>而当编译器读取.py 文件时，需要将储存好的 Bytes 数据解码。Python 2 默认 ASCLL 码， 而Python 3 默认 UTF-8 编码。 所以当用 python 2 执行含有中文字符串的文件时会解码错误。于是在开头加行 <code>\#-*-coding:utf-8-*-</code></li>
</ul>
<h2 id="python-2">Python 2</h2>
<pre><code>编码过程：写的代码通过 utf-8 写入，再通过解释器将其 Bytes 转换为另外编码形式的的 Bytes, utf-8 向下兼容 ASCLL。</code></pre>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202206280008191.png" alt="image-20220628000845318" /><figcaption aria-hidden="true">image-20220628000845318</figcaption>
</figure>
<p>以上的数据都是以 bytes 形式存储的，在Python 2 中成为 str 类型。通过 <code>print repr(a)</code> 来查看内存中储存的形式。如果在字符串前面加上 u <code>str = u'你好'</code>，则 u 后面的字符串通过 Unicode 加载进内存。 这种类型称为为 Unicode</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202206280018694.png" alt="image-20220628001647028" /><figcaption aria-hidden="true">image-20220628001647028</figcaption>
</figure>
<h3 id="unicode-和-str-类型的转换">Unicode 和 str 类型的转换</h3>
<pre><code>其实 str 就是 Bytes ，就是将Unicode 进行编码后的到的结果。</code></pre>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202206280018560.png" alt="image-20220628001829089" /><figcaption aria-hidden="true">image-20220628001829089</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># coding : utf-8</span></span><br><span class="line"><span class="built_in">str</span> = <span class="string">&quot;你好&quot;</span></span><br><span class="line"><span class="built_in">print</span> <span class="built_in">str</span>.decode(<span class="string">&#x27;ascll&#x27;</span>) <span class="comment">#错误，ascll支持中文</span></span><br><span class="line"><span class="built_in">print</span> <span class="built_in">str</span>.decode(<span class="string">&#x27;utf-8&#x27;</span>) <span class="comment">#结果 你好</span></span><br><span class="line"><span class="built_in">print</span> <span class="built_in">str</span>.decode(<span class="string">&#x27;gb2312&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="python-3">Python 3</h3>
<p>默认以 Unicode 从硬盘中加载进内存。</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202206280024379.png" alt="image-20220628002447002" /><figcaption aria-hidden="true">image-20220628002447002</figcaption>
</figure>
<p>表示 bytes 内容， <code>str = b'你好'</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = <span class="string">&quot;你好&quot;</span></span><br><span class="line"><span class="built_in">print</span> a.encode(<span class="string">&#x27;ascll&#x27;</span>) <span class="comment">#错误 无法将中文编码为 ascll 码</span></span><br><span class="line"><span class="built_in">print</span> a.encode (<span class="string">&#x27;utf-8&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>将 Bytes 解码为 Unicode</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = <span class="string">b&#x27;\xe4\xbd\xa0&#x27;</span></span><br><span class="line"><span class="built_in">print</span> a.decode(<span class="string">&#x27;utf-8&#x27;</span>) <span class="comment">#输出 你</span></span><br></pre></td></tr></table></figure>
<h3 id="参考">参考</h3>
<p>https://www.bilibili.com/video/BV1XK4y1t7D4?share_source=copy_web</p>
]]></content>
      <categories>
        <category>科学</category>
      </categories>
  </entry>
  <entry>
    <title>Neus</title>
    <url>/2023/05/26/%E7%A7%91%E5%AD%A6/Neus/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="motivation">Motivation</h1>
<p>IDR: 无法处理深度图上的突变，需要 object mask 监督</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202305261755910.png" alt="image-20230526175549538" /><figcaption aria-hidden="true">image-20230526175549538</figcaption>
</figure>
<p>NeRF 优点： 体积渲染方法能够训练网络找到远处的表面来产生正确的场景表示</p>
<h1 id="method">Method</h1>
<p>we developed a novel volume rendering method to render images from the implicit SDF and minimize the difference between the rendered images and the input images</p>
<h2 id="rendering-procedure">Rendering Procedure</h2>
<h3 id="scene-representation">Scene representation</h3>
<p>物体表面 $SDF = 0 $</p>
<h3 id="s-density">S-density</h3>
<p>logistic density distribution, 标准差为 <span class="math inline">\(1/s\)</span> ,当网络收敛时, <span class="math inline">\(1/s\)</span> 收敛于 <span class="math inline">\(0\)</span>.</p>
<p><img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202305261804177.png" alt="image-20230526180401502" style="zoom: 67%;" /></p>
<h3 id="rendering">Rendering</h3>
<p><img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202305261809614.png" alt="image-20230526180958103" style="zoom:67%;" /></p>
<p>weight function <span class="math inline">\(w(t)\)</span></p>
<h3 id="requirements-on-weight-function">Requirements on weight function</h3>
<ol type="1">
<li><p><strong>Unbiased</strong> . Given a camera ray $p(t), w(t) $attains a locally maximal value at a surface intersection point $ p(t)$, <em>i.e.</em> with <span class="math inline">\(f(p(t)) = 0,\)</span> that is, the point $ p(t) $ is on the zero-level set of the <span class="math inline">\(SDF (x).\)</span></p>
<p>保证与SDF为０的采样点，贡献最大</p></li>
<li><p><strong>Occlusion-aware</strong>.(遮挡的识别和处理) Given any two depth values $t0 $ and $t1 $ satisfying <span class="math inline">\(f(t0) = f(t1), w(t0) &gt; 0, w(t1) &gt; 0\)</span>, and, $ t0 &lt; t1$, there is $ w(t0) &gt; w(t1)$. That is, when two points have the same SDF value (thus the same SDF-induced S-density value), the point nearer to the view point should have a larger contribution to the final output color than does the other point.</p>
<p>距离相机越近的采样点贡献越大　（SDF相同的情况下）</p>
<h4 id="naive-solution">Naive solution</h4>
<p><code>&lt;img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202305261819723.png" alt="image-20230526181920993" style="zoom:67%;" /&gt;</code></p></li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202305261819916.png" alt="image-20230526181947212" style="zoom:67%;" /></p>
<p><img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202305261848805.png" alt="image-20230526184750903" style="zoom: 67%;" /></p>
<h4 id="our-solution">Our solution</h4>
<pre><code>`&lt;img src=&quot;https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202305261849307.png&quot; alt=&quot;image-20230526184949149&quot; style=&quot;zoom:67%;&quot; /&gt;`</code></pre>
<p>Unbiased but not occulusion-aware. 当光线穿过两个平面时, SDF函数 <span class="math inline">\(f\)</span> 有两个零点,导致 <span class="math inline">\(w(t)\)</span> 有两个相同峰值.</p>
<p><img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202305261854401.png" alt="image-20230526185439894" style="zoom:67%;" /></p>
<p><img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202305261815655.png" alt="image-20230526181525877" style="zoom:67%;" /></p>
<h4 id="how-we-derive-opaque-density">How we derive opaque density</h4>
<pre><code>经过复杂的数学推导,</code></pre>
<p><img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202305261900999.png" alt="image-20230526190003816" style="zoom:80%;" /></p>
<p><img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202305261901341.png" alt="image-20230526190114158" style="zoom:67%;" /></p>
<pre><code>在写出体渲染的离散化写出:

`&lt;img src=&quot;https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202305261905780.png&quot; alt=&quot;image-20230526190533946&quot; style=&quot;zoom:67%;&quot; /&gt;`</code></pre>
<h3 id="training">Training</h3>
<p>不依赖其他监督,只依赖颜色</p>
<p>损失函数</p>
<p><img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230526190715720.png" alt="image-20230526190715720" style="zoom:80%;" /></p>
<h4 id="hierarchical-sampling.">Hierarchical sampling.</h4>
<p>我们首先沿着光线均匀采样64个点，然后我们迭代地进行4次重要性采样.只保留一个 fine NN, 第一次采样的概率基于 S-density <span class="math inline">\(\phi_s(f(x))\)</span> ,<span class="math inline">\(s\)</span> 是固定的, 第二次采样时学习后的 <span class="math inline">\(s\)</span>.</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202305261915853.png" alt="image-20230526191520712" /><figcaption aria-hidden="true">image-20230526191520712</figcaption>
</figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202305261917631.png" alt="image-20230526191713633" /><figcaption aria-hidden="true">image-20230526191713633</figcaption>
</figure>
]]></content>
      <categories>
        <category>科学</category>
      </categories>
      <tags>
        <tag>NeRF</tag>
      </tags>
  </entry>
  <entry>
    <title>2023年成都双年展：时间引力</title>
    <url>/2023/09/03/%E6%9D%82%E8%B0%88/20230903-2023%E5%B9%B4%E6%88%90%E9%83%BD%E5%8F%8C%E5%B9%B4%E5%B1%95%EF%BC%9A%E6%97%B6%E9%97%B4%E5%BC%95%E5%8A%9B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><table>
<tbody>
<tr class="odd">
<td>description:"作品锦集"</td>
</tr>
</tbody>
</table>
<h1 id="瞬间永恒">瞬间永恒</h1>
<p>策展人：王绍强</p>
<p>本版块试图在“瞬间 ' “过程 ' “数字化 ' ' 三个维度中，以国内 外当代艺术中的经典作品为案例对主题展开回应。与此同时，展览的有限性与作品泪求永恒的诚意一如瞬间与永恒 的辩证。在刹那绽放永恒的光芒，让永恒于刹那间收藏。</p>
<p><img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202309032146808.png" style="zoom:80%;" /></p>
<p>静穆古典的画风中赋予陌生感，<span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3poLWhhbnMvJUU4JUI2JTg1JUU3JThFJUIwJUU1JUFFJTlFJUU0JUI4JUJCJUU0JUI5JTg5Izp+OnRleHQ9JUU3JUJBJUFGJUU3JUIyJUI5JUU3JTlBJTg0JUU3JUIyJUJFJUU3JUE1JTlFJUU4JTg3JUFBJUU1JThBJUE4JUU0JUI4JUJCJUU0JUI5JTg5LCVFOCVCNiU4NSVFNyU4RSVCMCVFNSVBRSU5RSVFNCVCOCVCQiVFNCVCOSU4OSVFNiU5NiU4NyVFNSVBRCVBNiVFNCVCRCU5QyVFNSU5MyU4MSVFMyU4MCU4Mg==">超现实主义<i class="fa fa-external-link-alt"></i></span></p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202309032153253.png" alt="郑重宾，星系座X-01 03 02" /><figcaption aria-hidden="true">郑重宾，星系座X-01 03 02</figcaption>
</figure>
<p>光在裂隙之间</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202309032157820.png" alt="徐冰,英文方块字书法教室" /><figcaption aria-hidden="true">徐冰,英文方块字书法教室</figcaption>
</figure>
<figure>
<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230903215842564.png" alt="徐冰，英文方块字书法：桃花源记" /><figcaption aria-hidden="true">徐冰，英文方块字书法：桃花源记</figcaption>
</figure>
<p>与《天书》的『伪文字』不同，它是可阅读的。一切都似乎是熟悉的：从不解到释然的过程，传统的创作工具和线条。但同时又是崭新的，新的书写体系。不变的是理解新事物的兴奋。</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202309032216865.png" alt="乔治·巴塞利兹，也许太大了" /><figcaption aria-hidden="true">乔治·巴塞利兹，也许太大了</figcaption>
</figure>
<p>新表现主义的代表人物，喜欢上下颠倒作画。</p>
<p><img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202309032247396.jpg" alt="Wernber Bouwens 地球仪内的空间" style="zoom:50%;" /></p>
<p>光滑的地球仪是对地球的粗暴简单地抽象，背后却是错综复杂的地形结构，与此同时，其他颜色也隐匿于蓝绿色的主导下。</p>
<h1 id="存在遥望">存在遥望</h1>
<p>策展人：Philipp Ziegler</p>
<p>在这场想象、知和表达的饕餮盛宴中，约三十位国内外知 名艺术家将围绕主题"存在遥望"为本届双年展带来四十多件作品，将现在视为过往已至的耒来，帮助人们拓展对所在世界复杂性的理解，同时，通过展现自然和人工生命体相互融合的生态系统以及技术实体与有机实体的共生栖居之所，预见人类的未来。交互式装置、虚拟现实及人工智能等作品展示了媒体艺术的最新发展，同时带来了测试新技术以及论证其运用能使社会受益的各种艺术表达。我们的时代面临着复杂的生态及社会经济挑战，而所有参展作品都希望建立人们的这种意识。它们不仅表明了寻找新方法应对今日危机的必要性，同时诠释了通过艺术创意展望未来的可能性，在这个未来里，我们与自然、技术和其他共生体 （ 包栝人类和非人 类 ） 和谐地生活在一起。</p>
<p><img src="E:\workplace\Tencent Files\1206315053\FileRecv\MobileFile\20230903_160434.jpg" alt="克丽斯塔 ． 佐梅雷尔 & 劳伦 ． 米尼奥诺，飞蝇人生" style="zoom:67%;" /></p>
<p>静止不动时，苍蝇飞走，做出动作时，苍蝇就会在人的轮廓。对人们日常的行为另一个视角的解读。</p>
<p><img src="E:\workplace\Tencent Files\1206315053\FileRecv\MobileFile\20230903_161121.jpg" alt="Kerstin Ergenzinger，太空胡须" style="zoom: 50%;" /></p>
<p>设计初衷应该是，受到气流影响，这些胡须就会移动、弯曲、左右伸展、颤动，就像受到了突如其 来的神经冲动的刺激或者被一阵神秘的风所吹动。"雕塑受器组与传器 〈 热丝风速计 ） 相连，测量室内空 气流速。胡须在这种噪声下表现出不安和轻微的紧张状态，反映并转化气流变化的信号。” 但是实际上观众的影响微乎其微，我用嘴吹了很久都没效果，可能室内的空调影响更大。</p>
<figure>
<img src="https://justineemard.com/wp-content/uploads/2020/09/7D8A0407-OK-470x313.jpg" alt="*超有机体 *贾斯汀·埃马尔 2020 安装（吹制玻璃、机器人、传感器和机器学习系统） 尺寸：约100m2" /><figcaption aria-hidden="true">*<strong>超有机体 *贾斯汀·埃马尔</strong> <strong>2020</strong> <strong>安装（吹制玻璃、机器人、传感器和机器学习系统）</strong> <strong>尺寸：约100m2</strong></figcaption>
</figure>
<p>系统的不可预测性使我们生活在一种独特的体验中。这个新的有组织的存在的光和声音在共生中反应，同时彼此惊讶，在一个结构化的、有机的和漂浮的星座中碰撞。从这套装置中散发出一种集体智慧的形式：一个超有机体栩栩如生，产生新的图像，这是由装置时空中投射的阴影和反射产生的。而观众却永远无法探知神经网络的运作，玄秘且动人，欣喜又恐惧。</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202309032333683.png" alt="肥皂剧" /><figcaption aria-hidden="true">肥皂剧</figcaption>
</figure>
<p>当我们使用机器手臂完成吹泡泡这一行为时，是否仍然能够捕捉到儿时的乐趣和愉悦；也同时思考工业机器人能否成为想象力的创新力的源泉？但是周围小朋友的惊呼和欢乐回答了这个问题。</p>
]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
  </entry>
  <entry>
    <title>MRTK2</title>
    <url>/2023/08/14/%E6%8A%80%E6%9C%AF/20230814-MRTK2/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><table>
<tbody>
<tr class="odd">
<td>description:" "</td>
</tr>
</tbody>
</table>
<h1 id="简介">简介</h1>
<p>为加快 MR 应用开发的一套组件和特性。</p>
<h2 id="the-main-configuration-profile">The Main configuration profile</h2>
<p>绑定在 <em>MixedRealityToolkit</em> 对象上，为 Toolkit 提供入点</p>
<h1 id="配置文件">配置文件</h1>
<ul>
<li>Expeience settings : 默认的 MR 环境尺度</li>
<li>Camera:</li>
<li>Input system settings:</li>
</ul>
<h1 id="特性分类">特性分类</h1>
<h2 id="输入系统">输入系统</h2>
<ul>
<li>Interactable: 根据输入时间进行相应的 UX 组件 （interactable.cs)</li>
<li>Cursor</li>
<li>Focus</li>
<li>Pointer：分为远近，Near Pointer 包括 Grab 和 Poke.</li>
<li>Controller</li>
<li>Device Manager : Input Data Providers, 用于检测创建和管理 Contrller 的生命周期</li>
</ul>
<p>由下至上构建输入系统，Device Manager 需要提过一个 InputSystemProfile 来进行配置。</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
  </entry>
</search>
