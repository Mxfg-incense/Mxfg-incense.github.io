<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title></title>
    <url>/2022/11/23/%E5%85%B6%E4%BB%96/11.23/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="debug">debug</h1>
<ol type="1">
<li>step in 进入该函数</li>
<li>step out 跳出当前栈 到 断点处</li>
</ol>
<h1 id="rendering">Rendering</h1>
<ol type="1">
<li><code>Ray_intersect</code>:</li>
<li><code>pay_load</code></li>
</ol>
<h1 id="rgb">RGB</h1>
<p>hitpoint ?</p>
<p>payload.alive ?</p>
<p>ubantu , debug</p>
]]></content>
  </entry>
  <entry>
    <title>Anaconda问题</title>
    <url>/2022/07/22/%E5%85%B6%E4%BB%96/Ananconda%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>打开 <strong>Anaconda</strong> 时出现</p>
<p><img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202207221820298.png" /></p>
<h3 id="解决方法">解决方法</h3>
<p>取消代理</p>
<p><img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202207221821701.png" /></p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
  </entry>
  <entry>
    <title></title>
    <url>/2022/11/09/%E5%85%B6%E4%BB%96/11.9/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="sfm">SFM</h1>
<p>几何验证</p>
<p>标准 RANSAC</p>
<p>满足就是好的match</p>
<h2 id="增量重建">增量重建</h2>
<h3 id="initialization">Initialization</h3>
<h3 id="立体视觉">立体视觉</h3>
<p>同一个像素点</p>
<p>同一个特征点在普通位置</p>
<h3 id="单应矩阵">单应矩阵</h3>
<p>colmap_matcher</p>
<p>skip-early</p>
]]></content>
  </entry>
  <entry>
    <title>NeRF细节整理</title>
    <url>/2022/10/14/%E5%85%B6%E4%BB%96/NeRF%E7%B2%BE%E8%AF%BB/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="download-from-google-driver">Download from Google driver</h1>
<p>Use the Wget command:</p>
<p>小文件</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget --no-check-certificate <span class="string">&quot;https://drive.google.com/uc?export=download&amp;id=<span class="variable">$&#123;Fileid&#125;</span>&quot;</span> -O <span class="string">&quot;<span class="variable">$&#123;Filename&#125;</span>&quot;</span></span><br></pre></td></tr></table></figure>
<p>大文件</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget --load-cookies /tmp/cookies.txt <span class="string">&quot;https://drive.google.com/uc?export=download&amp;confirm=<span class="subst">$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate &#x27;https://drive.google.com/uc?export=download&amp;id=$&#123;fileid&#125;&#x27; -O- | sed -rn &#x27;s/.confirm=([0-9A-Za-z_]+)</span>./\1\n/p&#x27;)&amp;id=<span class="variable">$&#123;fileid&#125;</span>&quot;</span> -O <span class="variable">$&#123;filename&#125;</span> &amp;&amp; <span class="built_in">rm</span> -rf /tmp/cookies.txt</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>解压</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">unzip <span class="variable">$&#123;filename&#125;</span></span><br></pre></td></tr></table></figure>
<h1 id="ndc-ray-space-derivation">NDC ray space derivation</h1>
<p>论文中的内参矩阵里的 <span class="math inline">\(n,f\)</span> ：the near and far clipping planes and <span class="math inline">\(r,t\)</span> are the right and top bounds scene at the near clipping plane. 所以 <span class="math inline">\(\frac{r}{t}=\)</span> Aspect ratio (屏幕高宽比)</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202210140206585.png" alt="A perspective camera" /><figcaption aria-hidden="true">A perspective camera</figcaption>
</figure>
<h2 id="ndc">NDC</h2>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202210140217293.png" alt="归一化" /><figcaption aria-hidden="true">归一化</figcaption>
</figure>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
  </entry>
  <entry>
    <title>Anaconda 安装 Tensorflow-gpu 2.4.0</title>
    <url>/2022/08/14/%E5%85%B6%E4%BB%96/Tensorflow-gpu2.4.0%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="前言">前言</h1>
<p>装好 <code>Tensorflow 2.3.0</code> 之后，训练一个 MNIST 集花了7分钟左右，于是想安装 GPU 版本的. 于是就开始踩坑了</p>
<h1 id="选定版本">选定版本</h1>
<p>安装<code>Tensorflow-gpu</code> 需要安装<a href="https://www.tensorflow.org/install/source"><strong>相应的</strong> CUDA 和 cuDNN 版本</a>。这里应该先看自己的显卡所支持的 CUDA 版本，再确定 Tensorflow 版本。通过 <code>NIVIDIA-系统信息-组件</code> 查看</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202208141916549.png" alt="驱动支持的CUDA版本" /><figcaption aria-hidden="true">驱动支持的CUDA版本</figcaption>
</figure>
<p>我的显卡是 RTX 3060 版本比较高，之前安装的 2.3.0 版本不知道为什么就在编译模型，和构建模型的时候卡死。所以选择 <code>Tensorflow-gpu=2.4.0</code> 。</p>
<h1 id="安装">安装</h1>
<p>打开cmd, 激活虚拟环境</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda active ts</span><br></pre></td></tr></table></figure>
<p>选择阿里云镜像源，默认源无该版本且速度慢</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install Tensorflow-gpu=2.4.0 -i https://mirrors.aliyun.com/pypi/simple/</span><br></pre></td></tr></table></figure>
<p>听说这里应该会自动安装对应的 CUDA 和 cuDNN，然而我并没用，手动安装</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install cudnn==8.0 -i https://mirrors.aliyun.com/pypi/simple/</span><br></pre></td></tr></table></figure>
<p>这里会自动安装 cudatookit ，接着安装 keras</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install keras==2.4.3</span><br></pre></td></tr></table></figure>
<p>是否检测到GPU</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">tf.config.list_physical_devices(<span class="string">&#x27;GPU&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>输出 <code>[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]</code> 则成功。</p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
  </entry>
  <entry>
    <title></title>
    <url>/2022/10/19/%E5%85%B6%E4%BB%96/instant-ngp%E5%A4%8D%E7%8E%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="数据集准备">数据集准备</h1>
<p>数据结构如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-fox</span><br><span class="line">  -images</span><br><span class="line">  -transform.json</span><br></pre></td></tr></table></figure>
<p>通过 <code>scripts/colmap2nerf.py</code> 处理视频或者一序列的图像，图像应避免动态模糊和虚焦。对于大型场景可能训练几分钟来增加锐度</p>
<blockquote>
<p>锐度，即图像边缘对比度，在边缘部分增加白色和黑色边缘增加对比度</p>
</blockquote>
<p>经过 COLMAP 稀疏重建后在 <code>sphare/0</code> 下生成三个 <code>.txt</code> 文件。</p>
<h4 id="camera.txt">camera.txt</h4>
<p>包含相机内参</p>
<p>以下为实例</p>
<figure class="highlight txt"><table><tr><td class="code"><pre><span class="line"># Camera list with one line of data per camera:</span><br><span class="line">#   CAMERA_ID, MODEL, WIDTH, HEIGHT, PARAMS[]</span><br><span class="line"># Number of cameras: 159</span><br><span class="line">1 SIMPLE_RADIAL 1920 1080 1496.1000558533603 960 540 -0.022162590119422163</span><br><span class="line">2 SIMPLE_RADIAL 1920 1080 1487.0032035424961 960 540 0.020998321685288947</span><br></pre></td></tr></table></figure>
<ul>
<li><p>CAMERA_ID ：对应每张图片的序号</p></li>
<li><p>MODEL ： 相机的模型选择具体参考详见<span class="exturl" data-url="aHR0cHM6Ly9jb2xtYXAuZ2l0aHViLmlvL2NhbWVyYXMuaHRtbA==">官方文档<i class="fa fa-external-link-alt"></i></span></p>
<p>主要给出了几种建议, 无畸变时采用 simple model.</p>
<ol type="1">
<li><code>SIMPLE_PINHOLE</code> , <code>PINHOLE</code>: 小孔相机模型，在图像未畸变时使用，在此情况下，也可以通过更复杂的相机模型改进参数</li>
<li><code>SIMPLE_RADIAL</code> ：对于在内参都不知道的情况下，每张图像有不同的相机校准。e.g internet photos??(从网络获取的图片？)</li>
<li><code>OPENCV</code> : 已知校准参数的情况下</li>
</ol>
<p><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2NvbG1hcC9jb2xtYXAvYmxvYi9tYXN0ZXIvc3JjL2Jhc2UvY2FtZXJhX21vZGVscy5o">具体的每个模型的参数<i class="fa fa-external-link-alt"></i></span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">// Simple Pinhole camera model.</span><br><span class="line">//   f, cx, cy</span><br><span class="line">CAMERA_MODEL_DEFINITIONS(<span class="number">0</span>, <span class="string">&quot;SIMPLE_PINHOLE&quot;</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">// Pinhole camera model.</span><br><span class="line">//    fx, fy, cx, cy</span><br><span class="line">CAMERA_MODEL_DEFINITIONS(<span class="number">1</span>, <span class="string">&quot;PINHOLE&quot;</span>, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">// Simple camera model <span class="keyword">with</span> one focal length <span class="keyword">and</span> one radial distortion</span><br><span class="line">// parameter.</span><br><span class="line">//    f, cx, cy, k</span><br><span class="line">CAMERA_MODEL_DEFINITIONS(<span class="number">2</span>, <span class="string">&quot;SIMPLE_RADIAL&quot;</span>, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">// Simple camera model <span class="keyword">with</span> one focal length <span class="keyword">and</span> two radial distortion</span><br><span class="line">// parameters.</span><br><span class="line">//    f, cx, cy, k1, k2</span><br><span class="line">CAMERA_MODEL_DEFINITIONS(<span class="number">3</span>, <span class="string">&quot;RADIAL&quot;</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">// OpenCV camera model.</span><br><span class="line">//    fx, fy, cx, cy, k1, k2, p1, p2</span><br><span class="line">CAMERA_MODEL_DEFINITIONS(<span class="number">4</span>, <span class="string">&quot;OPENCV&quot;</span>, <span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">// OpenCV fish-eye camera model.</span><br><span class="line">//    fx, fy, cx, cy, k1, k2, k3, k4</span><br><span class="line">CAMERA_MODEL_DEFINITIONS(<span class="number">5</span>, <span class="string">&quot;OPENCV_FISHEYE&quot;</span>, <span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">// Full OpenCV camera model.</span><br><span class="line">//    fx, fy, cx, cy, k1, k2, p1, p2, k3, k4, k5, k6</span><br><span class="line">CAMERA_MODEL_DEFINITIONS(<span class="number">6</span>, <span class="string">&quot;FULL_OPENCV&quot;</span>, <span class="number">12</span>)</span><br><span class="line"></span><br><span class="line">// FOV camera model.</span><br><span class="line">//    fx, fy, cx, cy, omega</span><br><span class="line">CAMERA_MODEL_DEFINITIONS(<span class="number">7</span>, <span class="string">&quot;FOV&quot;</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">// Simple camera model <span class="keyword">with</span> one focal length <span class="keyword">and</span> one radial distortion</span><br><span class="line">// parameter, suitable <span class="keyword">for</span> fish-eye cameras.</span><br><span class="line">//    f, cx, cy, k</span><br><span class="line">CAMERA_MODEL_DEFINITIONS(<span class="number">8</span>, <span class="string">&quot;SIMPLE_RADIAL_FISHEYE&quot;</span>, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">// Simple camera model <span class="keyword">with</span> one focal length <span class="keyword">and</span> two radial distortion</span><br><span class="line">// parameters, suitable <span class="keyword">for</span> fish-eye cameras.</span><br><span class="line">//    f, cx, cy, k1, k2</span><br><span class="line">CAMERA_MODEL_DEFINITIONS(<span class="number">9</span>, <span class="string">&quot;RADIAL_FISHEYE&quot;</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">// Camera model <span class="keyword">with</span> radial <span class="keyword">and</span> tangential distortion coefficients <span class="keyword">and</span></span><br><span class="line">// additional coefficients accounting <span class="keyword">for</span> thin-prism distortion.</span><br><span class="line">//    fx, fy, cx, cy, k1, k2, p1, p2, k3, k4, sx1, sy1</span><br><span class="line">CAMERA_MODEL_DEFINITIONS(<span class="number">10</span>, <span class="string">&quot;THIN_PRISM_FISHEYE&quot;</span>, <span class="number">12</span>)</span><br></pre></td></tr></table></figure>
<h4 id="images.txt">images.txt</h4>
<p><code>images.txt</code> 示例：</p></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Image list with two lines of data per image:</span></span><br><span class="line"><span class="comment">#  IMAGE_ID, QW, QX, QY, QZ, TX, TY, TZ, CAMERA_ID, NAME</span></span><br><span class="line"><span class="comment">#  POINTS2D[] as (X, Y, POINT3D_ID)</span></span><br><span class="line"><span class="comment"># Number of images: 2, mean observations per image: 2</span></span><br><span class="line"><span class="number">1</span> <span class="number">0.851773</span> <span class="number">0.0165051</span> <span class="number">0.503764</span> -<span class="number">0.142941</span> -<span class="number">0.737434</span> <span class="number">1.02973</span> <span class="number">3.74354</span> <span class="number">1</span> P1180141.JPG</span><br><span class="line"><span class="number">2362.39</span> <span class="number">248.498</span> <span class="number">58396</span> <span class="number">1784.7</span> <span class="number">268.254</span> <span class="number">59027</span> <span class="number">1784.7</span> <span class="number">268.254</span> -<span class="number">1</span></span><br><span class="line"><span class="number">2</span> <span class="number">0.851773</span> <span class="number">0.0165051</span> <span class="number">0.503764</span> -<span class="number">0.142941</span> -<span class="number">0.737434</span> <span class="number">1.02973</span> <span class="number">3.74354</span> <span class="number">1</span> P1180142.JPG</span><br><span class="line"><span class="number">1190.83</span> <span class="number">663.957</span> <span class="number">23056</span> <span class="number">1258.77</span> <span class="number">640.354</span> <span class="number">59070</span></span><br></pre></td></tr></table></figure>
<p>​ <code>Q</code> 表示的旋转的四个参数？与 <code>Eigen::Quaterniond</code>格式相同 <code>T</code> 表示平移参数。第二行表示一个特征点在图像中的二维坐标。</p>
<h4 id="points3d.txt">points3D.txt</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 3D point list with one line of data per point:</span></span><br><span class="line"><span class="comment">#  POINT3D_ID, X, Y, Z, R, G, B, ERROR, TRACK[] as (IMAGE_ID, POINT2D_IDX)</span></span><br><span class="line"><span class="comment"># Number of points: 3, mean track length: 3.3334</span></span><br><span class="line"><span class="number">63390</span> <span class="number">1.67241</span> <span class="number">0.292931</span> <span class="number">0.609726</span> <span class="number">115</span> <span class="number">121</span> <span class="number">122</span> <span class="number">1.33927</span> <span class="number">16</span> <span class="number">6542</span> <span class="number">15</span> <span class="number">7345</span> <span class="number">6</span> <span class="number">6714</span> <span class="number">14</span> <span class="number">7227</span></span><br><span class="line"><span class="number">63376</span> <span class="number">2.01848</span> <span class="number">0.108877</span> -<span class="number">0.0260841</span> <span class="number">102</span> <span class="number">209</span> <span class="number">250</span> <span class="number">1.73449</span> <span class="number">16</span> <span class="number">6519</span> <span class="number">15</span> <span class="number">7322</span> <span class="number">14</span> <span class="number">7212</span> <span class="number">8</span> <span class="number">3991</span></span><br><span class="line"><span class="number">63371</span> <span class="number">1.71102</span> <span class="number">0.28566</span> <span class="number">0.53475</span> <span class="number">245</span> <span class="number">251</span> <span class="number">249</span> <span class="number">0.612829</span> <span class="number">118</span> <span class="number">4140</span> <span class="number">117</span> <span class="number">4473</span></span><br></pre></td></tr></table></figure>
<p>如果需要进一步 rectify, 可以把参数输入到 OpenCV 的 <strong>stereoRectify()</strong> 函数中，之后 <strong>initUndistortRectifyMap()</strong> , 最后使用 <strong>remap()</strong> 函数进行重映射 从而得到矫正的结果。</p>
<h2 id="transform.json">transform.json</h2>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="attr">&quot;camera_angle_x&quot;</span><span class="punctuation">:</span> <span class="number">1.2433395001651382</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;camera_angle_y&quot;</span><span class="punctuation">:</span> <span class="number">0.7661685246315253</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;fl_x&quot;</span><span class="punctuation">:</span> <span class="number">1339.9721836141384</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;fl_y&quot;</span><span class="punctuation">:</span> <span class="number">1339.9721836141384</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;k1&quot;</span><span class="punctuation">:</span> <span class="number">-0.021131598158465558</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;k2&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;p1&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;p2&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;cx&quot;</span><span class="punctuation">:</span> <span class="number">960.0</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;cy&quot;</span><span class="punctuation">:</span> <span class="number">540.0</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;w&quot;</span><span class="punctuation">:</span> <span class="number">1920.0</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;h&quot;</span><span class="punctuation">:</span> <span class="number">1080.0</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;aabb_scale&quot;</span><span class="punctuation">:</span> <span class="number">16</span><span class="punctuation">,</span></span><br></pre></td></tr></table></figure>
<p><code>camera_angle_x</code> 是 <code>angle_y = math.atan(h / (fl_y * 2)) * 2</code>，即光心到边缘的最大角度。</p>
<p><code>fl_x</code> 是相机的焦距大小，看了代码之后发现取的是最后一个图像得到的焦距，实际上在·<code>1300-1496</code>之间进行浮动，据通过手机厂商的数据发现是 <code>26.8mm</code> 等效焦距，实际焦距 <code>5.4mm</code> ??</p>
<h2 id="现有数据集">现有数据集</h2>
<p>Nerf: 将near plane 和 far plane 的空间转化成 NDC [-1,1]，渲染时光线只截用该空间中的。</p>
<p>ngp: 没有采用NDC， unit cube ? 似乎没什么影响， <code>aabb_scale</code> 的作用就是为了限制渲染范围。</p>
<h2 id="实验">实验</h2>
<ol type="1">
<li>对云雾的消除。推测原因：上方缺乏光线穿过，因此需要增加相机的视角。上中下 和 上。 如果我们增加相机上方视角更多的图片呢：预测应该不会有很大改善。</li>
<li>增加桌面的特征值</li>
<li>勾选 <code>train extrinces、</code> 等</li>
</ol>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
  </entry>
  <entry>
    <title>Variable Bitrate Neural Fields</title>
    <url>/2022/12/14/%E5%85%B6%E4%BB%96/Variable_Bitrate/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="motivation">Motivation</h1>
<ol type="1">
<li>压缩3D信息用于更高效的数据传输，和直播</li>
<li>传统Nerf 的问题：因为需要很大的网络对场景进行编码，很多光线，每个点都要过这个大网络，因此渲染慢。</li>
<li>feature grids: 每个顶点包含一个 feature vector. 任意一个点用插值的到特征。网络只需要对所有顶点进行编码, 网络减小，速度增加。但是储存的feature grids 占用的空间却比之前一个网络的多。</li>
<li>ngp: 每个顶点的坐标通过 hash 映射到一个 codebook 的 index 上。但是需要多层，每层的codebook也很大，最终的存储还是很大。</li>
</ol>
<h1 id="vq-feature-grids-with-learning">VQ feature grids with learning</h1>
<ol type="1">
<li>直接在顶点上储存 index 并学习</li>
<li>为了解决不可微的问题，使用 softmax 的技巧。 储存一系列浮点数，取max。<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202212141921446.png" alt="Vector quantized feaature grids with learning" /></li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>Lightroom 缓存</title>
    <url>/2022/07/13/%E5%85%B6%E4%BB%96/lightroomcahce/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="目录缓存-catalog">目录缓存 (Catalog)</h2>
<p>​ 引导 LR 到照片在硬盘中的位置信息，对其进行远程操控，不用再复制一遍文件,不占用过多内存，也就是操作面板左侧的部分。只保存操作信息。在 <code>编辑-目录设置</code>中找到其缓存位置。</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202207141203760.png" alt="目录缓存位置" /><figcaption aria-hidden="true">目录缓存位置</figcaption>
</figure>
<p>有三个文件夹</p>
<ol type="1">
<li><p><strong>Backup</strong> : 备份目录缓存，不会备份照片。</p></li>
<li><p><strong>Helper</strong>: 搜索目录缓存</p></li>
<li><p><strong>Preview</strong>: 图片预览缓存，可删除，下次进入会重新加载</p></li>
</ol>
<h2 id="相机原始缓存-camera-raw">相机原始缓存 (Camera RAW)</h2>
<p>​ 将图片完整加载进入 <strong>camera RAW </strong> 缓存，获得更大的调整范围。<code>编辑-首选项-性能</code> 中可进行清理和配置，</p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>Lightroom</tag>
      </tags>
  </entry>
  <entry>
    <title>ngp 代码阅读</title>
    <url>/2022/11/09/%E5%85%B6%E4%BB%96/ngp%E4%BB%A3%E7%A0%81%E9%98%85%E8%AF%BB/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="implement">Implement</h1>
<p>具体的实现细节</p>
<h2 id="performance-vs-quality">Performance vs quality</h2>
<p>hash table 的大小<span class="math inline">\(T\)</span> 过大导致GPU内存不足。</p>
<p>经过实验取得 <span class="math inline">\(F=2,L=16\)</span></p>
<h2 id="implicit-hash-collision-resolution">Implicit hash collision resolution</h2>
<ol type="1">
<li>一对点不太可能同时在每一层都发生碰撞,而且 <span class="math inline">\(N_{min}\)</span> 保证不发生冲突</li>
<li>一对点对梯度的贡献是不同的,表面的点的影响更大</li>
<li>分辨率的分布是几何的, 分辨率越大的较少的选取</li>
</ol>
<h2 id="online-adaptivity">Online adaptivity</h2>
<p>如果输入 <span class="math inline">\(x\)</span> 的分布集中在一个小的区域,那么精细网格会更少的发生哈希冲突,能学习的更精确.</p>
<p><strong>Neural Radiance Caching</strong></p>
<h2 id="model-architecture">Model Architecture</h2>
<p>由两个 MLP 并联</p>
<ol type="1">
<li><p><strong>density MLP</strong>: maps encoded position <span class="math inline">\(enc(\bold{x},\theta)\)</span> to 16 outputs values ， <span class="math inline">\(\theta\)</span> is the encoding parameters</p></li>
<li><p><strong>color MLP</strong>:</p>
<p><strong>Input</strong></p>
<p>the 16 output values of the density MLP, and the view direction projected onto the first 16 coefficients of the spherical harmonics basis. This is a natural frequency encoding over unit vectors</p>
<p><strong>output:</strong></p>
<p>RGB color triplet.</p>
<p>sRGB: sigmoid activation</p>
<p>HDR: exponential activation</p>
<p>1-hidden-layer density MLP and a 2-hidden-layer color MLP, both 64 neurons wide.</p>
<h2 id="accelerated-ray-marching">Accelerated ray marching</h2>
<p>we concentrate samples near surfaces by maintaining an occupancy grid that coarsely marks empty vs. nonempty space.</p>
<h3 id="ray-marching-step-size-and-stopping">Ray Marching Step Size and Stopping</h3>
<ol type="1">
<li><strong>synthetic NeRF scenes:</strong> step size $t= /1024 $ in the unit cube <span class="math inline">\([0,1]^3\)</span></li>
<li><strong>Others</strong>: <span class="math inline">\(t\)</span>​ exponential growth, which means that the computation cost grows only logarithmically in scene diameter, with no perceivable loss of quality.</li>
<li>Stop ray marching and set the remaining contribution to zero as soon as the transmittance of the ray drops below a threshold</li>
</ol>
<h2 id="occupancy-grids">Occupancy Grids</h2>
<p>During ray marching, whenever a sample is to be placed according to the step size from the previous section, the sample is skipped if its grid cell’s bit is low. Which one of the 𝐾 grids is queried is determined by both the sample position x and the step size Δ𝑡: among the grids covering x, the finest one with cell side length larger than Δ𝑡 is queried.</p>
<p><em>update the occupancy grids</em>. a second set of grids that store full-precision floating density. update every 16 training steps.</p>
<h2 id="number-of-rays-versus-batch-size">Number of Rays Versus Batch size</h2>
<p>​ batch size = Samples per ray * Rays per batch</p>
<p><strong>Training from a larger number of rays, i.e. incorporating more viewpoint variation into the batch. </strong>Include as many rays as possible in batches of fixed size rather that building variable-size batches from a fixed ray count</p></li>
</ol>
<h1 id="input">Input</h1>
<ol type="1">
<li><p>load <code>config/base.json</code>: 包括 <code>loss</code>, <code>optimizer</code>, <code>encoding</code> 的超参等 <code>envmap</code>?</p></li>
<li><p><code>train</code></p></li>
<li><p><code>training_prep_nerf</code>: 每过16次迭代，更新occupancy grids.</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (m_training_step &lt; <span class="number">256</span>) &#123;</span><br><span class="line">		<span class="built_in">update_density_grid_nerf</span>(alpha, <span class="built_in">NERF_GRIDSIZE</span>()*<span class="built_in">NERF_GRIDSIZE</span>()*<span class="built_in">NERF_GRIDSIZE</span>()*n_cascades, <span class="number">0</span>, stream);</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">		<span class="built_in">update_density_grid_nerf</span>(alpha, <span class="built_in">NERF_GRIDSIZE</span>()*<span class="built_in">NERF_GRIDSIZE</span>()*<span class="built_in">NERF_GRIDSIZE</span>()/<span class="number">4</span>*n_cascades, <span class="built_in">NERF_GRIDSIZE</span>()*<span class="built_in">NERF_GRIDSIZE</span>()*<span class="built_in">NERF_GRIDSIZE</span>()/<span class="number">4</span>*n_cascades, stream);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p><code>train_nerf_step(uint32_t target_batch_size, Testbed::NerfCounters&amp; counters, cudaStream_t stream)</code>:</p></li>
<li><p><code>generate_training_samples_nerf</code></p></li>
</ol>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
  </entry>
  <entry>
    <title>ngp背景重建</title>
    <url>/2022/10/23/%E5%85%B6%E4%BB%96/ngp%E8%83%8C%E6%99%AF%E9%87%8D%E5%BB%BA/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="目的">目的</h1>
<p>探究影响背景重建的因素。</p>
<h1 id="推测因素">推测因素</h1>
<figure>
<img src="E:\instant-ngp\data\nerf\fs\fs.gif" alt="原始重建结果" /><figcaption aria-hidden="true">原始重建结果</figcaption>
</figure>
<ol type="1">
<li><strong>视角</strong> 在拍摄时由于俯拍绕物体一周，导致场景上方缺乏光线透过，于是在场景顶部产生云雾。</li>
<li><strong>距离</strong> 拍摄时绕物体一周的过程中，对于场景中的一个点，缺乏同一 <span class="math inline">\((\theta,\phi)\)</span> 的数据，导致体密度训练较差。</li>
<li><strong>背景特征</strong> 背景特征多，增加网络的复杂程度，是否导致网络更难学习。</li>
<li>训练 <strong>外参 曝光 畸变</strong></li>
</ol>
<h1 id="实验一">实验一</h1>
<h2 id="实验目的">实验目的</h2>
<p>探究相机拍摄视角对背景重建的影响</p>
<h2 id="实验条件">实验条件</h2>
<ol type="1">
<li><strong>同一场景</strong>，光照相同，背景相同</li>
<li><strong>相机参数</strong> ：同一相机 (Sony A6000), 镜头焦距 50mm，采用 A 挡拍摄 (F = 2.8) , 曝光补偿 +0.7，ISO: auto.</li>
<li><strong>数据量相同</strong>：每组实验的照片数量一致</li>
<li><strong>COLMAP 模型</strong>： <code>SIMPLE_RADIAL</code> 且 每张图像内参一致</li>
<li>未勾选 训练外参，曝光和畸变。</li>
</ol>
<h2 id="实验步骤">实验步骤</h2>
<ol type="1">
<li><p><strong>数据收集</strong>：绕物体分别在 上、中、下拍摄一圈。</p></li>
<li><p><strong>第一组</strong> ：对于从上方拍摄的视角提取 215 张图像。</p>
<p><strong>第二组</strong> ：上、中、下分别使用 60、60 、110张图像 并且筛掉一些模糊和虚焦的照片</p></li>
<li><p><strong>数据处理</strong>：使用COLMAP稀疏重建， <strong>每一组</strong>都总共有215张图像用于稀疏重建</p>
<p>第一组得到的相机内参：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Camera list with one line of data per camera:</span></span><br><span class="line"><span class="comment">#   CAMERA_ID, MODEL, WIDTH, HEIGHT, PARAMS[]</span></span><br><span class="line"><span class="comment"># Number of cameras: 1</span></span><br><span class="line"><span class="number">1</span> SIMPLE_RADIAL <span class="number">1920</span> <span class="number">1080</span> <span class="number">4090.2916176564518</span> <span class="number">960</span> <span class="number">540</span> <span class="number">0.348649511020239</span></span><br></pre></td></tr></table></figure>
<p>第二组得到的相机内参：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Camera list with one line of data per camera:</span></span><br><span class="line"><span class="comment">#   CAMERA_ID, MODEL, WIDTH, HEIGHT, PARAMS[]</span></span><br><span class="line"><span class="comment"># Number of cameras: 1</span></span><br><span class="line"><span class="number">1</span> SIMPLE_RADIAL <span class="number">1920</span> <span class="number">1080</span> <span class="number">4726.2638345804498</span> <span class="number">960</span> <span class="number">540</span> <span class="number">0.48132964624147656</span></span><br></pre></td></tr></table></figure></li>
<li><p><strong>NeRF 重建</strong> : <code>run.py</code> 两组实验相机沿着相同的轨迹 <code>base_cam.json</code>，导出渲染后的视频</p></li>
</ol>
<h2 id="实验结果">实验结果</h2>
<h4 id="第一组"><strong>第一组</strong></h4>
<p>背景渲染结果白色桌面为锥型</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202210241950980.png" alt="整体效果" /><figcaption aria-hidden="true">整体效果</figcaption>
</figure>
<video src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202210242027829.mp4" title="第一组">
99
</video>
<p>物体周围有明显的云雾环绕</p>
<h4 id="实验二">实验二</h4>
<video src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202210242031040.mp4" title="实验二">
99
</video>
<p>云雾分布有明显分层现象，上方云雾仍然为白色，中间云雾的一半视角出现绿色，而另一半云雾基本消除，下方圆桌形态较好重建，但桌面呈现透明。更多周围背景被重建（窗外绿树，栏杆，沙发等）</p>
<h2 id="结论">结论</h2>
<p>增加相机视角多样性明显减少物体周围的云雾</p>
<h2 id="不足">不足</h2>
<ol type="1">
<li>拍摄过程中虚焦导致不同视角的数据量有差别</li>
<li>不同视角拍摄时镜头与物体距离未保持一致</li>
</ol>
<h2 id="讨论">讨论</h2>
<ol type="1">
<li>网络倾向于在相机面前贴云雾，导致通常沿着相机轨迹产生云雾</li>
<li>室内一面造成的云雾少于窗外绿树形成的云雾。推测，室外场景不同变化小.</li>
<li>上方的云雾？</li>
</ol>
<h1 id="实验二-1">实验二</h1>
<h3 id="实验目的-1">实验目的</h3>
<p>背景纹理的复杂程度如何影响背景重建效果</p>
<h3 id="实验条件-1">实验条件</h3>
<ol type="1">
<li><strong>同一场景</strong>，光照相同，背景相同</li>
<li><strong>相机</strong>：同一实际拍摄</li>
<li><strong>数据量相同</strong>：每组实验的照片数量基本一致</li>
<li><strong>COLMAP 模型</strong>： <code>SIMPLE_RADIAL</code> 且选择内参 <code>share_for all images</code></li>
<li>未勾选 训练外参，曝光和畸变。</li>
</ol>
<h3 id="实验步骤-1">实验步骤</h3>
<ol type="1">
<li><p><strong>数据收集</strong>：绕物体在相似的角度分别在有格子纹理和空白桌面进行拍摄</p></li>
<li><p>各提取60张图像</p></li>
<li><p><strong>数据处理</strong>：使用COLMAP稀疏重建</p>
<p>空白桌面得到的相机内参：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Camera list with one line of data per camera:</span></span><br><span class="line"><span class="comment">#   CAMERA_ID, MODEL, WIDTH, HEIGHT, PARAMS[]</span></span><br><span class="line"><span class="comment"># Number of cameras: 1</span></span><br><span class="line"><span class="number">1</span> SIMPLE_RADIAL <span class="number">3840</span> <span class="number">2160</span> <span class="number">2928.591596486669</span> <span class="number">1920</span> <span class="number">1080</span> <span class="number">0.035193673608008569</span></span><br></pre></td></tr></table></figure>
<p>有纹理得到的相机内参：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Camera list with one line of data per camera:</span></span><br><span class="line"><span class="comment">#   CAMERA_ID, MODEL, WIDTH, HEIGHT, PARAMS[]</span></span><br><span class="line"><span class="comment"># Number of cameras: 1</span></span><br><span class="line"><span class="number">1</span> SIMPLE_RADIAL <span class="number">3840</span> <span class="number">2160</span> <span class="number">2929.642972834683</span> <span class="number">1920</span> <span class="number">1080</span> <span class="number">0.027481430175291963</span></span><br></pre></td></tr></table></figure></li>
<li><p><strong>NeRF 重建</strong> : <code>run.py</code> 两组实验相机沿着相同的轨迹 <code>base_cam.json</code>，导出渲染后的视频</p></li>
</ol>
<h3 id="实验结果-1">实验结果</h3>
<h4 id="有纹理组">有纹理组</h4>
<p>桌上的纹理较好重建</p>
<video src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202210261857883.mp4" title="第一组">
99
</video>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202210261912272.png" alt="image-20221026191200695" /><figcaption aria-hidden="true">image-20221026191200695</figcaption>
</figure>
<h4 id="空白桌面组">空白桌面组</h4>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202210261859279.png" alt="空白对照" /><figcaption aria-hidden="true">空白对照</figcaption>
</figure>
<p>空白组的桌面相比有纹理的会更加透明</p>
<h3 id="实验结论">实验结论</h3>
<ol type="1">
<li><p>纹理更多 COLMAP 更好的进行特征提取</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202210261918587.png" alt="image-20221026191811412" /><figcaption aria-hidden="true">image-20221026191811412</figcaption>
</figure></li>
</ol>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202211052223653.png" alt="image-20221026191914388" /><figcaption aria-hidden="true">image-20221026191914388</figcaption>
</figure>
<h2 id="实验三">实验三</h2>
<ol type="1">
<li><p><strong>Train extrinsic</strong>: propagates gradients back onto the camera parameters in order to minimize the loss (in this case by treating the cameras as rigid bodies with momentum and the loss gradients as impulses acting on them). This can fix slight inaccuracies in the poses from <code>transform.json</code>. If you're using COLMAP, this option only yields a small benefit as COLMAP is already quite accurate -- I'd leave it off for most scenes.</p></li>
<li><p><strong>Train distortion</strong>: learns a grid-based camera distortion model on top of the Open CV camera model parameterized in <code>transforms.json</code>. Again, COLMAP usually does a good enough job that you don't need this.</p></li>
<li><p><strong>Train exposure</strong>: learns to compensate for varying exposure levels of the training images. If you generate your own data, you should not use this and instead set your camera to fixed exposure</p></li>
<li><p><strong>extrinsic</strong>: 14073 steps ; 收敛时间 235s ; Loss: 0.000482(33.17dB)</p></li>
<li><p><strong>exposure</strong>: 7032 steps; 收敛时间 110s ; Loss: 0.000577 (32.39dB)</p></li>
<li><p><strong>disorder</strong>: 6374 steps ; 收敛时间：100s Loss 0.000606(32.17db)</p></li>
<li><p><strong>origin</strong>: 6214 steps ; 收敛时间 100s ; Loss : 000614 (32.12DB)</p></li>
</ol>
<video src="E:\instant-ngp\data\nerf\ex2\blank\origin.mp4" title="origin">
</video>
<video src="E:\instant-ngp\data\nerf\ex2\blank\extrinsic.mp4">
</video>
<video src="E:\instant-ngp\data\nerf\ex2\blank\exposure.mp4">
</video>
<video src="E:\instant-ngp\data\nerf\ex2\blank\disorder.mp4">
</video>
<h2 id="结论-1">结论</h2>
<ol type="1">
<li>勾选<strong>extrinsic</strong> 结果更加清晰，使头发上的云雾消失，并且训练速度变慢一倍左右。</li>
<li>勾选 <strong>exposure</strong> 使头发上的云雾消失。</li>
<li>勾选 <strong>disorder</strong> 使结果更加清晰。</li>
</ol>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
  </entry>
  <entry>
    <title>加密</title>
    <url>/2022/06/30/%E5%85%B6%E4%BB%96/test/</url>
    <content><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="抱歉, 这个密码看着不太对, 请再试试." data-whm="抱歉, 这个文章不能被校验, 不过您还是能看看解密后的内容.">
  <script id="hbeData" type="hbeData" data-hmacdigest="34d306308e78602647ee2af0e1ba120e81fb02111f2ccf6c53f776b9a3b4401d">4630436162ade97ba2718b7d0c4b3b630ef8b034c35893a7afa4c54a5752d90eba191a593f89497fdfca691efaf72d5caa0c664d8e7a85bd833fac72ade59ddbf66b4bdec75a2ed1e83f57bcb279b78c8202c7ce8d3eb34051070935a62ccbf9be563b576fcb19a6e4c095e03496f05d0fec5de7a8af18b78d977beffb6874da4670293f572d11dfa81b48ce6cd0448f0a018d399d177f54eb76d77c6c17f9c36f9f255c3de0f225f9e9c6b4f23d83fc3307cf9be8ef0d2bb8d0474ceec45d7300894f4b8f11650b44ad991ba7d432283e64e8468c79d445b4aef43276f04ffecdc0b540f5d74022a21d6c663658536777acea65da1c70d7ceedf635d566051a343742697d7f69fae8d58a663affc9c692b5e6979adbae0ddec5d44de1e87c283ee769f49dc2014a109295dad07c418b</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-default">
      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-default">您好, 这里需要密码.</span>
      </label>
    </div>
  </div>
</div>
<script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>其他</category>
      </categories>
  </entry>
  <entry>
    <title>np.random.rand vs np.random.random</title>
    <url>/2022/07/23/%E5%85%B6%E4%BB%96/np.random.rand%20vs%20np.random.random/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>二者都连续均匀地在 <span class="math inline">\([0,1]\)</span> 生成 (uniform distribution) 样本，但接受地参数不同. <code>np.random.rand</code> 接受分隔地参数，<code>np.random.random</code> 接受一个 tuple.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.random.rand(<span class="number">2</span>,<span class="number">7</span>)</span><br><span class="line">a = np.random.random((<span class="number">2.7</span>))</span><br></pre></td></tr></table></figure>
<h3 id="推荐写法">推荐写法</h3>
<p>自 Numpy 1.17 后， 提供新的 方法</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rng = np.random.default_rng()  <span class="comment"># Create a default Generator.</span></span><br><span class="line">rng.random(size=<span class="number">10</span>)  <span class="comment"># Generate 10 samples.</span></span><br><span class="line">array([<span class="number">0.00416913</span>, <span class="number">0.31533329</span>, <span class="number">0.19057857</span>, <span class="number">0.48732511</span>, <span class="number">0.40638395</span>,</span><br><span class="line">       <span class="number">0.32165646</span>, <span class="number">0.02597142</span>, <span class="number">0.19788567</span>, <span class="number">0.08142055</span>, <span class="number">0.15755424</span>])</span><br><span class="line">rng = np.random.uniform(<span class="number">0</span>,<span class="number">1</span>,size=(<span class="number">2</span>,<span class="number">3</span>)) <span class="comment">#specify bound </span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
  </entry>
  <entry>
    <title>大理火把节来历</title>
    <url>/2022/08/01/%E5%85%B6%E4%BB%96/%E5%A4%A7%E7%90%86%E7%81%AB%E6%8A%8A%E8%8A%82%E6%9D%A5%E5%8E%86/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>普遍流传火烧松明楼的故事缺乏证据。该说法大概在明清时期广泛为人接受。如清代学者</p>
<p>师范曾在《滇系·杂载》中总结出以下几点：</p>
<ol type="1">
<li>火把节即星回节</li>
<li>起源一：武侯征南，于是日擒孟获，侵夜入城，城中父老设庭燎以迎之</li>
<li>起源二：纪念曼阿奴之妻阿南，焚夫衣后横刀自断。</li>
<li><strong>起源三：火烧松明楼，纪念慈善夫人（也称柏洁夫人），此最为广传的一种。</strong></li>
</ol>
<p>但元明清常常流传着很多关于大理白族火把节的记载与南诏时期不符。比如南诏时期，《太平广记》中引南诏王诗文《星回节游避风台与清平官赋》:</p>
<blockquote>
<p>避风善阐台,极目见藤越,悲哉古与今,依然烟与月。自我居震旦,翊卫类夔契。伊昔颈皇运,艰难仰忠烈。不觉岁云暮,感极星回节。元昶同一心,子孙堪贻厥。</p>
</blockquote>
<p>从「岁云暮」应该看出星回节应该位于年末，而火把节位于六月二十五，二者应该是两个节日。但是在明清的记载中大多将二者混为一谈。</p>
<p>因此，《火烧松明楼》作为白族火把节的起源这一说法，应该只是穿凿附会之说。</p>
<p>尽管如此，纪念柏洁夫人已然作为节日庆祝的主要载体。比如海东镇的赛龙舟与“捞尸会”，染手花（虽然已经不多见）与白洁夫人手刨火烧残余至十指染血有关，大理北门村和西门村等多地更是将“白洁夫人”奉为本主。</p>
<p>目前还有一种的说法是大理白族火把节其真正的象征源于男性的垄断生育。抢升斗的必须是新婚的男性，象征着得子。</p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
  </entry>
  <entry>
    <title>手写数字识别</title>
    <url>/2022/08/14/%E5%85%B6%E4%BB%96/%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="使用-mlp-实现">使用 MLP 实现</h1>
<h2 id="设置">设置</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">tf.config.list_physical_devices(<span class="string">&#x27;GPU&#x27;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>[PhysicalDevice(name=&#39;/physical_device:GPU:0&#39;, device_type=&#39;GPU&#39;)]</code></pre>
<h2 id="载入数据">载入数据</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">(x_train,y_train),(x_test,y_test) = mnist.load_data()</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.imshow(x_test[<span class="number">0</span>])</span><br><span class="line">plt.colorbar()</span><br><span class="line">plt.grid(<span class="literal">False</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202208141915773.png" alt="载入数据" /><figcaption aria-hidden="true">载入数据</figcaption>
</figure>
<p>​</p>
<h4 id="load_data">load_data()</h4>
<p><strong>返回</strong>：</p>
<p>两个元组：</p>
<pre><code>x_train, x_test: uint8 数组表示的灰度图像，尺寸为 (num_samples, 28, 28)

y_train, y_test: uint8 数组表示的数字标签（范围在 0-9 之间的整数），尺寸为 (num_samples,)</code></pre>
<p><strong>参数</strong>： path: 如果在本地没有索引文件 (at '~/.keras/datasets/' + path), 它将被下载到该目录 #### Mnist 数据集</p>
<p>训练集为 60,000 张 28x28 像素灰度图像，测试集为 10,000 同规格图像，总共 10 类数字标签。</p>
<h2 id="处理原始数据">处理原始数据</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">x_train = x_train / <span class="number">255.0</span>       <span class="comment">#隐式转换为float64</span></span><br><span class="line">x_test = x_test / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(x_train.shape,<span class="string">&quot;train data&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(x_test.shape,<span class="string">&quot;test data&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>(60000, 28, 28) train data
(10000, 28, 28) test data</code></pre>
<p>将原始数据归一化。<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2RiYXQyMDE1L2FydGljbGUvZGV0YWlscy81MDAwODMxNQ==" title="最好的markdown教程">归一化的作用<i class="fa fa-external-link-alt"></i></span></p>
<h2 id="转换标签">转换标签</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> to_categorical</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">y_train = to_categorical(y_train, num_classes=<span class="number">10</span>)</span><br><span class="line">y_test = to_categorical(y_test, num_classes=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(y_test)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>[[0. 0. 0. ... 1. 0. 0.]
 [0. 0. 1. ... 0. 0. 0.]
 [0. 1. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]</code></pre>
<p>使用 <span class="exturl" data-url="aHR0cHM6Ly93d3cuZ2Vla3Nmb3JnZWVrcy5vcmcvcHl0aG9uLWtlcmFzLWtlcmFzLXV0aWxzLXRvX2NhdGVnb3JpY2FsLw==">to_categorical()<i class="fa fa-external-link-alt"></i></span> 将标签向量转化为 binary matrix</p>
<h2 id="构建模型">构建模型</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense,Dropout,Flatten</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Flatten(input_shape=(<span class="number">28</span>,<span class="number">28</span>)))</span><br><span class="line">model.add(Dense(<span class="number">512</span>,activation=<span class="string">&#x27;relu&#x27;</span>,name=<span class="string">&quot;Dense1&quot;</span>)) <span class="comment">#添加全连接层</span></span><br><span class="line">model.add(Dropout(<span class="number">0.3</span>,name=<span class="string">&#x27;dropout1&#x27;</span>))</span><br><span class="line">model.add(Dense(<span class="number">128</span>,activation=<span class="string">&#x27;relu&#x27;</span>,name=<span class="string">&#x27;Dense2&#x27;</span>))</span><br><span class="line">model.add(Dropout(<span class="number">0.3</span>,name=<span class="string">&#x27;dropout2&#x27;</span>))</span><br><span class="line">model.add(Dense(<span class="number">10</span>,activation=<span class="string">&#x27;softmax&#x27;</span>,name=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line">model.summary()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;sequential&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten (Flatten)            (None, 784)               0         
_________________________________________________________________
Dense1 (Dense)               (None, 512)               401920    
_________________________________________________________________
dropout1 (Dropout)           (None, 512)               0         
_________________________________________________________________
Dense2 (Dense)               (None, 128)               65664     
_________________________________________________________________
dropout2 (Dropout)           (None, 128)               0         
_________________________________________________________________
softmax (Dense)              (None, 10)                1290      
=================================================================
Total params: 468,874
Trainable params: 468,874
Non-trainable params: 0
_________________________________________________________________</code></pre>
<p>网络第一层 <code>Flatten</code> 将图像转换成以为数组，该层没有要学习的参数。</p>
<p>每个 <code>Dense</code> 层有 512 神经元， 最后一个使用 <code>softmax</code> 激活函数，它可以将一个数值向量归一化为一个概率分布向量:</p>
<p><span class="math display">\[
Softmax(zi) = \frac{e^{z_i}}{\sum_j {e^{z_j}}}
\]</span></p>
<h2 id="编译模型">编译模型</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.losses <span class="keyword">import</span> categorical_crossentropy</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> Adamax</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=Adamax(),</span><br><span class="line">              loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br></pre></td></tr></table></figure>
<p>使用 <code>Admax</code> <span class="exturl" data-url="aHR0cHM6Ly9rZXJhcy5pby96aC9vcHRpbWl6ZXJzLw==">优化器<i class="fa fa-external-link-alt"></i></span>，<code>categotical_crossentropy</code>（交叉熵损失） 作为<span class="exturl" data-url="aHR0cHM6Ly9rZXJhcy5pby96aC9sb3NzZXMv">损失函数<i class="fa fa-external-link-alt"></i></span>，通常与 softmax 配合使用： <span class="math display">\[
Loss = -log(1-p_i) 
\]</span> <span class="math inline">\(p_i\)</span>是预测样本真实标签得到的概率</p>
<h2 id="训练模型">训练模型</h2>
<p>调用 <code>model.fit</code> 方法，这样命名因为会将模型与训练数据进行拟合</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.fit(x_train,y_train,batch_size=<span class="number">128</span>,epochs=<span class="number">10</span>,verbose=<span class="number">1</span>,validation_data=(x_test,y_test))</span><br></pre></td></tr></table></figure>
<pre><code>Epoch 1/10
469/469 [==============================] - 4s 5ms/step - loss: 0.7144 - accuracy: 0.7838 - val_loss: 0.1901 - val_accuracy: 0.9447
Epoch 2/10
469/469 [==============================] - 2s 4ms/step - loss: 0.2355 - accuracy: 0.9317 - val_loss: 0.1319 - val_accuracy: 0.9605
Epoch 3/10
469/469 [==============================] - 2s 4ms/step - loss: 0.1644 - accuracy: 0.9515 - val_loss: 0.1056 - val_accuracy: 0.9678
Epoch 4/10
469/469 [==============================] - 2s 4ms/step - loss: 0.1290 - accuracy: 0.9617 - val_loss: 0.0917 - val_accuracy: 0.9717
Epoch 5/10
469/469 [==============================] - 2s 4ms/step - loss: 0.1077 - accuracy: 0.9687 - val_loss: 0.0837 - val_accuracy: 0.9743
Epoch 6/10
469/469 [==============================] - 2s 4ms/step - loss: 0.0963 - accuracy: 0.9710 - val_loss: 0.0751 - val_accuracy: 0.9759
Epoch 7/10
469/469 [==============================] - 2s 4ms/step - loss: 0.0802 - accuracy: 0.9763 - val_loss: 0.0738 - val_accuracy: 0.9772
Epoch 8/10
469/469 [==============================] - 2s 4ms/step - loss: 0.0714 - accuracy: 0.9790 - val_loss: 0.0663 - val_accuracy: 0.9791
Epoch 9/10
469/469 [==============================] - 2s 4ms/step - loss: 0.0664 - accuracy: 0.9798 - val_loss: 0.0647 - val_accuracy: 0.9798
Epoch 10/10
469/469 [==============================] - 2s 4ms/step - loss: 0.0570 - accuracy: 0.9830 - val_loss: 0.0633 - val_accuracy: 0.9800</code></pre>
<p><code>epochs</code> 是训练次数，<code>validation_date</code> 是划分出测试集，训练集正确率达到98%以上</p>
<h2 id="评估准确率">评估准确率</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">test_loss,test_acc = model.evaluate(x_test,y_test,verbose=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nTest accurancy&#x27;</span>, test_acc)</span><br></pre></td></tr></table></figure>
<pre><code>313/313 [==============================] - 1s 2ms/step - loss: 0.0284 - accuracy: 0.9916

Test accurancy 0.991599977016449</code></pre>
<h2 id="进行预测">进行预测</h2>
<p>来看第一个预测结果</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">predictions= model.predict(x_test)</span><br><span class="line">predictions[<span class="number">0</span>]</span><br><span class="line">np.argmax(predictions[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<pre><code>7</code></pre>
<p>可以绘制图表，查看对全部类的预测</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">plot_image</span>(<span class="params">i,predictions_array, true_label, img</span>):</span><br><span class="line">  predictions_array, true_label, img = predictions_array, true_label, img</span><br><span class="line">  plt.grid(<span class="literal">False</span>)</span><br><span class="line">  plt.xticks([])</span><br><span class="line">  plt.yticks([])</span><br><span class="line"></span><br><span class="line">  plt.imshow(img, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line">  predicted_label = np.argmax(predictions_array)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> predicted_label == true_label:</span><br><span class="line">    color = <span class="string">&#x27;blue&#x27;</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    color = <span class="string">&#x27;red&#x27;</span></span><br><span class="line"></span><br><span class="line">  plt.xlabel(<span class="string">&quot;&#123;&#125; &#123;:3.0f&#125;% (&#123;&#125;)&quot;</span>.<span class="built_in">format</span>(predicted_label,</span><br><span class="line">                                      <span class="number">100</span>*np.<span class="built_in">max</span>(predictions_array),true_label),color=color)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_value_array</span>(<span class="params">i,predictions_array, true_label</span>):</span><br><span class="line">   predictions_array, true_label = predictions_array, true_label</span><br><span class="line">   plt.grid(<span class="literal">False</span>)</span><br><span class="line">   plt.xticks(<span class="built_in">range</span>(<span class="number">10</span>))</span><br><span class="line">   plt.yticks([])</span><br><span class="line">   thisplot = plt.bar(<span class="built_in">range</span>(<span class="number">10</span>), predictions_array, color=<span class="string">&quot;#777777&quot;</span>)</span><br><span class="line">   plt.ylim([<span class="number">0</span>,<span class="number">1</span>])</span><br><span class="line">   predicted_label = np.argmax(predictions_array)</span><br><span class="line"></span><br><span class="line">   thisplot[predicted_label].set_color(<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">   thisplot[true_label].set_color(<span class="string">&#x27;blue&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>正确标签为蓝色，错误为红色 ## 验证预测结果</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">num_rows = <span class="number">10</span></span><br><span class="line">num_cols = <span class="number">5</span></span><br><span class="line">num_images = num_rows*num_cols</span><br><span class="line">plt.figure(figsize=(<span class="number">2</span>*<span class="number">2</span>*num_cols, <span class="number">2</span>*num_rows))</span><br><span class="line">x_test.reshape(<span class="number">10000</span>,<span class="number">28</span>,<span class="number">28</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_images):</span><br><span class="line">  t = np.argmax(y_test[i])</span><br><span class="line">  plt.subplot(num_rows, <span class="number">2</span>*num_cols, <span class="number">2</span>*i+<span class="number">1</span>)</span><br><span class="line">  plot_image(i, predictions[i], t, x_test[i])</span><br><span class="line">  plt.subplot(num_rows, <span class="number">2</span>*num_cols, <span class="number">2</span>*i+<span class="number">2</span>)</span><br><span class="line">  plot_value_array(i, predictions[i], t)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202208141915886.png" alt="验证预测结果" /><figcaption aria-hidden="true">验证预测结果</figcaption>
</figure>
<h1 id="使用-cnn">使用 CNN</h1>
<h2 id="重新载入数据">重新载入数据</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">(x_train,y_train),(x_test,y_test) = mnist.load_data()</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.imshow(x_test[<span class="number">0</span>])</span><br><span class="line">plt.colorbar()</span><br><span class="line">plt.grid(<span class="literal">False</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">x_train = np.expand_dims(x_train,-<span class="number">1</span>)</span><br><span class="line">x_test = np.expand_dims(x_test,-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">x_train = x_train / <span class="number">255.0</span></span><br><span class="line">x_test = x_test / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line">y_train = to_categorical(y_train)</span><br><span class="line">y_test = to_categorical(y_test)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202208141914539.png" alt="载入数据" /><figcaption aria-hidden="true">载入数据</figcaption>
</figure>
<p>x.shape = (samples_nums, height, width, channels)</p>
<h2 id="构建模型-1">构建模型</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Conv2D,MaxPooling2D</span><br><span class="line">model = Sequential()</span><br><span class="line">input_size = (<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>)</span><br><span class="line">model.add(Conv2D(<span class="number">32</span>,</span><br><span class="line">          kernel_size = (<span class="number">3</span>,<span class="number">3</span>), </span><br><span class="line">          activation = <span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">          input_shape = input_size))</span><br><span class="line"></span><br><span class="line">model.add(Dropout(<span class="number">0.3</span>))</span><br><span class="line"></span><br><span class="line">model.add(Conv2D(<span class="number">16</span>,</span><br><span class="line">          kernel_size = (<span class="number">3</span>,<span class="number">3</span>), </span><br><span class="line">          activation = <span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(MaxPooling2D(pool_size=(<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line">model.add(Dropout(<span class="number">0.3</span>))</span><br><span class="line">model.add(Flatten())</span><br><span class="line">model.add(Dense(<span class="number">128</span>,activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(Dropout(<span class="number">0.4</span>))</span><br><span class="line">model.add(Dense(<span class="number">10</span>,activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;sequential_5&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_8 (Conv2D)            (None, 26, 26, 32)        320       
_________________________________________________________________
dropout_12 (Dropout)         (None, 26, 26, 32)        0         
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 24, 24, 16)        4624      
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 12, 12, 16)        0         
_________________________________________________________________
dropout_13 (Dropout)         (None, 12, 12, 16)        0         
_________________________________________________________________
flatten_5 (Flatten)          (None, 2304)              0         
_________________________________________________________________
dense_8 (Dense)              (None, 128)               295040    
_________________________________________________________________
dropout_14 (Dropout)         (None, 128)               0         
_________________________________________________________________
dense_9 (Dense)              (None, 10)                1290      
=================================================================
Total params: 301,274
Trainable params: 301,274
Non-trainable params: 0
_________________________________________________________________</code></pre>
<h2 id="编译和训练模型">编译和训练模型</h2>
<p>选择 <code>Adamdelta</code> 作为优化器</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> Adam</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=Adam(), loss = <span class="string">&#x27;categorical_crossentropy&#x27;</span>, metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">model.fit(x_train,y_train,</span><br><span class="line">          batch_size=<span class="number">128</span>,</span><br><span class="line">          epochs=<span class="number">10</span>,</span><br><span class="line">          verbose=<span class="number">1</span>,</span><br><span class="line">          validation_data=(x_test,y_test))</span><br></pre></td></tr></table></figure>
<pre><code>Epoch 1/10
469/469 [==============================] - 6s 9ms/step - loss: 0.6243 - accuracy: 0.8000 - val_loss: 0.0790 - val_accuracy: 0.9767
Epoch 2/10
469/469 [==============================] - 3s 7ms/step - loss: 0.1273 - accuracy: 0.9605 - val_loss: 0.0503 - val_accuracy: 0.9837
Epoch 3/10
469/469 [==============================] - 3s 6ms/step - loss: 0.0927 - accuracy: 0.9715 - val_loss: 0.0396 - val_accuracy: 0.9874
Epoch 4/10
469/469 [==============================] - 3s 7ms/step - loss: 0.0748 - accuracy: 0.9758 - val_loss: 0.0387 - val_accuracy: 0.9891
Epoch 5/10
469/469 [==============================] - 3s 6ms/step - loss: 0.0634 - accuracy: 0.9814 - val_loss: 0.0355 - val_accuracy: 0.9880
Epoch 6/10
469/469 [==============================] - 3s 7ms/step - loss: 0.0558 - accuracy: 0.9828 - val_loss: 0.0331 - val_accuracy: 0.9900
Epoch 7/10
469/469 [==============================] - 3s 6ms/step - loss: 0.0502 - accuracy: 0.9835 - val_loss: 0.0295 - val_accuracy: 0.9911
Epoch 8/10
469/469 [==============================] - 3s 6ms/step - loss: 0.0488 - accuracy: 0.9848 - val_loss: 0.0296 - val_accuracy: 0.9906
Epoch 9/10
469/469 [==============================] - 3s 6ms/step - loss: 0.0439 - accuracy: 0.9856 - val_loss: 0.0313 - val_accuracy: 0.9910
Epoch 10/10
469/469 [==============================] - 3s 6ms/step - loss: 0.0420 - accuracy: 0.9865 - val_loss: 0.0303 - val_accuracy: 0.9912





&lt;tensorflow.python.keras.callbacks.History at 0x16d0c5fa340&gt;</code></pre>
<h2 id="评估准确率-1">评估准确率</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">test_loss, test_acc = model.evaluate(x_test, y_test, verbose= <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nTest accuracy:&#x27;</span>, test_acc)</span><br><span class="line"></span><br><span class="line">num_rows = <span class="number">10</span></span><br><span class="line">num_cols = <span class="number">5</span></span><br><span class="line">num_images = num_rows*num_cols</span><br><span class="line">plt.figure(figsize=(<span class="number">2</span>*<span class="number">2</span>*num_cols, <span class="number">2</span>*num_rows))</span><br><span class="line">x_test.reshape(<span class="number">10000</span>,<span class="number">28</span>,<span class="number">28</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_images):</span><br><span class="line">  t = np.argmax(y_test[i])</span><br><span class="line">  plt.subplot(num_rows, <span class="number">2</span>*num_cols, <span class="number">2</span>*i+<span class="number">1</span>)</span><br><span class="line">  plot_image(i, predictions[i], t, x_test[i])</span><br><span class="line">  plt.subplot(num_rows, <span class="number">2</span>*num_cols, <span class="number">2</span>*i+<span class="number">2</span>)</span><br><span class="line">  plot_value_array(i, predictions[i], t)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>313/313 - 1s - loss: 0.0303 - accuracy: 0.9912

Test accuracy: 0.9911999702453613</code></pre>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202208141915772.png" alt="验证预测结果" /><figcaption aria-hidden="true">验证预测结果</figcaption>
</figure>
<h2 id="cnn-与-mlp-对比">CNN 与 MLP 对比</h2>
<ol type="1">
<li>CNN 能提取像素间的空间关系，而 MLP 将图像变为一维向量丢失空间信息</li>
<li>MLP 是每一层是全连接的，参数数量多， CNN 每一层共享 kernel ，节点之间不是全连接，因此参数大小取决于 kernel 大小，参数数量少</li>
<li>CNN　具有 <em>局部平移不变性</em>, 即无论图像出现在那个位置，都能提取到该特征。（因为共享 filter）. 而 MLP 不具有平移不变性，如果一张图片的特征出现在左上，而另一张特征出现在右下，那么 MLP 将尝试往右下修正参数。</li>
</ol>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>CNN</tag>
        <tag>MLP</tag>
      </tags>
  </entry>
  <entry>
    <title>火把节记录</title>
    <url>/2022/08/01/%E5%85%B6%E4%BB%96/%E7%81%AB%E6%8A%8A%E8%8A%82%E6%84%9F%E5%8F%97/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>大理白族的火把节在每年六月二十日，分为竖火把，点火，抢升斗，耍火把等环节，具有独特且浓郁的名族特色，也是白族最盛大的传统节日。</p>
<h2 id="竖火把">竖火把</h2>
<p>火把节的资金往往由村中的新生儿女的几户人家均摊。火把往往在本主庙院子里或者附近竖立，然后在竖立的挖坑以便插入。不同于彝族，白族火把节往往高竖火把，由松木制成。然后再旁边插上竹条和稻草等助燃。最后制作『升斗』，是由细木和彩纸糊成，旁边再插上旗子，共有三层，故曰『连升三级』，象征着婴儿的出世。</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202208012330672.png" alt="连升三级" /><figcaption aria-hidden="true">连升三级</figcaption>
</figure>
<h2 id="点火">点火</h2>
<p>火把节的操办具有地域性，每个村寨都有自己的本主庙，而所有村落按照本主庙划分为不同的「辖区」，每个区域都竖立自己单独的火把，火种必须从本主庙迎出来。</p>
<video src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202208012337426.mp4" title="南潘溪村迎火">
99
</video>
<p>然后将火把顶上的稻草引燃</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202208012350457.png" alt="南潘上登火把节" /><figcaption aria-hidden="true">南潘上登火把节</figcaption>
</figure>
<h2 id="抢升斗">抢升斗</h2>
<p>抢升斗的人选必须是刚婚的男性，抢下『连升三级』，祝愿着得子。</p>
<h2 id="耍火把">耍火把</h2>
<p>这应该是火把节最高潮和有趣的部分了。每家人挤在迎来的火种前引燃自己手中的火把，将火焰传递的温暖送入自家门中。</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202208012356921.png" alt="借火" /><figcaption aria-hidden="true">借火</figcaption>
</figure>
<p>纵然黑夜降临，但亲朋好友之间互相取火，将薪火不断传递，『万炬纵横，灿如星海』。正如同明代诗人杨慎笔下的『松炬荧荧宵作平』。</p>
<p><img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202208020001028.jpg" /></p>
<p><img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202208020107106.jpg" /></p>
<p>撒一把松明子，烈焰迸发，火光四射。</p>
<p><img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202208020009767.jpg" /></p>
<p>尽情挥舞手中的火把，让疾风为火焰注入生命力，让黑暗中染上绚丽炽红的轨迹。</p>
<p><img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202208020012250.jpg" /></p>
<p><img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202208020105980.jpg" /></p>
<p>火把上的大火直冲云霄，点亮一片天空。火星四溅，松木崩裂，感受到火炬内部有股强劲的生命力在迸发。</p>
<p><img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202208020021338.jpg" /></p>
<p>最终火把却被这股生命力反噬，仿佛英雄垂暮，摇摇欲坠，大厦将倾。</p>
<p><img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202208020024687.jpg" /></p>
<p>最终轰然倒塌，仿佛火山爆发，岩浆滚滚流淌而下，又如浴火重生。</p>
<p><img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202208020026118.jpg" /></p>
<p>火把节如同不断上演的光影艺术剧，绚丽多姿，多彩纷呈。白子们通过火焰的传递，传承苍洱间祖祖辈辈生活的土地。又如同一首苍老的山歌，遒劲有力，发自肺腑，全出于本性，没有丝毫扭捏造作。火焰的力量从火把的根部直顶头部，穿云裂石。舞动时，划过黑暗。这就是为何火把节象征着生育的根本吧。</p>
<p>欢迎各位来西南地区体会独特的风土人情。</p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>旅游</tag>
        <tag>摄影</tag>
      </tags>
  </entry>
  <entry>
    <title>黔行山水间</title>
    <url>/2022/09/22/%E5%85%B6%E4%BB%96/%E9%BB%94%E8%A1%8C%E5%B1%B1%E6%B0%B4%E9%97%B4/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>​ 贵州，中国唯一没有平原支撑的省份，群山环绕，数千条河流将其塑造为喀斯特岩溶地貌的王国。大量的山林河谷让这片土地充斥着浓郁的神秘气息。我于是怀着敬畏和些许的恐惧抵达了贵阳。</p>
<p>​ 贵阳的交通是立体的。坐车身在其中，各条道路在眼前不断地交织绕的人晕头转向，难辨东西。黔灵山公园的猕猴让人有些期待，在公园里跋涉许久才终于看到两只猕猴间互相厮杀，其中一只差点失足从屋檐下掉落，令人捏一把汗。又行了几步，终于发现一群猕猴，哦，不，应该是一群强盗吧。幸亏身上没带食物，否则肯定被哄抢的一干二净。在甲秀楼溜达完后，然后再附近找了家餐馆，叫“雷家圆子”，就是用豆腐做的油炸圆子，配上其特有的调料，口感外脆内嫩，味道鲜美，算是特色小吃吧。</p>
<p>​ 饭后到高铁站后与社会实践团队会合，大家神态不一，有的社交达人如鱼得水和旁人侃侃而谈，也有的社恐面露羞涩，一言不发。我显然属于后者，所以高铁路上一直假装睡觉，害怕与旁边的组员交谈。我想，以后会有机会和大家熟悉的，也不必过多担心。</p>
<p>​ 在六盘水经过一晚的修整，来到了本次调研的第一站：水城古镇。这里坐落着一个三线博物馆，纪念的是西南三线建设的历史。沿路的房屋墙壁上都有显赫的那个时代的标语。“人亲堪比阶级爱”，“好人好马上三线”，“为人民服务”等等。参观了博物馆后，知道三线建设是上世纪我国的重大军事战略计划，对西南地区的现代工业化起到了积极的推动作用。让人感到有趣的是一个手动的防空警报器，但是却被工人们用作闹钟，同学们开始疯狂转警报器，空厅传响，整个博物馆瞬间弥漫着一种紧张的备战氛围，霎时间回到那段峥嵘岁月。之后我们便开始在水城古镇进行街头访谈，收获颇丰。突然天空下起大雨，我于是坐在伞下和一个来自广东的游客聊了一下关于三线的问题，谈到当时韶关是广东的三线建设的重点，当时的备战气氛其实非常紧张，很多工业，和技术人员都从东部比如上海等地迁往西部。然后我们小组向一个小卖部的老板考察了水城古镇的历史。在这里未开发以前，这里基本都是住宅区，都用的自己的房子做点小生意，后来政府为了开发古镇景区拆迁了旧的房屋，但是没有给足相应的补贴，如今又向这里的摊位收取较为高昂的租金，这里百姓对此忿忿不平。听到这些话，我感到有些唏嘘。但是我们又采访了一位烙锅店的左氏老板，她对此的看法却又截然不同。她从小生活在水城，她母亲曾经是在路边做烙豆腐的。她对景区的开发持非常积极的态度，街道变得更加整洁了，社会环境和治安也有了很大改善，比如之前女孩子从来不敢走夜路，如今她也不会担心走夜路，游客更多使得生意更加兴隆。我想，之所以产生不同看法的原因是从不同的方面看待水城的变迁。政府在协调拆迁问题时确实存在着过失，百姓原本的生产经营方式突然改变，又缺乏补贴，引起了一部分原本生意蒸蒸日上的商家的忿怨。而后面采访的这位，较为年轻的老板更关注于变迁带来的好的环境改变。尽管如此，政府也应该更多的考虑和协调百姓的不满。然后晚上也品尝了水城的特色小吃—烙锅。用土砂锅烙烤食物，蘸一下辣椒面，香辣爽口，油而不腻。只是有点难以控制火候大小，容易热油飞溅，还是略微有些危险。</p>
<p>​ 第二天从六盘水前往久负盛名的黄果树瀑布，作为最大的瀑布群。做观光车的一路上都能看到一些小型的瀑布。离大瀑布的远近不同，感受也不同。从远处看去，夹在两山之间，激起的云雾在山谷中升腾，是秀美。而逐渐走进后，一下多了一个感官维度--触觉。激荡的水珠在脸上胡乱地拍打，心中升起阵阵凉意，耳边隆隆，水风忽忽，闭上双眼依然能感到震撼。更神奇的事，瀑布的背后，隐藏着一条溶洞，如同西游记里地水帘洞，从背面这个角度观飞瀑实属新奇，飞落地水花出奇的白，仿佛瀑布化身成了雪崩。不得不再一次感叹大自然的鬼斧神工。除了壮阔的黄果树瀑布，还有秀美的银链坠潭瀑布。其落差不大，潭沿面凸起的石面，像一片片莲叶一般，静谧而柔美地流泻如同绸缎。不知这些水滴从高处坠落时是否感到害怕，分明刚刚还在水平如面镜的水流中缓缓流淌，下一刻便倏忽间从平滑的水面坠落倾泻而下，让我不免后怕坐在飞机上的失重感</p>
<p>​ 第三天终于有实操环节了--摘刺梨。之前喝过名叫“刺柠吉”的饮料，印象中爽口。可是当亲眼看到刺梨时，浑身是刺的它似乎并不那么友好，令人不知从哪里下嘴，终于忍住牙床的刺痛艰难咬下一口时，一股酸涩令人倒吸一口气。看来刺梨的确不适合直接食用，难怪必须通过进一步加工才能除去它的酸涩味，以充分其清热爽口的优点。听完讲解后，我们便兴致勃勃地戴上手套下田采摘。这里的农田也是起伏不平，地面湿滑容易摔倒，下坡只能让旁边的玉米受苦了，一群人经过后，玉米全部都垂头丧气的倒了下来。刺梨一簇簇地挂在枝头，生熟让人难以判断，管他呢，权且当搞点小破坏。结果就发现用一层手套摘刺梨稍微一用力就能轻易地被戳穿，只得戴上两层手套，捏住刺梨之后使劲往一个方向转，就能轻易地摘下来了。大家都摘得热火朝天，尽管被刺的惨叫声此起彼伏，最后还是收获了半筐刺梨，半载而归。好心的村民想把刺梨送给我们，但是实在是苦于揣着兜里的麻烦，只得一再推却。</p>
<p>​ 采摘刺梨的之后的一天，我们团队又调查了一家刺梨加工企业，参观了刺梨加工的生产线。了解到刺梨的营养价值很高，尤其是维C含量。又介绍了很多用刺梨作为原材料的产品，除了刺梨原浆，刺梨酒，还有用来解腻用的饮品，大家都仔细品尝了一番。并且与书亦烧仙草合作推出刺梨口味的奶茶。这是确凿的事实，后来从六盘水返回到贵阳的时候，我就在高铁站奶茶店喝到了这熟悉的味道，在喝到的第一口有些莫名感动。刺梨相貌本身不讨好，原本味道又有些苦涩，但是却能被人们坚持发掘价值，经过一系列加工与其他食材配合，最终能华丽蜕变为一种竞品在市场上销售，博得消费者的喜爱，实在是催人奋进。</p>
<p>​ 还令人难以忘怀的就是乌蒙大草原。在海拔两千多米的高山间，竟然滋养出一片西南地区最大的天然草场。与平时所见一马平川的草原不同，乌蒙大草原不断给人遐想和未知期待。山丘起伏挡住了视线，让人一眼看不到全貌，越过眼前的小土坡也许就又能看见奔跑的羊群，抑或是听见阵阵牛羚，而稍微挪动脚步又能看到一只威风凛然的黄牛盘踞在下一个山头。长期在这样有趣的坡道行走，也丝毫不觉得疲惫，反倒妙趣横生。草原上还看到一群穿着布依族服饰的姑娘们围成一圈，随着音乐的节奏欢快的舞蹈，旁边的游客也逐渐加入这场草原盛会，其乐融融。我坐在草地上，和煦的风吹得我醉眼迷离，恍惚地看这片热闹的草地，人们与牛羊甚至骆驼结伴，风筝在白云间游走，山顶上徐徐旋转地大风车。这片深处群山腹地的草原就如同，尽管有些老套，但的确是贵州高原上的明珠。使生活在此的人们，能够在地无三尺平的贵州，在一片广阔的草地尽情撒欢，释放内心的烦闷，遥望连绵的草野。</p>
<p>​ 另外，我在团队中负责视频后期，当然也承担了小部分的拍摄工作。我之前没有任何关于视频创作的经验，完全是从头学起。因为要和配合新闻稿做两个视频，时间非常紧迫。白天不仅坐车和拍摄非常辛苦，晚上还得紧张工作。为了呈现更好的效果，我一帧一帧的处理视频细节，一开始很不熟练，导致效率很低，还出现一堆问题，前几天不得不工作到凌晨2点。后面也感受到自己愈发熟练，效率也逐渐提高，过程虽然很辛苦，但是看到做出来的视频还是非常有成就感，并且学习了一项新的技能。与团队成员的协作共事，同甘共苦，让大家很快成为一个紧密的团体，不善言语的我也认识了很多新的好伙伴。</p>
<p>​ 在这七天里，少不了车马困顿。“天下山峰何其多，唯有此处峰成林”。每个镇乡之间的都要绕行大量的山路。感觉贵州的建设实属不易。交通方面是一个难题，不过越来越多的高桥正在飞架，据统计，贵州桥梁数量达到20000多座，全世界排名100座桥梁当中，有80多座来自中国；这80多座大桥之中，就有一大半来自贵州。但是六盘水铁路线还是处于落后局面，基本靠六安一条线路，我认为如果毕节-六盘水能通铁路能加强黔西和四川的联系。大量山地加上云贵准静止锋带来长期阴雨的天气，制约了贵州的农业发展。除了少量优良的土地能种植猕猴桃等经济作物，而沿途看到的大部分作物还是玉米。尽管如此贵州有着丰富的旅游资源、多彩的民族文化，源远流长的酒文化。在我心中，贵州是一片神圣而又神秘的土地，不同于开阔、壮丽的西藏那样强烈宗教带来的神圣，恰恰相反，崎岖、起伏的峰林赋予贵州一股质朴、平易近人的灵气。在参观农民画时，无意听到苗族山歌，回声嘹亮，空灵婉转，仿佛一场与山灵的对话。我想以后我还会来到贵州，在此体味淡泊自得的生活态度，去追寻信奉神巫的山间传说，涤荡内心，直面自我。</p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>旅游</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/2022/07/14/%E5%85%B6%E4%BB%96/%E7%94%98%E5%8D%97%E6%B8%B8%E8%AE%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="备冬草">备冬草</h2>
<p>于是乎直接沿着最快的线路，沿着京昆高速和兰海高速直抵舟曲县。随后沿着一条小路经过腊子口到达岷县。在路上遇到了牧民准备冬草。把收割的草晒在路沿上，然后在收起来打捆屯在冬天。准备冬草规模浩大，十分忙碌，大概就是农忙？草原气候，夏季多雨，草肥物盛，冬季雪灾，大雪也会覆盖在草场上，牛羊没有新鲜牧草可以吃，所以趁着牧草枯草前割掉一些，晒干后作为牛羊冬天的食物。</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202207142030421.jpg" alt="储备冬草" /><figcaption aria-hidden="true">储备冬草</figcaption>
</figure>
<h2 id="铁尺梁">铁尺梁</h2>
<p>​ 然后顺着蜿蜒的山路盘旋而上，到达险关腊子口，红军在此激战，突破了国民党军队的防线。可以沿着栈道顺着腊子河谷看到留下的碉堡。</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202207142031021.jpg" alt="腊子口纪念碑" /><figcaption aria-hidden="true">腊子口纪念碑</figcaption>
</figure>
<h2 id="铁尺梁-1">铁尺梁</h2>
<p>​ 铁尺梁因如直立的铁尺而得名，众山之巅，诸神之上。无色经幡飘扬。可以俯瞰蜿蜒的盘山公路，散落在低谷的人家。平视可以看到叠锋隐约，错落有致，有个山峰形状酷似。据说毛泽东在此写下七律长征。</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202207142034408.jpg" alt="酷似熊的山峰" /><figcaption aria-hidden="true">酷似熊的山峰</figcaption>
</figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202207142036607.jpg" alt="月亮与经幡" /><figcaption aria-hidden="true">月亮与经幡</figcaption>
</figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202207142038251.jpg" alt="成群的牛羊" /><figcaption aria-hidden="true">成群的牛羊</figcaption>
</figure>
<h2 id="达尔宗圣湖">达尔宗圣湖</h2>
<p>​</p>
<p>​</p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>旅游</tag>
        <tag>摄影</tag>
      </tags>
  </entry>
  <entry>
    <title>启功带你学书法-破除迷信</title>
    <url>/2022/07/05/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/%E5%90%AF%E5%8A%9F%E7%BB%99%E4%BD%A0%E8%AE%B2%E4%B9%A6%E6%B3%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>​ 启功先生以破除迷信的思想贯穿全书，很实在，不故弄玄虚。扫清各种神秘的古怪学说为初学者造成的困惑和恐吓。</p>
<span id="more"></span>
<h3 id="碑和帖">碑和帖</h3>
<p>​ 碑在《说文解字》中解释为「竖石也」。原本是坟墓面前的石头。后来逐渐扩展为活人也立碑，比如谁在此留下丰功伟绩。常常带有纪念意义，史学价值比较高，所以需要是大家共同认得的字。所以大部分时间里，碑都是以楷书为主要的，但是也有例外。比如武则天为张昌宗立碑，叫《升仙太子碑》，完全用草书写，成为草书写碑的开端。碑通常是书写者直接在碑上书写，是书写者与刻工的共同参与。</p>
<p>​ 帖是字条，是平常生活中用来彼此传达信息的，是一种随意的书写，字体行草书偏多。刻帖要求还书写精神的原貌，需要先用墨迹摹写之后，再以字勾勒。</p>
<h3 id="入门练习">入门练习</h3>
<p>​ 临帖和读帖同样重要，不能偏废。</p>
<p>​ 临帖临碑时注意和现实中的用笔区别，再好的拓本也只能反映字的外形轮廓，里面墨色的浓淡、干湿、轻重的细节是丢失的。另外，有的石刻过于方正，是可能用排笔，板刷写出的，不用强求。</p>
<h3 id="用笔">用笔</h3>
<blockquote>
<p>赵雪松云：“书法以用笔为上，而结字亦须用工”。窃以为不然。</p>
</blockquote>
<p>不可被用笔至上论所迷惑，以结字为先。</p>
<blockquote>
<p>无麻不成笔</p>
</blockquote>
<h3 id="选临碑帖">选临碑帖</h3>
<p>可以有自己的创造性，按照古代已有的方法去做，吸取最有效的部分，为我所用。</p>
<blockquote>
<p>名家之书，皆古人之妙处与自家之病处相结合耳。</p>
</blockquote>
<h3 id="悬腕之说">悬腕之说</h3>
<p>「悬腕」是宋初以后的说法，宋代以前，没有高桌椅，都是席地而坐，因此没有地方能够搁放自己的手腕和手肘，显得用笔灵活，上下左右，提按自如。但是如今在高桌椅上写<strong>小字</strong>的时候，如果强行悬腕，反而右臂僵硬，无法运用臂力。</p>
<h3 id="求人不如求己">求人不如求己</h3>
<blockquote>
<p>文章千古事，得失寸心知</p>
</blockquote>
<p>意思是做文章是千古的事情，有失有得，只有自家知道。</p>
<p>书中有一个方法：把自己认为写的好的贴在墙上，过几天再瞧，就觉得很惭愧了，然后再修改，自己就明白了。</p>
]]></content>
      <categories>
        <category>阅读笔记</category>
      </categories>
      <tags>
        <tag>书法理论</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/2022/11/03/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/%E9%95%80%E9%87%91%E6%97%B6%E4%BB%A3/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="第二次工业革命">第二次工业革命</h1>
<h2 id="工业经济">工业经济</h2>
<p>​ 从小农场的手工制造业转型为工业社会。“迅速彻底的革命”。五大湖，匹兹堡钢铁中心，原材料</p>
<h2 id="铁路">铁路</h2>
<ol type="1">
<li>同一轨距</li>
<li>批量化生产，全国连锁店 全国性品牌</li>
</ol>
<h2 id="发明创造">发明创造</h2>
<ol type="1">
<li>爱迪生</li>
</ol>
<h2 id="竞争与合并">竞争与合并</h2>
<ol type="1">
<li>防止恶性竞争咯昂段</li>
</ol>
<h2 id="thomas-a.-scott">Thomas A. Scott</h2>
<ol type="1">
<li>慈善</li>
<li>集权方法，连轴转</li>
<li></li>
</ol>
<h2 id="工人自由">工人自由</h2>
<ol type="1">
<li>利益分配不均</li>
<li>少部分产业技术工人能经济独立：钢铁</li>
<li>半技术工人：操作机器，死亡率高</li>
<li>妇女恶劣的工作环境，“如同内战前一样”</li>
</ol>
<h2 id="阶级分化">阶级分化</h2>
<ol type="1">
<li>贫富差距</li>
</ol>
<h1 id="西部转型">西部转型</h1>
<p>资本主义流入 自然条件 美国文化的特别素质实在西部形成的，西部是安全阀门，将东部对自己不满的人吸引，从而抵消社会动乱。</p>
<h2 id="西进定居">西进定居</h2>
<p>农场主：东部出生本土，重建后南部逃离的黑人</p>
<h2 id="大型农场">大型农场</h2>
<p>主要仍然是家庭弄工厂</p>
<p>加州大型农场</p>
<h2 id="牛仔">牛仔</h2>
<p>牛群驱赶活动</p>
<ol type="1">
<li>西部城市人口比例高</li>
<li>矿山铁路</li>
</ol>
<h2 id="印第安人">印第安人</h2>
<ol type="1">
<li>摧毁伊甸人的经济基础</li>
<li>联邦军队与部落</li>
<li>文化打击</li>
<li><strong>道斯法</strong> ： 将印第安人土地分解，分配个家庭，剩余的出售</li>
<li>1924年赋予所有印第安人</li>
</ol>
<h1 id="政治">政治</h1>
<p>Mark Twain</p>
<h2 id="政治腐败">政治腐败</h2>
<p>大股份公司</p>
<p><strong>腐败政治机器</strong></p>
<p>共和党：控制工业化北部，中西部，西部</p>
<p>政治僵局时代，</p>
<h2 id="政府与经济">政府与经济</h2>
<ol type="1">
<li>联邦权力小</li>
<li>政党被利益集团控制，共和当坚持高关税，保护美国工业</li>
<li>金本控制</li>
</ol>
<h2 id="改革立法">改革立法</h2>
<ol type="1">
<li>文官改革法 竞争性考试</li>
<li>ICC 保障为农场主所收费用合理</li>
</ol>
<h2 id="州政治冲突">州政治冲突</h2>
<h1 id="镀金时代的自由">镀金时代的自由</h1>
<ol type="1">
<li>劳工关系</li>
<li>达尔文 契约自由</li>
</ol>
<h1 id="劳工与共和国">劳工与共和国</h1>
<ol type="1">
<li>铁路大罢工<br />
</li>
<li>改革者堆小生产时代的的怀旧，</li>
<li>劳工运动</li>
</ol>
<h2 id="贝拉米乌托邦">贝拉米乌托邦</h2>
<ol type="1">
<li>社会主义《合作社会》</li>
</ol>
<h2 id="劳工与政治">劳工与政治</h2>
]]></content>
      <categories>
        <category>阅读笔记</category>
      </categories>
  </entry>
  <entry>
    <title>枪炮、病菌与钢铁</title>
    <url>/2022/11/18/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/%E6%9E%AA%E7%82%AE%E7%97%85%E8%8F%8C%E4%B8%8E%E9%92%A2%E9%93%81/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="chapter-3">Chapter 3</h1>
<p>来自动物的病菌</p>
<p>欧洲对美洲的征</p>
<p>农业社会的密集人口： 群聚疾病 <strong>原因</strong>：污水排放，贸易路线，在饲养的动物中间演化：牛瘟。</p>
<p>人口数量少：慢性病</p>
<h2 id="从感染动物到人类社群的四个阶段">从感染动物到人类社群的四个阶段</h2>
<ol type="1">
<li>直接传染</li>
<li>在人类社群传播，成为流行病，之后消亡</li>
<li>曾以动物为宿主，后转入人体的病原体。</li>
<li></li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>一文搞懂字符编码</title>
    <url>/2022/06/27/%E7%BC%96%E7%A0%81/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="字符集和编码">字符集和编码</h1>
<p>​ 字符集从字符到一个数字的映射。编码是一种规则，即如何将这个字符转变为二进制数。</p>
<h2 id="ascll">ASCLL</h2>
<p>​ 计算机处理字符总是需要将其变为一个个 bit 所以最开始的字符集是 <a href="https://www.ascii-code.com/"><strong>ASCLL</strong></a> 码，将不同的英文字母，数字，以及控制字符映射到 8-bits 中。一开始 ASCLL 码只用到了 0 - 127。后来新增加了扩展 ASCLL 码， 利用了 128 - 255 剩下的一半字符。当称为 ASCLL 集的时候作为一种字符集，ASCLL 码时，是一种编码规则。</p>
<span id="more"></span>
<h2 id="gb">GB</h2>
<h3 id="gb-2312">GB 2312</h3>
<p>GB2312 是一种中文的字符集，分区管理， 共计 94 个区， 每个区含 94 个位，共8836 码位。 码位按照按照区，行，列一次决定，比如「侃」字在 57 区 0 行 9 列， 码位就是 5709，十六进制为 <code>0x39 0x09</code> 分别加上 <code>0xA0</code> 得到 <code>0xD9</code> 和 <code>0xA9</code> ，得到最终的 GB2312 为 <code>0xD90xA9</code> 。 加 <code>0xA0</code> 的目的可能使得高位和低位的值都大于 127， 向下兼容 ASCLL 码。当机器遇到连续两位大于 127 的 byte 时就能以此区分究竟是 ASCLL 码还是 GB2312 码。 GB2312 是双字节编码，为了与 ASCII 码区分开，字节的第8位必须是1，所以GB2312是8位编码。所以至少要从 0x80 128, 1000 0000) 开始吧，但是根据上面的规定，0x80 - 0x9f 要留给控制块，所以只能从 0xA0 开始咯。那为什么 GB2312 编码不是从 0xA0 开始，而是 0xA1 开始呢？ 因为 0xA0 正好是图形块的空格，所以就从 0xA1 编码，这就是 0xA0 的由来</p>
<h3 id="gbk">GBK</h3>
<p>​ 拓展，不规定低位大于 127 ，新增近 20000 个汉字符号。对应的字符编码叫 GBK 码</p>
<h3 id="gb18030">GB18030</h3>
<p>​ 新增少数民族文字</p>
<h2 id="unicode">Unicode</h2>
<p>​ 是一个规则，包含字符集和对应的编码规则。把世界上所有的字符放在一起。</p>
<h3 id="ucs-2-字符集">UCS-2 字符集</h3>
<p>​ <code>0x0000 - 0xFFFF</code> ，可表示 65536 个字符。这里只是一个字符集，并不算真正意义上的编码。</p>
<h3 id="ucs-4-字符集">UCS-4 字符集</h3>
<p>​ <code>0x00000000 - 0xFFFFFFFF</code> ， 可表示 43 亿字符。</p>
<h3 id="缺点">缺点</h3>
<p>​ 储存空间过大</p>
<h3 id="utf-8-编码">UTF-8 编码</h3>
<p>​ 每次传送 8 位 数字，而且可变长，节省流量和内存空间，是目前最广泛使用的编码规则</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202206272300871.png" alt="image-20220627230028146" /><figcaption aria-hidden="true">image-20220627230028146</figcaption>
</figure>
<h2 id="编码的应用举例">编码的应用举例</h2>
<ul>
<li>​ 在计算机内存中是使用 Unicode 字符集， 当进行文本编辑时保存之前时用的 Unicode 数据。但是当数据写入磁盘的时候就和操作系统有关了，Linux 下是 UTF-8，在 Windows 下使用 GBK 编码。 比如写入一个文本文件时， 使用 UTF-8 编码 ， 自然当打开文件时也应该默认使用 UTF-8 解码，在转为 Unicode 数据在内存里。 比如当使用 Python的 <em>open( )</em> 函数时，是内存中的进程与磁盘的交互，而这个交互过程中的编码格式则是使用操作系统的默认编码（ Linux 为 utf-8，Windows 为 gbk）</li>
<li>而当编译器读取.py 文件时，需要将储存好的 Bytes 数据解码。Python 2 默认 ASCLL 码， 而Python 3 默认 UTF-8 编码。 所以当用 python 2 执行含有中文字符串的文件时会解码错误。于是在开头加行 <code>\#-*-coding:utf-8-*-</code></li>
</ul>
<h2 id="python-2">Python 2</h2>
<p>​ 编码过程：写的代码通过 utf-8 写入，再通过解释器将其 Bytes 转换为另外编码形式的的 Bytes, utf-8 向下兼容 ASCLL。</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202206280008191.png" alt="image-20220628000845318" /><figcaption aria-hidden="true">image-20220628000845318</figcaption>
</figure>
<p>以上的数据都是以 bytes 形式存储的，在Python 2 中成为 str 类型。通过 <code>print repr(a)</code> 来查看内存中储存的形式。如果在字符串前面加上 u <code>str = u'你好'</code>，则 u 后面的字符串通过 Unicode 加载进内存。 这种类型称为为 Unicode</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202206280018694.png" alt="image-20220628001647028" /><figcaption aria-hidden="true">image-20220628001647028</figcaption>
</figure>
<h3 id="unicode-和-str-类型的转换">Unicode 和 str 类型的转换</h3>
<p>​ 其实 str 就是 Bytes ，就是将Unicode 进行编码后的到的结果。</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202206280018560.png" alt="image-20220628001829089" /><figcaption aria-hidden="true">image-20220628001829089</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># coding : utf-8</span></span><br><span class="line"><span class="built_in">str</span> = <span class="string">&quot;你好&quot;</span></span><br><span class="line"><span class="built_in">print</span> <span class="built_in">str</span>.decode(<span class="string">&#x27;ascll&#x27;</span>) <span class="comment">#错误，ascll支持中文</span></span><br><span class="line"><span class="built_in">print</span> <span class="built_in">str</span>.decode(<span class="string">&#x27;utf-8&#x27;</span>) <span class="comment">#结果 你好</span></span><br><span class="line"><span class="built_in">print</span> <span class="built_in">str</span>.decode(<span class="string">&#x27;gb2312&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="python-3">Python 3</h3>
<p>默认以 Unicode 从硬盘中加载进内存。</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202206280024379.png" alt="image-20220628002447002" /><figcaption aria-hidden="true">image-20220628002447002</figcaption>
</figure>
<p>表示 bytes 内容， <code>str = b'你好'</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = <span class="string">&quot;你好&quot;</span></span><br><span class="line"><span class="built_in">print</span> a.encode(<span class="string">&#x27;ascll&#x27;</span>) <span class="comment">#错误 无法将中文编码为 ascll 码</span></span><br><span class="line"><span class="built_in">print</span> a.encode (<span class="string">&#x27;utf-8&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>将 Bytes 解码为 Unicode</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = <span class="string">b&#x27;\xe4\xbd\xa0&#x27;</span></span><br><span class="line"><span class="built_in">print</span> a.decode(<span class="string">&#x27;utf-8&#x27;</span>) <span class="comment">#输出 你</span></span><br></pre></td></tr></table></figure>
<h3 id="参考">参考</h3>
<p>https://www.bilibili.com/video/BV1XK4y1t7D4?share_source=copy_web</p>
]]></content>
      <categories>
        <category>编码</category>
      </categories>
      <tags>
        <tag>编码</tag>
      </tags>
  </entry>
  <entry>
    <title>Item 03 - Use const whenever possible</title>
    <url>/2022/06/30/C++/Effective_C++/Item03_const/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>只要明确值不被改变就应该声明为 <code>const</code> ，以此获得编译器的襄助，保证规则不被违反。</p>
<h2 id="顶层-const-与-底层-const">顶层 <code>const</code> 与 底层 <code>const</code></h2>
<p>const pointer 成为顶层 const, pointer 指向的数据为 const 称为底层 const.</p>
<span id="more"></span>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">char</span> greeting[] = <span class="string">&quot;hello world&quot;</span>; 	<span class="comment">// greeting 类型为 char [12]</span></span><br><span class="line"><span class="type">const</span> <span class="type">char</span> *p = greeting;			<span class="comment">// 添加底层const const data , non-const pointer</span></span><br><span class="line"><span class="type">char</span> * <span class="type">const</span> p = greeting;			<span class="comment">// 顶层const non-const data , const pointer </span></span><br><span class="line"><span class="type">const</span> <span class="type">char</span> * <span class="type">const</span> p =greeting 		<span class="comment">// const data , const pointer</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>底层 const 的以下两种写法等价</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">const</span> <span class="type">char</span> *p;			</span><br><span class="line"><span class="type">char</span> <span class="type">const</span> *p;</span><br></pre></td></tr></table></figure>
<p><strong>STL</strong> 中的 iterator 类似于 (T*) 指针。声明迭代器为 const 类似于 <code>T * const</code> ，顶层const。而如果需要迭代器所指向的数据不被修改，需要 <code>const_iterator</code> 。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">std::vector&lt;<span class="type">int</span>&gt; v&#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>&#125;;</span><br><span class="line"><span class="type">const</span> std::vector&lt;<span class="type">int</span>&gt;::iterator it = v.<span class="built_in">begin</span>();      <span class="comment">//顶层const </span></span><br><span class="line">*it = <span class="number">1</span>;  <span class="comment">//正确，可被修改</span></span><br><span class="line">++it;   <span class="comment">//错误，不能修改迭代器本身</span></span><br><span class="line">std::vector&lt;<span class="type">int</span>&gt;::const_iterator itt = v.<span class="built_in">begin</span>();      <span class="comment">//底层const </span></span><br><span class="line">*itt = <span class="number">1</span>;  <span class="comment">//错误，被指向的数据不可被修改</span></span><br><span class="line">++itt;   <span class="comment">//正确，可以递增迭代器本身</span></span><br></pre></td></tr></table></figure>
<h2 id="函数返回值">函数返回值</h2>
<p>将函数范围值声明为 const 可以减少不必要的麻烦,比如</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Rational</span> &#123;</span><br><span class="line">&#125;;</span><br><span class="line">...</span><br><span class="line"><span class="function"><span class="type">const</span> Rational *<span class="title">operator</span><span class="params">(<span class="type">const</span> Rational &amp;lhs, <span class="type">const</span> Rational &amp;rhs)</span> </span>&#123;...&#125;</span><br></pre></td></tr></table></figure>
<p>如果去掉返回值的 const ，你的用户可能做出如下行为</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">(<span class="number">3</span>*<span class="number">5</span>) = <span class="number">3</span></span><br></pre></td></tr></table></figure>
<p>你可能觉得根本不会有人做出怎么奇怪的操作，但是下面这个错误就比较隐蔽， 用户在条件语句中将 <code>==</code> 写成了 <code>=</code>，发生隐式 <strong>bool</strong> 类型的转化：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span>( (<span class="number">3</span>*<span class="number">5</span>) = <span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<p>尽量将使用 <em>reference-to-const</em> 作为参数不仅避免拷贝，还能绑定到右值，比如:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">foo</span> <span class="params">(std::string &amp; s)</span></span></span><br><span class="line"><span class="function">...</span></span><br><span class="line"><span class="function">std::string str</span>;</span><br><span class="line"><span class="built_in">foo</span>(str)		<span class="comment">//正确，绑定到左值</span></span><br><span class="line"><span class="built_in">foo</span>(<span class="string">&quot;hello&quot;</span>)	<span class="comment">//错误，不能绑定右值 &quot;hello&quot; </span></span><br></pre></td></tr></table></figure>
<p>尽管 const 只有六个字符，但是却能避免很多不必要的麻烦。</p>
<h2 id="const-成员函数">const 成员函数</h2>
<h4 id="目的">目的</h4>
<ol type="1">
<li>使得 class 接口容易被理解，明白哪些函数改动内容，而哪些不行</li>
<li>使得 ‘操作 const 对象’ 成为可能。因为很多情况需要使用 <em>pass by reference-to-const</em> ，这项技术的前提就是需要 const 成员函数。</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TextBlock</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="type">const</span> <span class="type">char</span> &amp;<span class="keyword">operator</span>[](std::<span class="type">size_t</span> pos) <span class="type">const</span> &#123; </span><br><span class="line">      <span class="keyword">return</span> text[pos];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">char</span> &amp;<span class="keyword">operator</span>[](std::<span class="type">size_t</span> pos)  &#123;</span><br><span class="line">      <span class="keyword">return</span> text[pos];</span><br><span class="line">    &#125;</span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    std::string text;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>下面是调用 operator [] 的例子</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">print</span><span class="params">(<span class="type">const</span> TextBlock &amp; str)</span> </span>&#123; <span class="comment">//str 是 const 对象</span></span><br><span class="line">  std::cout &lt;&lt; str[<span class="number">0</span>];       <span class="comment">//调用 const 成员函数</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果 operator [] 的返回值类型是 <strong>char reference</strong> ，如果是 char 的话，下面句子无法编译: <figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">str[<span class="number">0</span>] = <span class="string">&#x27;x&#x27;</span></span><br></pre></td></tr></table></figure></p>
<h3 id="bitwise-const-and-logical-const">bitwise const and logical const</h3>
<ul>
<li><strong>bitwise const</strong>: class 内部的成员变量不能修改 ，编译器检测的方式</li>
<li><strong>logical const</strong>: 设计者期望的常量</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CTextBlock</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">CTextBlock</span>(<span class="type">char</span> *str):<span class="built_in">p</span>(str)&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">char</span> &amp; <span class="keyword">operator</span>[](std::<span class="type">size_t</span> pos) <span class="type">const</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> p[pos];</span><br><span class="line">    &#125;</span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    <span class="type">char</span> *p;</span><br><span class="line">&#125;;</span><br><span class="line">...</span><br><span class="line"><span class="type">char</span> str[] = <span class="string">&quot;hello&quot;</span>;</span><br><span class="line"><span class="function"><span class="type">const</span> CTextBlock <span class="title">ccb</span><span class="params">(str)</span></span>;</span><br><span class="line"><span class="type">char</span> *p = &amp;ccb[<span class="number">0</span>];</span><br><span class="line">*p = <span class="string">&#x27;J&#x27;</span>;			<span class="comment">//还是被修改了</span></span><br></pre></td></tr></table></figure>
<p>这里我们想要的 const 是 p 的内部值不被改变，但是 operator[] 返回值没加 const 时也能编译成功，即逃过了编译器 <strong>bitwise const</strong> 检查。所以尽可能使用 <strong>STL</strong> 中的 string 而非手动管理内存。</p>
<p>下面在介绍一个 <strong>logical const</strong> 被 编译器 <strong>bitwise const </strong>所过度限制的例子。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CTextBlock</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="function">std::<span class="type">size_t</span> <span class="title">length</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    <span class="type">char</span> *pText;</span><br><span class="line">    std::<span class="type">size_t</span> textlength;</span><br><span class="line">    <span class="type">bool</span> lengthIsvalid;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function">std::<span class="type">size_t</span> <span class="title">CTextBlock::length</span><span class="params">()</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span>(!lengthIsvalid) &#123;</span><br><span class="line">    textlength = std::<span class="built_in">strlen</span>(pText);</span><br><span class="line">    lengthIsvalid = <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> textlength;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>显然 <code>length()</code> 不是 <code>bitwise const</code> ， 因为 <code>textlength</code> 发生了改变。但是对于我们而言，<code>textlength</code> 与 <code>lengthIsvalid</code> 是可以接受的。 我们可以使用 <code>mutable</code> 关键字释放掉 non-static 成员变量 <strong>bitwise const</strong> 的约束。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CTextBlock</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="function">std::<span class="type">size_t</span> <span class="title">length</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    <span class="type">char</span> *pText;</span><br><span class="line">    <span class="keyword">mutable</span> std::<span class="type">size_t</span> textlength; <span class="comment">//现在可在 const 成员函数中被修改</span></span><br><span class="line">    <span class="keyword">mutable</span> <span class="type">bool</span> lengthIsvalid;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function">std::<span class="type">size_t</span> <span class="title">CTextBlock::length</span><span class="params">()</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span>(!lengthIsvalid) &#123;</span><br><span class="line">    textlength = std::<span class="built_in">strlen</span>(pText);</span><br><span class="line">    lengthIsvalid = <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> textlength;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="在-const-成员函数和-non-const-成员函数中避免重复">在 const 成员函数和 non-const 成员函数中避免重复</h2>
<p>在对某个函数实现 const 与 non-const 重载时，会产生大量的代码重复，比如在上面的例子中放入更多复杂的操作</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TextBlock</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="type">const</span> <span class="type">char</span> &amp;<span class="keyword">operator</span>[](std::<span class="type">size_t</span> pos) <span class="type">const</span> &#123; </span><br><span class="line">      <span class="comment">//do  somethings</span></span><br><span class="line">      <span class="keyword">return</span> text[pos];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">char</span> &amp;<span class="keyword">operator</span>[](std::<span class="type">size_t</span> pos)  &#123;</span><br><span class="line">      <span class="comment">// do somethings</span></span><br><span class="line">      <span class="keyword">return</span> text[pos];</span><br><span class="line">    &#125;</span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    std::string text;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>我们应该考虑令其中的一个调用另一个，这是一种很重要的思想，在重载 <code>+=</code> 和 <code>+</code> 是也利用之。利用 const 成员函数实现 non-const</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TextBlock</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="type">const</span> <span class="type">char</span> &amp;<span class="keyword">operator</span>[](std::<span class="type">size_t</span> pos) <span class="type">const</span> &#123; </span><br><span class="line">      <span class="comment">//do  somethings</span></span><br><span class="line">      <span class="keyword">return</span> text[pos];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">char</span> &amp;<span class="keyword">operator</span>[](std::<span class="type">size_t</span> pos)  &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="built_in">const_cast</span>&lt;<span class="type">char</span> &amp;&gt;(      <span class="comment">//移除 op[] 的 const </span></span><br><span class="line">          <span class="built_in">static_cast</span>&lt;<span class="type">const</span> TextBlock&amp;&gt;(*<span class="keyword">this</span>)[pos]);  <span class="comment">//为当前对象添加 const </span></span><br><span class="line">    &#125;</span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    std::string text;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>这里用到两次转型 分别是为 <code>*this</code> 添加 const ， 为 op[ ] 的返回值移除 const. 注意 <code>const_cast</code> 与 <code>static_const</code> 的区别。只有 <code>const_cast</code> 能移除 const。</p>
<p>但是反向做法：利用 non-const 成员函数实现 const 是不正确的。这是一个危险的行为，首先 <strong>non-const</strong> 函数并未声明不对对象进行修改，而 <strong>const</strong> 成员函数依赖与一个改变对象的函数显然是不合理的。而且你不得不使用 <code>const_cast</code> 去除 const，最终实现的 <strong>const</strong> 成员函数不能保证真正的 const. const 成员函数声明也就失效了。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TextBlock</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="type">const</span> <span class="type">char</span> &amp;<span class="keyword">operator</span>[](std::<span class="type">size_t</span> pos) <span class="type">const</span> &#123; </span><br><span class="line">      <span class="comment">//do  somethings</span></span><br><span class="line">      <span class="keyword">return</span> <span class="built_in">static_cast</span>&lt;<span class="type">const</span> <span class="type">char</span> &amp;&gt;(      <span class="comment">//添加 op[] 的 const </span></span><br><span class="line">          <span class="built_in">const_cast</span>&lt;TextBlock&amp;&gt;(*<span class="keyword">this</span>)[pos]);  <span class="comment">//为当前对象移除 const </span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">char</span> &amp;<span class="keyword">operator</span>[](std::<span class="type">size_t</span> pos)  &#123;</span><br><span class="line">      <span class="comment">// do somethings</span></span><br><span class="line">      text[pos] = <span class="string">&#x27;a&#x27;</span>;</span><br><span class="line">      <span class="keyword">return</span> text[pos];</span><br><span class="line">    &#125;</span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    std::string text;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h2 id="总结">总结</h2>
<ul>
<li>将某些东西声明为 const 可帮助编译器侦测错误用法。const 可作用于对象，函数参数，函数返回值类型，成员函数本体。</li>
<li>编译器实施 <strong>bitwise constness</strong> ，但编写程序时应使用 <strong>conceptual constness</strong>.</li>
<li>non-const 版本调用 const 版本避免代码重复</li>
</ul>
<h2 id="参考">参考</h2>
<p>Effective C++ 中文版（第三版）</p>
]]></content>
      <categories>
        <category>C++</category>
        <category>Effective_C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>const</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo美化：为Next主题外接 Waline 评论系统</title>
    <url>/2022/06/29/Blog%E6%90%AD%E5%BB%BA/Hexo/Hexo-Next%E4%B8%BB%E9%A2%98%E5%A4%96%E6%8E%A5%E8%AF%84%E8%AE%BA%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h3 id="前言">前言</h3>
<p>​ <strong>Waline</strong> 是一款基于 <strong>Valine</strong> 衍生的评论系统，首先在笔者目前使用的 NexT 8.12.1 下已经不再内置 Valine 系统，需要自己手动配置。 看了一圈其他的评论系统，貌似只有 Waline 支持数学公式，所以最终选择 Waline 评论系统</p>
<span id="more"></span>
<h3 id="配置数据库和服务端部署">配置数据库和服务端部署</h3>
<p>​ 选择 <a href="%5BLeanCloud%5D(https://www.leancloud.cn/)">Leanclound</a> 作为评论数据库，在 Vercel 上部署服务端。接着就按照 <span class="exturl" data-url="aHR0cHM6Ly93YWxpbmUuanMub3JnL2d1aWRlL2dldC1zdGFydGVkLmh0bWwjbGVhbmNsb3VkLSVFOCVBRSVCRSVFNyVCRCVBRS0lRTYlOTUlQjAlRTYlOEQlQUUlRTUlQkElOTM=">Waline的官方文档<i class="fa fa-external-link-alt"></i></span> 进行操作即可。这里介绍几个注意的点：</p>
<ol type="1">
<li><p>注册时推荐使用国际版，否则需要绑定备案的域名，比较麻烦。</p></li>
<li><p>在 Vercel 上部署服务端时，注意环境变量名称 <code>LEAN_ID</code>, <code>LEAN_KEY</code> 和 <code>LEAN_MASTER_KEY</code>一定要一字不差。遇到访客评论系统在不登录账号时报错如下:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Invalid value type for field &#x27;link&#x27;,value &#x27;&quot;&quot;&#x27;,expect type is &#123;:type &quot;Object&quot;&#125;,but it is &#x27;&#123;:type &quot;String&quot;&#125;&#x27;. [400 POST https://ioksy7et.api.lncldglobal.com/1.1/classes/Comment]</span><br></pre></td></tr></table></figure></li>
</ol>
<p>​ 解决方法：重新在 Leanclound 上创建 <code>Comment</code> 类。</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202206301329339.png" alt="在数据储存中创建新的Comment类" /><figcaption aria-hidden="true">在<code>数据储存</code>中创建新的Comment类</figcaption>
</figure>
<h3 id="在-hexo-上使用-waline">在 Hexo 上使用 Waline</h3>
<p>在 Hexo 根目录下执行命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install @waline/hexo-next</span><br></pre></td></tr></table></figure>
<p>接着你可以在 Hexo 根目录下 <code>\node_modules\@waline</code> 中找到 <code>default.yaml</code> 文件，里面就是所有 Waline 的设置选项了。 为了方便将其中需要改变的选项手动写入到 <code>next</code> 主题下 的 <code>_config.yaml</code>中， 以下是部分参考，更多的选项设置在上述 <code>default.yaml</code> 中：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">waline:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span> <span class="comment">#是否开启</span></span><br><span class="line">  <span class="attr">serverURL:</span> <span class="string">waline-server-ecru.vercel.app</span> <span class="comment"># Waline #服务端地址，我们这里就是上面部署的 Vercel 地址</span></span><br><span class="line">  <span class="attr">locale:</span></span><br><span class="line">    <span class="attr">placeholder:</span> <span class="string">疑义相与析，畅所欲言，不登录也没关系哒</span> <span class="comment"># #评论框的默认文字</span></span><br><span class="line">  <span class="attr">avatar:</span> <span class="string">mm</span> <span class="comment"># 头像风格</span></span><br><span class="line">  <span class="attr">meta:</span> [<span class="string">nick</span>,<span class="string">mail</span>] <span class="comment"># 自定义评论框上面的三个输入框的内容</span></span><br><span class="line">  <span class="attr">pageSize:</span> <span class="number">10</span> <span class="comment"># 评论数量多少时显示分页</span></span><br><span class="line">  <span class="attr">lang:</span> <span class="string">zh-cn</span> <span class="comment"># 语言, 可选值: en, zh-cn</span></span><br><span class="line">  <span class="attr">visitor:</span> <span class="literal">true</span> <span class="comment"># 文章阅读统计</span></span><br><span class="line">  <span class="attr">comment_count:</span> <span class="literal">true</span> <span class="comment"># 如果为 false , 评论数量只会在当前评论页面显示, 主页则不显示</span></span><br><span class="line">  <span class="attr">requiredFields:</span> [<span class="string">nick</span>] <span class="comment"># 设置用户评论时必填的信息，[nick,mail]: [nick] | [nick, mail]</span></span><br><span class="line">  <span class="attr">libUrl:</span> <span class="string">https://unpkg.com/@waline/client@v2/dist/waline.js</span> <span class="comment"># Set custom library cdn url</span></span><br><span class="line">  <span class="attr">login:</span> <span class="string">enable</span></span><br></pre></td></tr></table></figure>
<h3 id="登录服务端">登录服务端</h3>
<p>接着部署后就能够看到登录按钮，进行登录，貌似第一个登录的账号就会有个 <strong>博主</strong> 的标识。</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/mxfg-incense/picture@main/test/202206292335984.png" alt="进入登录界面" /><figcaption aria-hidden="true">进入登录界面</figcaption>
</figure>
<p>但是访客不登陆也能评论。访客填写不同的邮箱会显示其对应账号的头像。</p>
<p>最后效果可以参见<span class="exturl" data-url="aHR0cHM6Ly93YWxpbmUuanMub3JnLw==">官方文档<i class="fa fa-external-link-alt"></i></span> 。</p>
<h3 id="参考">参考</h3>
<p><span class="exturl" data-url="aHR0cHM6Ly93YWxpbmUuanMub3JnL2d1aWRlL2dldC1zdGFydGVkLmh0bWw=">官方文档<i class="fa fa-external-link-alt"></i></span></p>
<p><span class="exturl" data-url="aHR0cHM6Ly9xaWFuZmFuZ3VvamluLnRvcC8yMDIyLzAxLzIwL0hleG8lRTUlOEQlOUElRTUlQUUlQTIlRTglQkYlOUIlRTklOTglQjYlRUYlQkMlOUElRTQlQjglQkEtTmV4dC0lRTQlQjglQkIlRTklQTIlOTglRTYlQjclQkIlRTUlOEElQTAtV2FsaW5lLSVFOCVBRiU4NCVFOCVBRSVCQSVFNyVCMyVCQiVFNyVCQiU5Ri8=">谢同学博客<i class="fa fa-external-link-alt"></i></span></p>
]]></content>
      <categories>
        <category>Blog搭建</category>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>三角形中的几个恒等式</title>
    <url>/2022/07/01/%E6%95%B0%E5%AD%A6/%E5%85%B6%E4%BB%96/%E4%B8%89%E8%A7%92%E5%BD%A2%E4%B8%AD%E7%9A%84%E5%87%A0%E4%B8%AA%E6%81%92%E7%AD%89%E5%BC%8F/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><p>在 <span class="math inline">\(\Delta ABC\)</span> 中，以下等式成立</p>
<h3 id="正余弦平方和">正余弦平方和</h3>
<p><span class="math display">\[
\sin A+\sin B+\sin C=4\cos  \frac{A}{2}\cos  \frac{B}{2}\cos  \frac{C}{2}\ \tag{1}
\]</span> 证： <span class="math display">\[
\begin{aligned} LHS &amp;= 2\,\sin \frac{A+B}{2}\,\cos \frac{A-B}{2} +\sin C  \\ &amp;= 2 \,\cos  \frac{C}{2}\,\cos \frac{A-B}{2}+2\,\sin \frac{C}{2}\,\cos \frac{C}{2}\\ &amp;=2\,\cos  \frac{C}{2}\,(\cos \frac{A-B}{2}+\cos \frac{A+B}{2})\\ &amp;=4\,\cos \frac{A}{2}\,\cos \frac{B}{2}\,\cos \frac{C}{2} \\ \end{aligned}
\]</span></p>
<p><span class="math display">\[
 \cos A+\cos B+\cos C=1+4\sin  \frac{A}{2}\sin  \frac{B}{2}\sin  \frac{C}{2}\\ \tag{2}
\]</span> 证： <span class="math display">\[
\begin{aligned} LHS &amp;= 2\,\cos \frac{A+B}{2}\,\cos \frac{A-B}{2} + 1-2\,\sin ^2\frac{C}{2}  \\  &amp;= 1-2\,\sin \frac{C}{2}\,(\sin \frac{C}{2}-\cos \frac{A-B}{2})  \\ &amp;=1-2\,\sin \frac{C}{2}\,(\cos \frac{A+B}{2}-\cos \frac{A-B}{2})   \\ &amp;=1-2\,\sin \frac{C}{2}\,(-2\,\sin \frac{A}{2}\,\sin \frac{B}{2})\\ &amp;=1+4\sin  \frac{A}{2}\sin  \frac{B}{2}\sin  \frac{C}{2} \end{aligned} 
\]</span></p>
<h3 id="正余半角平方和">正余半角平方和</h3>
<p><span class="math display">\[
\sin ^2\frac{A}{2}+\sin ^2\frac{B}{2}+\sin ^2\frac{C}{2}= 1-2\,\sin \frac{A}{2}\sin \frac{B}{2}\sin \frac{C}{2}\tag{3}
\]</span></p>
<p>证： <span class="math display">\[
\begin{aligned} RHS &amp;= 1+\sin \frac{C}{2}\,(\cos \frac{A+B}{2}-\cos \frac{A-B}{2}) \\ &amp;=  1+\sin ^2\frac{C}{2}- \cos \frac{A+B}{2}\cos \frac{A-B}{2}\\ &amp;=  1+\sin ^2\frac{C}{2}-\frac{\cos A+\cos B}{2} \\ &amp;= 1+\sin ^2\frac{C}{2}-\frac{2-2\sin ^2\frac{A}{2}-2\sin ^2\frac{B}{2}}{2}   \\ &amp;=  \sin ^2\frac{A}{2}+\sin ^2\frac{B}{2}+\sin ^2\frac{C}{2} \end{aligned}
\]</span></p>
<p>同理易得： <span class="math display">\[
\cos ^2\frac{A}{2}+\cos ^2\frac{B}{2}+\cos ^2\frac{C}{2}= 2+2\,\sin \frac{A}{2}\sin \frac{B}{2}\sin \frac{C}{2}\tag{4}
\]</span></p>
<h3 id="正割余割和">正割余割和</h3>
<p><span class="math display">\[
\tan A+\tan B+\tan C=\tan A\;\tan B\;\tan C \tag{5}
\]</span> 证： <span class="math display">\[
\begin{gather*} \text{和角公式：}\tan C = -\frac{\tan A+\tan B}{1-\tan A\;\tan B}\\ \tan C-\tan A\;\tan B\;\tan C = -(\tan A+\tan B)\\ \text{移项后得到结论} \end{gather*} 
\]</span></p>
<p>推论： <span class="math display">\[
\cot A\,\cot B+\cot A\,\cot C+\cot B\,\cot C =1\tag{6} 
\]</span></p>
<p>证： <span class="math display">\[
\begin{aligned} \text{由 (5)得到: }\frac{1}{\tan A\,\tan B}&amp;=\frac{\tan C}{\tan A+\tan B+\tan C}\\ \frac{1}{\tan A\,\tan C}&amp;=\frac{\tan B}{\tan A+\tan B+\tan C}\\ \frac{1}{\tan B\,\tan C}&amp;=\frac{\tan A}{\tan A+\tan B+\tan C}\\ \end{aligned}
\]</span> 三个式子相加即可</p>
<h3 id="正余割半角">正余割半角</h3>
<p><span class="math display">\[
\cot \frac{A}{2}\cot \frac{B}{2}\cot \frac{C}{2} = \cot \frac{A}{2}\,\cot \frac{B}{2}\,\cot \frac{C}{2} \tag{7}
\]</span></p>
<p>证： 受到 (5) 启发，只需证明 <span class="math display">\[
cot \frac{C}{2} = -\frac{\cot \frac{A}{2}+\cot \frac{B}{2}}{1-\cot \frac{A}{2}\,\cot \frac{B}{2}}
\]</span></p>
<p>即证： <span class="math display">\[
\begin{gather*} \tan\frac{C}{2} =\frac{\cot \frac{A}{2}\,\cot \frac{B}{2}-1}{\cot \frac{A}{2}+\cot \frac{B}{2}}\\ \Leftarrow \tan\frac{C}{2} = \frac{1-\tan\frac{A}{2}\tan\frac{B}{2}}{\tan\frac{A}{2}+\tan\frac{B}{2}} \end{gather*}
\]</span> 推论： <span class="math display">\[
\tan\frac{A}{2}\tan\frac{B}{2}+\tan\frac{B}{2}\tan\frac{C}{2}+\tan\frac{A}{2}\tan\frac{C}{2} = 1 \tag{8}
\]</span> 由 (7) 移项得到 <span class="math display">\[
\begin{gather*} \tan\frac{A}{2}\tan\frac{B}{2}=\frac{\tan\frac{A}{2}\,\tan\frac{B}{2}\,\tan\frac{B}{2}\,\cot\frac{C}{2}}{\tan\frac{A}{2}+\tan\frac{B}{2}+\tan\frac{C}{2}}\\ \tan\frac{A}{2}\tan\frac{C}{2}=\frac{\tan\frac{A}{2}\,\tan\frac{B}{2}\,\tan\frac{B}{2}\,\cot\frac{B}{2}}{\tan\frac{A}{2}+\tan\frac{B}{2}+\tan\frac{C}{2}}\\ \tan\frac{B}{2}\tan\frac{C}{2}=\frac{\tan\frac{A}{2}\,\tan\frac{B}{2}\,\tan\frac{B}{2}\,\cot\frac{A}{2}}{\tan\frac{A}{2}+\tan\frac{B}{2}+\tan\frac{C}{2}}\\ \end{gather*} \\
\]</span> 三个式子相加即可</p>
]]></content>
      <categories>
        <category>数学</category>
        <category>其他</category>
      </categories>
      <tags>
        <tag>三角函数</tag>
      </tags>
  </entry>
  <entry>
    <title>SI140 HW1</title>
    <url>/2022/09/26/%E6%95%B0%E5%AD%A6/SI140/SI140%20HW1/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script>
]]></content>
      <categories>
        <category>数学</category>
        <category>SI140</category>
      </categories>
  </entry>
  <entry>
    <title>将数量场转为向量场的例题</title>
    <url>/2022/06/28/%E6%95%B0%E5%AD%A6/%E6%95%B0%E5%AD%A6%E5%88%86%E6%9E%90/%E4%B9%A0%E9%A2%98/%E5%B0%86%E6%95%B0%E9%87%8F%E5%9C%BA%E8%BD%AC%E4%B8%BA%E5%90%91%E9%87%8F%E5%9C%BA/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h3 id="题面">题面</h3>
<p>​ 设 <span class="math inline">\(\Sigma(t)\)</span> 是平面 <span class="math inline">\(x+y+z=t\)</span> 被球面 <span class="math inline">\(x^2+y^2+z^2=1\)</span> 截下的部分，设 <span class="math display">\[
F(x,y,z)=1-(x^2+y^2+z^2),
\]</span> ​ 求证，对于 <span class="math inline">\(\left| t \right| \leq \sqrt 3\)</span> 时，有 <span class="math display">\[
\int _{\Sigma(t)} F(x,y,z)\,d\sigma = \frac{\pi}{18} (3-t^2)^2
\]</span></p>
<span id="more"></span>
<h3 id="方法一">方法一</h3>
<p>​ 将原坐标系 <span class="math inline">\(X Y Z\)</span> 进行变换，新坐标系的 <span class="math inline">\(X&#39;OY&#39;\)</span> 平面为原坐标系的平面 <span class="math inline">\(x+y+z=0\)</span> ，坐标 <span class="math inline">\(z&#39;\)</span> 为点在原坐标系下距离 <span class="math inline">\(\Sigma(0)\)</span> 的距离，<span class="math inline">\(z&#39; = \frac {t}{\sqrt3}\)</span> ， 为了渐变就沿用 <span class="math inline">\(xyz\)</span> 命名好了。接下来就是很普通的在 <span class="math inline">\(z=\frac{t}{\sqrt 3}\)</span> 上将 <span class="math inline">\(xy\)</span> 化为极坐标的积分了。 <span class="math display">\[
\begin{gather}
\begin{aligned}
\iint _{z=\frac{t}{\sqrt 3}} 1-z^2\,d\sigma &amp;= \int_0^{2\pi}d\theta \int_0^{\sqrt {1-\frac{t^2}{3}}}(1-\frac{t^2}{3}-r^2) r\,dr\\
 &amp;=\frac{\pi}{18} (3-t^2)^2
 \end{aligned}
\end{gather}
\]</span></p>
<h3 id="方法二">方法二</h3>
<p>​ 这个方法比较绕，是利用 <span class="math inline">\(Gauss\)</span> 定理 + 补面的方式。但是 F 是个数量场，怎么把它变成向量场呢? <span class="math display">\[
\begin{equation}
\iint_S F dS  =\iint_S \boldsymbol{v}\, \vec{n} \,dS
\end{equation}
\]</span> 所以现在就是需要去确定一种 <span class="math inline">\(\vec{v}\)</span> 和 <span class="math inline">\(\vec{n}\)</span> 使其点乘为 <span class="math inline">\(F\)</span> ， 为了简便 <span class="math inline">\(\vec{v} = (1-z^2) \,\vec{k}\)</span> ，<span class="math inline">\(\vec{n}=\vec{k}\)</span>， 在进行补面就能使用高斯公式了，设 <span class="math inline">\(V\)</span> 为 <span class="math inline">\(S_1:z=\frac{t}{\sqrt3}\)</span> 和球面 <span class="math inline">\(S_2:x^2+y^2+z^2=1\)</span> 围成的面积。 <span class="math display">\[
\begin{gather}
\begin{aligned}
\iint_{S_1+S_2} \boldsymbol{v}\, \vec{n} \,dS &amp; = \iiint_V \Delta\,\vec{v} \, d\vec{S}\\
&amp;=\iiint_V2z \,  dxdydz
\end{aligned}
\end{gather}
\]</span> 注意因为高斯定理要求向量场指向平面的外侧，上面公式的 <span class="math inline">\(\vec{v}\)</span> 的方向与的我们构造的<span class="math inline">\(\vec{v}\)</span> 之间方向相反。</p>
<p>再将<span class="math inline">\(xyz\)</span> 换为极坐标 (注意这里和 <span class="math inline">\(t\)</span> 没什么关系，<span class="math inline">\(t\)</span> 只是个常数) <span class="math display">\[
\begin{cases}
x= (1-z^2)\,r\,cos\theta\\
y= (1-z^2)\,r\,sin\theta\\
z=z\\
\end{cases}
\]</span> 然后三重积分 <span class="math display">\[
\begin{gather}
\begin{aligned}
\iiint_V2z \,  dxdydz &amp;= 2\pi\int_{\frac{t}{\sqrt3}}^1z\,dz\int_0^{\sqrt{1-z^2}}r\,dr\\
&amp; = -\frac{\pi}{18}(3-t^2)^2
\end{aligned}
\end{gather}
\]</span> 而另一方面 <span class="math display">\[
\because 1-z^2 = 0 \,\text{in} \,S_2\\
\therefore
\iint_{S_2} \boldsymbol{v}\, \vec{n} \,dS = 0\\
\]</span></p>
<p><span class="math display">\[
\begin{gathered}
\begin{aligned}
\iint_{S_1} \boldsymbol{v}\, \vec{n} \,dS &amp;=\iint_{S_1+S_2} \boldsymbol{v}\, \vec{n} \,dS-\iint_{S_2} \boldsymbol{v}\, \vec{n} \,dS \\
&amp;=\frac{\pi}{18}(3-t^2)^2
\end{aligned}
\end{gathered}
\]</span></p>
]]></content>
      <categories>
        <category>数学</category>
        <category>数学分析</category>
        <category>习题</category>
      </categories>
      <tags>
        <tag>数学分析</tag>
        <tag>高等数学</tag>
        <tag>高斯公式</tag>
        <tag>曲面积分</tag>
      </tags>
  </entry>
  <entry>
    <title>Introduction to Inequality</title>
    <url>/2022/07/05/%E6%95%B0%E5%AD%A6/%E6%95%B0%E5%AD%A6%E5%88%86%E6%9E%90/%E8%AF%BE%E5%A0%82%E7%AC%94%E8%AE%B0/ISP_equiality/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h2 id="oscillation">Oscillation</h2>
<p>Example: <span class="math display">\[
\begin{gather}
b_n=c_n \, a_n=(-1)^{n+1}a_n \text, \, a_n \geq 0\\
\sum_{n=1}^{N} b_n \leq \sum_{n=1}^{N}\left| b_n \right| = \sum_{n=1}^N a_n
\end{gather}
\]</span> Use <em>Euler's formula</em> to rewrite <span class="math display">\[
(-1)^n=e^{2\pi in\frac{1}{2}}=\cos(2\pi n\frac{1}{2})+i\sin(2\pi n\frac{1}{2})
\]</span> Periodicity is 2. Moreover , Take periodicity k <span class="math display">\[
(e^{2\pi i\frac{1}{k}})^{n+k}= (e^{2\pi i\frac{1}{k}})^{n}\\
\]</span></p>
<h3 id="fourier-series">Fourier series</h3>
<p>More generally, for $ x$, consider <span class="math inline">\(e^{-i\omega n}\)</span>: Periodicity <span class="math inline">\(\frac{1}{x}\)</span>, and <span class="math inline">\(\omega = \frac{2\pi}{x}\)</span> <span class="math display">\[
F(x):= \sum_{n=-\infty}^\infty a_n e^{-i\omega n}\text{     ,              }
F_N(x):= \sum_{n=-\infty}^\infty a_n e^{-i\omega n}    
\]</span> Generate a new function on <span class="math inline">\(\left[-1,1\right]\)</span> , known as Fourier analysis.</p>
<p>Since <span class="math inline">\(|e^{i\theta}|\leq 1\)</span>, therefore</p>
<h3 id="introduction-a-norm">introduction a norm</h3>
<p>For a sequence <span class="math inline">\((a_n)_{n\in\mathbb{Z}}\in\mathbb{R}\)</span>, Let <span class="math display">\[
\left\|a_n \right\|_{\boldsymbol l^2}:= (\sum _{n=-\infty}^\infty |a_n|^p )^\frac{1}{p} \text{  for } p\in [1,\infty]
\]</span> and <span class="math display">\[
\|a_n\| = \mathop{sup}\limits_{n\in\mathbb{Z}}|a_n|
\]</span> We can measure the distance between two sequences e.g. for <span class="math inline">\(c_n=(-1)^{n+1}\)</span> and <span class="math inline">\(d_n=(-1)^{n+1}(1+\frac{1}{n})\)</span>. <span class="math display">\[
\|c_n-d_n\|=(\sum_{n=-\infty}^{\infty}\frac{1}{n^2})^\frac{1}{2}=\frac{\pi}{\sqrt6}\leq2
\]</span></p>
<h3 id="l2-estimate-crude"><span class="math inline">\(L^2\)</span>-estimate: Crude</h3>
<p>Recall the crude estimate :<span class="math inline">\(|F_N(x)| \leq \sum_{n=-N}^{n=N} a_n\)</span> ：no oscillation</p>
<p>This yields <span class="math display">\[
\begin{aligned}
\|F_N\|_{L^2}&amp;=(\int_{-1}^1(F_N(x))^2d\,x)^\frac{1}{2}\\
&amp;\leq(\int_{-1}^1a_n^2d\,x)^\frac{1}{2})\\
&amp;=2^{\frac{1}{2}}\sum_{n=-N}^{N} a_n
\end{aligned}
\]</span> In particular, if <span class="math inline">\(a_n=1\)</span> for all <span class="math inline">\(|n|\leq N\)</span> then <span class="math display">\[
\|\sum_{n=-\infty}^\infty e^{-i\omega n}\| \leq 2^\frac{3}{2}N
\]</span> <span class="math inline">\(L^2\)</span> -size of <span class="math inline">\(F_N(x)\)</span> is bounded by <span class="math inline">\(O(N)\)</span></p>
<h3 id="theorem-3-parsevals-identity">Theorem 3 (Parseval's identity)</h3>
<p><span class="math display">\[
\|\sum_{n=-\infty}^\infty e^{-i\omega n}\| \leq 2N^\frac{3}{2}\ll2^\frac{3}{2}N
\]</span></p>
<p>Multiplying out the square: <span class="math display">\[
\begin{aligned}
\|\sum_{n=-N}^N e^{-i\omega n}\| &amp;=(\int_{-1}^1(\sum_{n=-N}^N e^{-i\omega n}) ^2d\,x)^\frac{1}{2}\\
&amp;=\int_{-1}^1 \sum_{n=-N}^N e^{-i\omega n}\sum_{m=-N}^N e^{-i\omega n}d\,x\\
&amp;= \sum_{n=-N}^N\sum_{m=-N}^N \int_{-1}^1  e^{-i\omega (n-m)}d\,x
\end{aligned}
\]</span> For the diagonal case (m=n) <span class="math display">\[
\int_{-1}^1  e^{-i\omega (n-m)}d\,x =2
\]</span> For the non-diagonal case (<span class="math inline">\(n\neq m\)</span>) <span class="math display">\[
\int_{-1}^1  e^{-i\omega (n-m)}d\,x =-\frac{1}{2\pi i (n-m)}(e^{-2\pi i (n-m)}-e^{2\pi i (n-m)})=0
\]</span></p>
<p>Same argument shows more generally <span class="math display">\[
\begin{gather}
\text{For any }a_n \;s.t.\|a_n\|_{l^2}=(\sum_{n=-\infty}^\infty |a_n|^2)^{\frac{1}{2}}&lt;\infty.\\
\|\sum_{n=-\infty}^\infty e^{-i\omega n}\| _{l^2}=2^{\frac{1}{2}}\|a_n\|_{l^2}
\end{gather}
\]</span></p>
]]></content>
      <categories>
        <category>数学</category>
        <category>数学分析</category>
        <category>课堂笔记</category>
      </categories>
      <tags>
        <tag>不等式</tag>
        <tag>Fourier</tag>
      </tags>
  </entry>
</search>
